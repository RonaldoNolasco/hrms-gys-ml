{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6793a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "import datetime\n",
    "import traceback\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import jellyfish\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "125e31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "sourceDataFolder = \"1-source-data\"\n",
    "\n",
    "bumeraniterationNumber = \"4\"\n",
    "bumeranRootPath = sourceDataFolder + r\"\\main\\bumeran\\iteration-\" + bumeraniterationNumber\n",
    "\n",
    "linkediniterationNumber = \"2\"\n",
    "linkedinRootPath = sourceDataFolder + r\"\\main\\linkedin\\iteration-\" + linkediniterationNumber\n",
    "\n",
    "intermFilesFolder = \"2-intermediate-files\"\n",
    "mergedMainFolder = \"3-merged-main\"\n",
    "logsFolder = \"4-logs\"\n",
    "logFile = \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85e41e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones utilitarias\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "\n",
    "def parseLineBreaksAndAccents(text):\n",
    "  return unidecode(\" \".join(text.split()))\n",
    "\n",
    "def parseNames(text):\n",
    "  return unidecode(text).strip().title()\n",
    "\n",
    "def findTags(tag, isBeforeChange):\n",
    "  return tag.find(\"span\", {\"style\": 'font-size:10.0pt;font-family:\"Arial\",sans-serif;mso-fareast-font-family:\\n\"Times New Roman\";color:' + ('#2192C9' if isBeforeChange else '#0A26EE') })\n",
    "\n",
    "def getChildIndex(mainChildTags, title, isBeforeChange):\n",
    "  return next((index for index, tag in enumerate(mainChildTags) if ( findTags(tag, isBeforeChange).text == title if findTags(tag, isBeforeChange) else False )), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbd47f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones principales\n",
    "def getFiles(rootPath):\n",
    "  startLimit = None\n",
    "  topLimit = None\n",
    "  folders = [f for f in os.listdir(rootPath) if os.path.isdir(os.path.join(rootPath, f))]\n",
    "  files = []\n",
    "  for folder in folders:\n",
    "    folderFiles = [os.path.join(folder, f) for f in os.listdir(os.path.join(rootPath, folder)) if os.path.isfile(os.path.join(rootPath, folder, f))]\n",
    "    files.extend(folderFiles)\n",
    "\n",
    "  filterIsIn = [\n",
    "    #r\"analista-calidad\\New application_ Analista de calidad - software  from Carlos Almeida Ignacio.html\",\n",
    "    #r\"bandeja-entrada\\New application_ Arquitecto de desarrollo TI from Rony Villanueva.html\",\n",
    "    #r\"bandeja-entrada\\New application_ Diseñador UX_UI from Estefania Pineyro.html\",\n",
    "    #r\"analista-calidad\\New application_ Analista de calidad - software  from Lizet Oria Rojas - ISTQB®.html\",\n",
    "    #r\"analista-calidad\\New application_ Analista de calidad - software  from Atenas Quintana Blas SFC™,SDC™,SMC™,CTFL.html\",\n",
    "    #r\"analista-calidad\\New application_ Analista de calidad from Yoshelin Ramos(2).html\",\n",
    "    #r\"bandeja-entrada\\New application_ .NET Developer from Wilder Jesus Ramirez Huamaccto.html\",\n",
    "    #r\"analista-calidad\\New application_ Analista de calidad from Hierson Armando Tineo(1).html\",\n",
    "    #r\"bandeja-entrada\\New application_ Desarrollador Java from Cesar Miguel Illesca Cangalaya.html\",\n",
    "    #r\"analista-calidad\\New application_ Analista de calidad from Juan Carlos Villagomez Canchari.html\",\n",
    "    #r\"asistente-pmo\\New application_ Asistente de PMO from Gerson Harold Trujillo Zuñiga.html\",\n",
    "    #r\"analista-calidad\\New application_ Analista de Calidad - TI from Roy Brandon Paul Ortiz Soto.html\",\n",
    "    #r\"analista-funcional\\New application_ Analista Funcional from Eloy Ivan Solano Coello.html\",\n",
    "    #r\"ejecutivo-comercial\\New application_ Ejecutivo Comercial - Sector TI from Gustavo Carquin mejia.html\"\n",
    "    #r\"analista-funcional\\New application_ Analista Funcional TI from Angie Pilar Chacaltana Cortez.html\",\n",
    "    #r\"analista-funcional\\New application_ Analista Funcional from Argenis Alexandra Moreno Rosales.html\"\n",
    "    #r\"analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad Senior_(18).html\",\n",
    "    #r\"analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad Senior_(24).html\",\n",
    "    #r\"bandeja-entrada\\Has recibido un CV para el aviso _Desarrollador.NET_(34).html\",\n",
    "    #r\"bandeja-entrada\\Has recibido un CV para el aviso _Ejecutivo(a) Comercial TI_(127).html\"\n",
    "    #r\"bandeja-entrada\\New application_ Cloud Specialist Jr. from Mario Sergio Campos Bernaola.html\",\n",
    "    #r\"analista-funcional\\New application_ Analista Funcional from Cyntia Caterine Huaytán Suazo.html\",\n",
    "  ]\n",
    "  filesFilteredIsIn = [f for f in files if ( f in filterIsIn if filterIsIn else True )]\n",
    "\n",
    "  # Casos particulares\n",
    "  filterIsNotIn = [\n",
    "    # Falta analizar los 19 casos particulares\n",
    "  ]\n",
    "  filesFilteredNotIn = [f for f in filesFilteredIsIn if ( f not in filterIsNotIn if filterIsNotIn else True )]\n",
    "\n",
    "  filesPartitioned = filesFilteredNotIn[(startLimit-1 if startLimit else 0): (topLimit if topLimit else len(files))]\n",
    "  return filesPartitioned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cdcdb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncoding(file, stringLog, rootPath):\n",
    "  encoding = \"utf-8\"\n",
    "  try:\n",
    "    with open(os.path.join(rootPath, file), \"r\") as f:\n",
    "      encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
    "  except Exception as e:\n",
    "    encoding = \"utf-8\"\n",
    "    print(file)\n",
    "    stringLog = stringLog + str(file) + \"\\n\"\n",
    "    traceback.print_exc()\n",
    "    stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "    print()\n",
    "    stringLog = stringLog + \"\\n\"\n",
    "    pass\n",
    "\n",
    "  return encoding, stringLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6d1455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidateBumeran(file, index, encoding, stringLog):\n",
    "  candidateData = {}\n",
    " \n",
    "  try:\n",
    "  # Abriendo el archivo\n",
    "    with open(os.path.join(bumeranRootPath, file), \"r\", encoding=encoding) as myFile:\n",
    "      #Parseando el archivo html a soup\n",
    "      soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
    "\n",
    "      # Obteniendo cada uno de los campos para la data\n",
    "\n",
    "      # Id del postulante\n",
    "      #candidateData[\"id\"] = str(index + 1)\n",
    "\n",
    "      # Fecha de postulación\n",
    "      rawPostulationDate = soup.find_all(\"span\", {\"style\": \"color:black\"})[3].text\n",
    "      postulationDate = datetime.datetime.strptime(rawPostulationDate, \"%A, %B %d, %Y %I:%M %p\")\n",
    "      candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "      # Definiendo los colores a usar para las búsquedas según las fechas\n",
    "      isBeforeChange = True if (postulationDate <= datetime.datetime(2020,6,11,12,5,0)) else False\n",
    "      # Linkedin comenzo a usarse en 22/04/25 23:06\n",
    "      # El primer punto de inflexión es 22/09/23 02:15\n",
    "      # El otro no tiene fecha definida, cambia muy poco el diseño pero agrega lo de adquirir más candidatos\n",
    "\n",
    "      # Nombre del perfil\n",
    "      candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(soup.findAll(\"span\", {\"style\": (\"color:#008599\" if isBeforeChange else \"color:#E90066\") })[0].text))\n",
    "\n",
    "      # Nombre del postulante\n",
    "      rawcandidateName = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")[0].text # El split join tambien quita saltos de línea\n",
    "      candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(rawcandidateName))\n",
    "\n",
    "      # Pais de residencia\n",
    "      tagResidenceCountry = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")[2].text\n",
    "      if tagResidenceCountry.find(\",\") == -1:\n",
    "        candidateData[\"residenceCountry\"] = \"\"\n",
    "      else:\n",
    "        rawResidenceCountry = tagResidenceCountry[0:tagResidenceCountry.find(\",\")]\n",
    "        candidateData[\"residenceCountry\"] = parseNames(parseLineBreaksAndAccents(rawResidenceCountry))\n",
    "\n",
    "      # Canal\n",
    "      candidateData[\"channel\"] = \"Bumeran\"\n",
    "\n",
    "      # Obteniendo todas las etiquetas principales\n",
    "      mainDivTag = soup.find_all(\"div\", {\"style\": 'background-position-x:50%;background-position-y:100%'})[0]\n",
    "      mainChildTags = mainDivTag.find_all(recursive=False)\n",
    "\n",
    "      # Experiencia laboral\n",
    "      workExperienceIndex = getChildIndex(mainChildTags, \"Experiencia laboral\", isBeforeChange)\n",
    "      educationIndex = getChildIndex(mainChildTags, \"Educación\", isBeforeChange)\n",
    "\n",
    "      if workExperienceIndex and educationIndex:\n",
    "        workExperienceTags = mainChildTags[workExperienceIndex+2:educationIndex]\n",
    "        candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(workExperienceTags[0].find_all(\"b\")[0].text))\n",
    "        candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(workExperienceTags[1].find_all(\"b\")[0].text))\n",
    "\n",
    "        # Hay un caso que tiene span ya de por si en las experiencias laborales, el html 22, revisar\n",
    "        daysOfExperience = 0\n",
    "        for index in range(0, len(workExperienceTags), 2):\n",
    "          startDate = datetime.datetime.strptime(parseLineBreaksAndAccents(workExperienceTags[index].text)[0: parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" - \")] , \"%d-%m-%Y\")\n",
    "          endDateText = parseLineBreaksAndAccents(workExperienceTags[index].text)[parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" - \")+3: parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" | \")]\n",
    "          endDate = datetime.datetime.strptime(endDateText, \"%d-%m-%Y\") if endDateText != \"Presente\" else datetime.datetime.strptime(rawPostulationDate, \"%A, %B %d, %Y %I:%M %p\")\n",
    "          daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "        candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "        candidateData[\"worksNumber\"] = int(len(workExperienceTags)/2)\n",
    "      else:\n",
    "        candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "        candidateData[\"yearsOfExperience\"] = 0\n",
    "        candidateData[\"worksNumber\"] = 0\n",
    "\n",
    "      # Carrera profesional (última alcanzada)\n",
    "      educationIndex = getChildIndex(mainChildTags, \"Educación\", isBeforeChange)\n",
    "      informaticsIndex = getChildIndex(mainChildTags, \"Informática\", isBeforeChange)\n",
    "\n",
    "      if educationIndex and informaticsIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        educationTags = mainChildTags[educationIndex+2:informaticsIndex]\n",
    "\n",
    "        boldTags0 = educationTags[0].find_all(\"b\")\n",
    "        if len(boldTags0) == 0:\n",
    "          candidateData[\"studyCenter\"] = \"\"\n",
    "          candidateData[\"careerField\"] = \"\"\n",
    "        elif len(boldTags0) == 1:\n",
    "          #print(\"GA\")\n",
    "          if (parseLineBreaksAndAccents(educationTags[0].text).find(\",\") - parseLineBreaksAndAccents(educationTags[0].text).find(\" | \") == 3):\n",
    "            candidateData[\"studyCenter\"] = \"\"\n",
    "            candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "          else:\n",
    "            candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "            candidateData[\"careerField\"] = \"\"\n",
    "        else:\n",
    "          #print(\"AG\")\n",
    "          #print(educationTags[0].find_all(\"b\")[0])\n",
    "          candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "          candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(boldTags0[1].text.strip()))\n",
    "        \n",
    "        haveBoldTags1 = True if len(educationTags[1].find_all(\"b\")) > 0 else False\n",
    "        #if len(boldTags1) == 1:\n",
    "        tempTags = educationTags[1].find_all(\"span\")\n",
    "        #print(tempTags[1:])\n",
    "        statusDegreeIndex = next(((index+1 if haveBoldTags1 else index) for index, x in enumerate( tempTags[1:] if haveBoldTags1 else tempTags ) if \",\" in x.text), None)\n",
    "        #print([x.text for index, x in enumerate(tempTags[1:])])\n",
    "        #print(statusDegreeIndex)\n",
    "        \n",
    "        if statusDegreeIndex is not None:\n",
    "          candidateData[\"careerStatus\"] = parseNames(parseLineBreaksAndAccents(educationTags[1].find_all(\"span\")[statusDegreeIndex].text.split(\",\")[1].strip()))\n",
    "          candidateData[\"careerDegree\"] = parseNames(parseLineBreaksAndAccents(educationTags[1].find_all(\"span\")[statusDegreeIndex].text.split(\",\")[2].strip()[:-1]))\n",
    "          candidateData[\"studiesNumber\"] = int(len(educationTags)/2)\n",
    "        else:\n",
    "          candidateData[\"careerStatus\"] = candidateData[\"careerDegree\"] = \"\"\n",
    "          candidateData[\"studiesNumber\"] = 0\n",
    "      else:\n",
    "        candidateData[\"studyCenter\"] = candidateData[\"careerField\"] = candidateData[\"careerStatus\"] = candidateData[\"careerDegree\"] = \"\"\n",
    "        candidateData[\"studiesNumber\"] = 0\n",
    "      #print(file)\n",
    "      #print(candidateData[\"careerStatus\"])\n",
    "      #print(candidateData[\"careerDegree\"])\n",
    "      #print()\n",
    "\n",
    "      # Habilidades técnicas\n",
    "      informaticsIndex = getChildIndex(mainChildTags, \"Informática\", isBeforeChange)\n",
    "      languageIndex = getChildIndex(mainChildTags, \"Idiomas\", isBeforeChange)\n",
    "\n",
    "      if informaticsIndex and languageIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        technicalSkillsTags = mainChildTags[informaticsIndex+2:languageIndex][0].find_all(\"span\")\n",
    "        candidateData[\"technicalSkills\"] = int(len(technicalSkillsTags)/4)\n",
    "\n",
    "      else:\n",
    "        candidateData[\"technicalSkills\"] = 0\n",
    "\n",
    "      # Falta habilidades blandas\n",
    "\n",
    "      # Lenguajes\n",
    "      languageIndex = getChildIndex(mainChildTags, \"Idiomas\", isBeforeChange)\n",
    "      otherKnowledgesIndex = getChildIndex(mainChildTags, \"Otros Conocimientos\", isBeforeChange)\n",
    "\n",
    "      if languageIndex and otherKnowledgesIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        languagesTags = mainChildTags[languageIndex+2:otherKnowledgesIndex][0].find_all(\"span\")\n",
    "        candidateData[\"languages\"] = int(len(languagesTags)/7)\n",
    "\n",
    "      else:\n",
    "        candidateData[\"languages\"] = 1\n",
    "\n",
    "      # Otros conocimientos\n",
    "      otherKnowledgesIndex = getChildIndex(mainChildTags, \"Otros Conocimientos\", isBeforeChange)\n",
    "      endIndex = len(mainChildTags)-1\n",
    "\n",
    "      if languageIndex and otherKnowledgesIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        otherKnowledgesTags = mainChildTags[otherKnowledgesIndex+2:endIndex][0].find_all(\"span\")\n",
    "        candidateData[\"anotherSkills\"] = int(len(otherKnowledgesTags)/3)\n",
    "      else:\n",
    "        candidateData[\"anotherSkills\"] = 0\n",
    "\n",
    "      candidateData[\"references\"] = 0\n",
    "\n",
    "      # Salario pretendido\n",
    "      tagsSalary = [index for index, tag in enumerate(soup.find_all(\"span\")) if \"Sueldo pretendido\" in tag.text]\n",
    "      if len(tagsSalary) > 0:\n",
    "        rawSalary = soup.find_all(\"span\")[tagsSalary[0]+1].text\n",
    "        candidateData[\"salary\"] = int(float(parseLineBreaksAndAccents(\" \".join(rawSalary.split()))[1:].title()))\n",
    "      else:\n",
    "        candidateData[\"salary\"] = 0\n",
    "\n",
    "  except Exception as e:\n",
    "    candidateData = {}\n",
    "    print(file)\n",
    "    stringLog = stringLog + str(file) + \"\\n\"\n",
    "    traceback.print_exc()\n",
    "    stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "    print()\n",
    "    stringLog = stringLog + \"\\n\"\n",
    "    pass\n",
    "\n",
    "  return candidateData, stringLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54cef587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidateLinkedin(file, index, encoding, stringLog):\n",
    "  candidateData = {}\n",
    "\n",
    "  encoding = \"utf-8\"\n",
    "  try:\n",
    "    with open(os.path.join(linkedinRootPath, file), \"r\") as f:\n",
    "      encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
    "  except Exception as e:\n",
    "    encoding = \"utf-8\"\n",
    "    print(file)\n",
    "    stringLog = stringLog + str(file) + \"\\n\"\n",
    "    traceback.print_exc()\n",
    "    stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "    print()\n",
    "    stringLog = stringLog + \"\\n\"\n",
    "    pass\n",
    "\n",
    "  try:\n",
    "  # Abriendo el archivo\n",
    "    with open(os.path.join(linkedinRootPath, file), \"r\", encoding=encoding) as myFile:\n",
    "      #Parseando el archivo html a soup\n",
    "      \n",
    "      soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
    "\n",
    "      rawPostulationDate = soup.find_all(\"span\", {\"style\": \"color:black\"})[3].text\n",
    "      postulationDate = datetime.datetime.strptime(rawPostulationDate, \"%A, %B %d, %Y %I:%M %p\")\n",
    "\n",
    "      rawProfileName = parseLineBreaksAndAccents(soup.find_all(\"span\", {\"style\": \"color:black\"})[7].text)\n",
    "      startIndexProfileName = rawProfileName.find(\": \")\n",
    "      endIndexProfileName = rawProfileName.find(\" from \")\n",
    "\n",
    "      if postulationDate <= datetime.datetime(2022,9,23,2,15,0):\n",
    "        \n",
    "        candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(rawProfileName[startIndexProfileName+1:endIndexProfileName]))\n",
    "\n",
    "        candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
    "\n",
    "        tempSpanTags = soup.find_all(\"span\", {\"style\": 'font-size:9.0pt;font-family:\\n            \"Helvetica\",sans-serif;color:#737373'})\n",
    "        existsCountry = True if len(tempSpanTags) > 1 else False\n",
    "        candidateData[\"residenceCountry\"] = parseNames(parseLineBreaksAndAccents(tempSpanTags[len(tempSpanTags)-1].text)) if existsCountry else \"\"\n",
    "\n",
    "        candidateData[\"channel\"] = \"Linkedin\"\n",
    "\n",
    "        tableTags = soup.find_all(\"table\")\n",
    "\n",
    "        notHaveScreening = True if \"Screening qualifications\" not in str(soup) else False\n",
    "        startTag = 15 if notHaveScreening else 16\n",
    "        endTag = len(tableTags)-3\n",
    "        findedTableTags = tableTags[startTag:endTag]\n",
    "\n",
    "        haveTags = [None, None, None, None, None]\n",
    "\n",
    "        for index, tag in enumerate(findedTableTags):\n",
    "          haveTags[0] = index if \"Current experience\" in tag.text else haveTags[0]\n",
    "          haveTags[1] = index if \"Past experience\" in tag.text else haveTags[1]\n",
    "          haveTags[2] = index if \"Education\" in tag.text else haveTags[2]\n",
    "          haveTags[3] = index if \"Skills matching your job\" in tag.text else haveTags[3]\n",
    "          haveTags[4] = index if \"Highlight\" in tag.text else haveTags[4]\n",
    "\n",
    "        for index, haveTag in enumerate(haveTags):\n",
    "          if index == 0:\n",
    "            if haveTag is not None:\n",
    "              #spanTags = findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\") Caso particular que no vale la pena\n",
    "              #startSpanIndex = 0 if len(spanTags) == 2 else len(spanTags)-3\n",
    "              candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[1])\n",
    "              candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[0])\n",
    "            else:\n",
    "              candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "          \n",
    "          elif index == 1:\n",
    "            if haveTag is not None:\n",
    "              daysOfExperience = 0\n",
    "              trTag = findedTableTags[haveTag].find_all(\"tr\")[1]\n",
    "              pTags = trTag.find_all(\"p\")\n",
    "              for pTag in pTags:\n",
    "                spanTag = parseLineBreaksAndAccents(pTag.find_all(\"span\")[1].text)\n",
    "                startDate = datetime.datetime.strptime(spanTag.split(\" - \")[0], \"%Y\")\n",
    "                endDate = datetime.datetime.strptime(spanTag.split(\" - \")[1], \"%Y\")\n",
    "                daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "              candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "              candidateData[\"worksNumber\"] = int(len(pTags))\n",
    "            else:\n",
    "              candidateData[\"yearsOfExperience\"] = 0\n",
    "              candidateData[\"worksNumber\"] = 0\n",
    "\n",
    "          elif index == 2:\n",
    "            # No se tiene el careerStatus en linkedin\n",
    "            if haveTag is not None:\n",
    "              trTags = findedTableTags[haveTag].find_all(\"tr\")[1:]\n",
    "              #print(trTags[0])\n",
    "              firstCenterWithDateIndex = -1\n",
    "              studiesNumber = 0\n",
    "              for index, trTag in enumerate(trTags):\n",
    "                if(len(trTag.find_all(\"span\"))>1):\n",
    "                  if(len(trTags[index-1].find_all(\"span\")) == 1):\n",
    "                    if firstCenterWithDateIndex == -1:\n",
    "                      firstCenterWithDateIndex = index-1\n",
    "                if(len(trTag.find_all(\"span\"))==1):\n",
    "                  studiesNumber = studiesNumber + 1\n",
    "              \n",
    "              #print(firstCenterWithDateIndex)\n",
    "              #print(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \")[1])\n",
    "              #print(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \"))\n",
    "              #print(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \")[1]))\n",
    "\n",
    "              if firstCenterWithDateIndex != -1:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex].text))\n",
    "                tempTagArray = trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")\n",
    "                candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")[1])) if len(tempTagArray) > 1 else \"\"\n",
    "                candidateData[\"careerStatus\"] = \"En Curso\" if (\"Present\" in parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[1].text)) else \"Graduado\"\n",
    "                tempText = parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")[0])\n",
    "                candidateData[\"careerDegree\"] = parseNames(tempText) if not tempText[0:4].isnumeric() else \"\"\n",
    "              else:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[0].text))\n",
    "                candidateData[\"careerField\"] = \"\"\n",
    "                candidateData[\"careerStatus\"] = \"\"\n",
    "                candidateData[\"careerDegree\"] = \"\"\n",
    "              \n",
    "              candidateData[\"studiesNumber\"] = studiesNumber\n",
    "            else:\n",
    "              candidateData[\"studyCenter\"] = \"\"\n",
    "              candidateData[\"careerField\"] = \"\"\n",
    "              candidateData[\"careerStatus\"] = \"\"\n",
    "              candidateData[\"careerDegree\"] = \"\"\n",
    "              candidateData[\"studiesNumber\"] = 0\n",
    "          elif index == 3:\n",
    "            if haveTag is not None:\n",
    "              skillsCounter = 0\n",
    "              spanTags = findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")\n",
    "              for spanTag in spanTags:\n",
    "                if \"\".join(spanTag[\"style\"].split()) == 'font-size:10.5pt;font-family:\"Helvetica\",sans-serif;mso-fareast-font-family:\"TimesNewRoman\";color:#4D4D4D':\n",
    "                  skillsCounter = skillsCounter + 1\n",
    "              \n",
    "              candidateData[\"technicalSkills\"] = skillsCounter\n",
    "            else:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "            \n",
    "            candidateData[\"languages\"] = 1\n",
    "            candidateData[\"anotherSkills\"] = 0 if notHaveScreening else int(parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text)[parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text).find(\": \")+2: parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text).find(\"/\")])\n",
    "          elif index == 4:\n",
    "            if haveTag is not None:\n",
    "              highlightText = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)\n",
    "              isKnows = True if (\"knows\" in highlightText) else False\n",
    "              #print(isKnows)\n",
    "              isMoreThanTwo = True if (\"others\" in highlightText) else False\n",
    "              if isKnows and isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" and \")+5:highlightText.find(\" others \")])\n",
    "              elif isKnows and not isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText.count(\" and \") + 1)\n",
    "              else:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" hired \")+7:highlightText.find(\" people \")])\n",
    "            else:\n",
    "              candidateData[\"references\"] = 0\n",
    "        candidateData[\"salary\"] = 0\n",
    "        \n",
    "      else:\n",
    "        candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(rawProfileName[startIndexProfileName+1:endIndexProfileName]))\n",
    "\n",
    "        candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"color:#0A66C2;text-decoration:none;text-underline:none\"}).text))\n",
    "        \n",
    "        tempSpanTags = soup.find_all(\"span\", {\"style\": 'font-size:10.5pt;font-family:\"Helvetica\",sans-serif;\\n          color:#737373'})\n",
    "        existsCountry = True if len(tempSpanTags) > 1 else False\n",
    "        candidateData[\"residenceCountry\"] = parseNames(parseLineBreaksAndAccents(tempSpanTags[len(tempSpanTags)-1].text)) if existsCountry else \"\"\n",
    "\n",
    "        candidateData[\"channel\"] = \"Linkedin\"\n",
    "\n",
    "        tableTags = soup.find_all(\"table\")\n",
    "\n",
    "        startTag = 14\n",
    "        endTag = len(tableTags)-3\n",
    "        findedTableTags = tableTags[startTag:endTag]\n",
    "\n",
    "        haveTags = [None, None, None, None, None]\n",
    "\n",
    "        for index, tag in enumerate(findedTableTags):\n",
    "          haveTags[0] = index if \"Current experience\" in tag.text else haveTags[0]\n",
    "          haveTags[1] = index if \"Past experience\" in tag.text else haveTags[1]\n",
    "          haveTags[2] = index if \"Education\" in tag.text else haveTags[2]\n",
    "          haveTags[3] = index if \"Screening qualifications\" in tag.text else haveTags[3]\n",
    "          haveTags[4] = index if \"Highlight\" in tag.text else haveTags[4]\n",
    "        \n",
    "        for index, haveTag in enumerate(haveTags):\n",
    "          if index == 0:\n",
    "            if haveTag is not None:\n",
    "              tempTrTags = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")\n",
    "              #print(tempTrTags[1].find_all(\"span\")[0].text)\n",
    "              tempWorkCenter = tempTrTags[1] if len(tempTrTags) > 1 else \"\"\n",
    "              candidateData[\"lastWorkCenter\"] = parseNames(tempWorkCenter[0:tempWorkCenter.rfind(\" - \")-4]) if tempWorkCenter != \"\" else \"\"\n",
    "              candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[0])\n",
    "            else:\n",
    "              candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "          \n",
    "          elif index == 1:\n",
    "            if haveTag is not None:\n",
    "              daysOfExperience = 0\n",
    "              trTags = [x for x in findedTableTags[haveTag].find_all(\"tr\") if x.find(\"span\", {\"style\": 'font-size:9.0pt;font-family:\"Helvetica\",sans-serif;\\n          color:#737373'})]\n",
    "              #print(trTags)\n",
    "              for trTag in trTags:\n",
    "                #print(pTag.text)\n",
    "                spanTag = parseLineBreaksAndAccents(trTag.find_all(\"span\")[0].text)\n",
    "                #print(spanTag)\n",
    "                #print(\"\".isnumeric())\n",
    "                if spanTag[spanTag.rfind(\" - \")-4:spanTag.rfind(\" - \")].isnumeric() and spanTag[spanTag.rfind(\" - \")+3:spanTag.rfind(\" - \")+7].isnumeric():\n",
    "                  startDate = datetime.datetime.strptime(spanTag[spanTag.rfind(\" - \")-4:spanTag.rfind(\" - \")], \"%Y\")\n",
    "                  endDate = datetime.datetime.strptime(spanTag[spanTag.rfind(\" - \")+3:spanTag.rfind(\" - \")+7], \"%Y\")\n",
    "                  daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "              candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "              candidateData[\"worksNumber\"] = int(len(trTags))\n",
    "            else:\n",
    "              candidateData[\"yearsOfExperience\"] = 0\n",
    "              candidateData[\"worksNumber\"] = 0\n",
    "\n",
    "          elif index == 2:\n",
    "            # No se tiene el careerStatus en linkedin\n",
    "            if haveTag is not None:\n",
    "              trTags = findedTableTags[haveTag].find_all(\"tr\")[1:]\n",
    "              #print(trTags[0])\n",
    "              firstCenterWithDateIndex = -1\n",
    "              studiesNumber = 0\n",
    "              for index, trTag in enumerate(trTags):\n",
    "                if \" - \" in parseLineBreaksAndAccents(trTag.text):\n",
    "                  if \" - \" not in parseLineBreaksAndAccents(trTags[index-1].text):\n",
    "                    if firstCenterWithDateIndex == -1:\n",
    "                      firstCenterWithDateIndex = index-1\n",
    "                if(\" - \" not in parseLineBreaksAndAccents(trTag.text)):\n",
    "                  studiesNumber = studiesNumber + 1\n",
    "              #print(firstCenterWithDateIndex)\n",
    "              if firstCenterWithDateIndex != -1:\n",
    "                #print(\"GA\")\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex].text))\n",
    "                tempTagArray = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find(\"span\").text))\n",
    "                candidateData[\"careerField\"] = parseNames(tempTagArray[tempTagArray.find(\", \")+1:tempTagArray.rfind(\" - \")-4])\n",
    "                candidateData[\"careerStatus\"] = \"En Curso\" if (\"Present\" in tempTagArray) else \"Graduado\"\n",
    "                candidateData[\"careerDegree\"] = parseNames(tempTagArray[0:tempTagArray.find(\", \")]) if tempTagArray.find(\", \") != -1 else \"\"\n",
    "                #print(candidateData)\n",
    "              else:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[0].text))\n",
    "                candidateData[\"careerField\"] = \"\"\n",
    "                candidateData[\"careerStatus\"] = \"\"\n",
    "                candidateData[\"careerDegree\"] = \"\"\n",
    "              \n",
    "              candidateData[\"studiesNumber\"] = studiesNumber\n",
    "            else:\n",
    "              candidateData[\"studyCenter\"] = \"\"\n",
    "              candidateData[\"careerField\"] = \"\"\n",
    "              candidateData[\"careerStatus\"] = \"\"\n",
    "              candidateData[\"careerDegree\"] = \"\"\n",
    "              candidateData[\"studiesNumber\"] = 0\n",
    "          \n",
    "          elif index == 3:\n",
    "            if haveTag is not None:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "              candidateData[\"languages\"] = 1\n",
    "              candidateData[\"anotherSkills\"] = int(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)[0])\n",
    "            else:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "              candidateData[\"languages\"] = 1\n",
    "              candidateData[\"anotherSkills\"] = 0\n",
    "            \n",
    "          elif index == 4:\n",
    "            if haveTag is not None:\n",
    "              highlightText = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)\n",
    "              #print(highlightText)\n",
    "              isKnows = True if (\"knows\" in highlightText) else False\n",
    "              #print(isKnows)\n",
    "              isMoreThanTwo = True if (\"others\" in highlightText) else False\n",
    "              if isKnows and isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" and \")+5:highlightText.find(\" others \")])\n",
    "              elif isKnows and not isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText.count(\" and \") + 1)\n",
    "              else:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" hired \")+7:highlightText.find(\" people \")])\n",
    "            else:\n",
    "              candidateData[\"references\"] = 0\n",
    "        candidateData[\"salary\"] = 0\n",
    "      \n",
    "  except Exception as e:\n",
    "\n",
    "    candidateData = {}\n",
    "    print(file)\n",
    "    stringLog = stringLog + str(file) + \"\\n\"\n",
    "    traceback.print_exc()\n",
    "    stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "    print()\n",
    "    stringLog = stringLog + \"\\n\"\n",
    "    pass\n",
    "  \n",
    "  return candidateData, stringLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3efbb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJson(path, encoding='utf-8', errors=None):\n",
    "  with open (path, \"r\", encoding=encoding, errors=errors) as file:\n",
    "    data = json.loads(file.read())\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "889453a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeJson(data, pathJson, pathCsv, encoding='utf-8'):\n",
    "  with open(pathJson, 'w', encoding=encoding) as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a3fec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeCsv(data, pathCsv, encoding='utf-8'):\n",
    "  with open(pathCsv, 'w', newline='', encoding=encoding) as file:\n",
    "    if data:\n",
    "      writer = csv.DictWriter(file, fieldnames=data[0].keys(), lineterminator='\\n')\n",
    "      writer.writeheader()\n",
    "      writer.writerows(data)\n",
    "    else:\n",
    "      file.write(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0976a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateFiles(files, source, rootPath):\n",
    "  stringLog = \"\"\n",
    "\n",
    "  # Definiendo la data final a recoger\n",
    "  data = []\n",
    "  # Iterando por cada postulación\n",
    "  for index, file in enumerate(files):\n",
    "    # Obteniendo el encoding\n",
    "    encoding, stringLog = getEncoding(file, stringLog, rootPath)\n",
    "\n",
    "    candidate, stringLog = getCandidateBumeran(file, index, encoding, stringLog) if source == 'bumeran' else getCandidateLinkedin(file, index, encoding, stringLog)\n",
    "    \n",
    "    if (candidate):\n",
    "      data.append(candidate)\n",
    "\n",
    "  return data, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "472c3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndWriteMain(source):\n",
    "  rootPath = bumeranRootPath if source == \"bumeran\" else linkedinRootPath\n",
    "  files = getFiles(rootPath)\n",
    "  # Iterando sobre los archivos y calculando la data\n",
    "  data, stringLog = iterateFiles(files, source, rootPath)\n",
    "\n",
    "  # Escribiendo la data y el log\n",
    "  with open(os.path.join(intermFilesFolder, source + '.json'), 'w') as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "  \n",
    "  with open(os.path.join(logsFolder, logFile + \"-\" + source + \".txt\"), \"w\", encoding='utf-16') as f:\n",
    "    f.write(stringLog)\n",
    "\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8528b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndWriteMergedMain(mainData):\n",
    "  mainMergeddata = []\n",
    "  for elem in mainData:\n",
    "    mainMergeddata.extend(elem)\n",
    "\n",
    "  writeJson(mainMergeddata, os.path.join(mergedMainFolder, \"result.json\"), 'utf-8')\n",
    "  writeCsv(mainMergeddata, os.path.join(mergedMainFolder, \"result.csv\"), 'utf-8')\n",
    "\n",
    "  return mainMergeddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9021c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio: 2023-05-10 01:40:50.747398\n",
      "Se inició el procesamiento\n",
      "analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad_(76).html\n",
      "\n",
      "analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad_(76).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3301910123.py\", line 5, in getEncoding\n",
      "    encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 126888: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analista-calidad\\Has recibido un CV para el aviso _Analista QA_(29).html\n",
      "\n",
      "analista-calidad\\Has recibido un CV para el aviso _Analista QA_(29).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3301910123.py\", line 5, in getEncoding\n",
      "    encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 123724: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analista-funcional\\Has recibido un CV para el aviso _Analista Funcional_(110).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 61, in _buffer_decode\n",
      "    codecs.utf_16_ex_decode(input, errors, 0, final)\n",
      "UnicodeDecodeError: 'utf-16-le' codec can't decode byte 0x0a in position 143272: truncated data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analista-funcional\\Has recibido un CV para el aviso _Analista Funcional_(150).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 67, in _buffer_decode\n",
      "    raise UnicodeError(\"UTF-16 stream does not start with BOM\")\n",
      "UnicodeError: UTF-16 stream does not start with BOM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\CVs Java  - Búsqueda.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 16, in getCandidateBumeran\n",
      "    rawPostulationDate = soup.find_all(\"span\", {\"style\": \"color:black\"})[3].text\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\Has recibido un CV para el aviso _Analista Programador Senior_Full Stack_(2).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 34, in getCandidateBumeran\n",
      "    tagResidenceCountry = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")[2].text\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\Has recibido un CV para el aviso _Analista Programador_(6).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 34, in getCandidateBumeran\n",
      "    tagResidenceCountry = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")[2].text\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\Has recibido un CV para el aviso _Asistente de Recursos Humanos_(304).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 67, in _buffer_decode\n",
      "    raise UnicodeError(\"UTF-16 stream does not start with BOM\")\n",
      "UnicodeError: UTF-16 stream does not start with BOM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\Has recibido un CV para el aviso _Asistente de Recursos Humanos_(45).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 67, in _buffer_decode\n",
      "    raise UnicodeError(\"UTF-16 stream does not start with BOM\")\n",
      "UnicodeError: UTF-16 stream does not start with BOM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\Has recibido un CV para el aviso _Cloud Specialist_(12).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 61, in _buffer_decode\n",
      "    codecs.utf_16_ex_decode(input, errors, 0, final)\n",
      "UnicodeDecodeError: 'utf-16-le' codec can't decode byte 0x0a in position 99676: truncated data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\Has recibido un CV para el aviso _Diseñador UX_(25).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 61, in _buffer_decode\n",
      "    codecs.utf_16_ex_decode(input, errors, 0, final)\n",
      "UnicodeDecodeError: 'utf-16-le' codec can't decode bytes in position 64492-64493: illegal encoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\Renan Abarca Torres te indicó como referencia en Bumeran.com.html\n",
      "\n",
      "bandeja-entrada\\Re_ CV de PHP Carla Merida.html\n",
      "\n",
      "bandeja-entrada\\RE_ Has recibido un CV para el aviso _Ejecutivo Comercial_(1).html\n",
      "\n",
      "bandeja-entrada\\RE_ Has recibido un CV para el aviso _Ejecutivo Comercial_.html\n",
      "\n",
      "bandeja-entrada\\RE_ Has recibido un CV para el aviso _Especialista Cloud_.html\n",
      "\n",
      "bandeja-entrada\\Su resumen mensual.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 27, in getCandidateBumeran\n",
      "    candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(soup.findAll(\"span\", {\"style\": (\"color:#008599\" if isBeforeChange else \"color:#E90066\") })[0].text))\n",
      "IndexError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 45, in getCandidateBumeran\n",
      "    mainDivTag = soup.find_all(\"div\", {\"style\": 'background-position-x:50%;background-position-y:100%'})[0]\n",
      "IndexError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 27, in getCandidateBumeran\n",
      "    candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(soup.findAll(\"span\", {\"style\": (\"color:#008599\" if isBeforeChange else \"color:#E90066\") })[0].text))\n",
      "IndexError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 27, in getCandidateBumeran\n",
      "    candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(soup.findAll(\"span\", {\"style\": (\"color:#008599\" if isBeforeChange else \"color:#E90066\") })[0].text))\n",
      "IndexError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 45, in getCandidateBumeran\n",
      "    mainDivTag = soup.find_all(\"div\", {\"style\": 'background-position-x:50%;background-position-y:100%'})[0]\n",
      "IndexError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 27, in getCandidateBumeran\n",
      "    candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(soup.findAll(\"span\", {\"style\": (\"color:#008599\" if isBeforeChange else \"color:#E90066\") })[0].text))\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ejecutivo-comercial\\Has recibido un CV para el aviso _Ejecutivo Comercial TI_(41).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 67, in _buffer_decode\n",
      "    raise UnicodeError(\"UTF-16 stream does not start with BOM\")\n",
      "UnicodeError: UTF-16 stream does not start with BOM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gestor-servicios-cloud\\Has recibido un CV para el aviso _Gestor de Servicios Cloud Jr._(14).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 67, in _buffer_decode\n",
      "    raise UnicodeError(\"UTF-16 stream does not start with BOM\")\n",
      "UnicodeError: UTF-16 stream does not start with BOM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gestor-servicios-cloud\\Has recibido un CV para el aviso _Gestor de Servicios Cloud_.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 67, in _buffer_decode\n",
      "    raise UnicodeError(\"UTF-16 stream does not start with BOM\")\n",
      "UnicodeError: UTF-16 stream does not start with BOM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jefe-proyecto\\Has recibido un CV para el aviso _Jefe de Proyecto TI_(21).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 61, in _buffer_decode\n",
      "    codecs.utf_16_ex_decode(input, errors, 0, final)\n",
      "UnicodeDecodeError: 'utf-16-le' codec can't decode bytes in position 70670-70671: illegal encoding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programador-net\\Has recibido un CV para el aviso _Programador .Net Senior_(4).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 34, in getCandidateBumeran\n",
      "    tagResidenceCountry = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")[2].text\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programador-net\\Has recibido un CV para el aviso _Programador .NET_(212).html\n",
      "\n",
      "programador-net\\Has recibido un CV para el aviso _Programador .NET_(212).html\n",
      "\n",
      "programador-net\\Has recibido un CV para el aviso _Programador .Net_(213).html\n",
      "\n",
      "programador-net\\Has recibido un CV para el aviso _Programador .Net_(213).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3301910123.py\", line 5, in getEncoding\n",
      "    encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 126306: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3301910123.py\", line 5, in getEncoding\n",
      "    encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 126316: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recursos-humanos\\Has recibido un CV para el aviso _Practicante de Recursos Humanos_(133).html\n",
      "\n",
      "recursos-humanos\\Has recibido un CV para el aviso _Practicante de Recursos Humanos_(136).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 61, in _buffer_decode\n",
      "    codecs.utf_16_ex_decode(input, errors, 0, final)\n",
      "UnicodeDecodeError: 'utf-16-le' codec can't decode bytes in position 65726-65727: illegal encoding\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 67, in _buffer_decode\n",
      "    raise UnicodeError(\"UTF-16 stream does not start with BOM\")\n",
      "UnicodeError: UTF-16 stream does not start with BOM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recursos-humanos\\Has recibido un CV para el aviso _Practicante de Recursos Humanos_(328).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 61, in _buffer_decode\n",
      "    codecs.utf_16_ex_decode(input, errors, 0, final)\n",
      "UnicodeDecodeError: 'utf-16-le' codec can't decode byte 0x0a in position 81680: truncated data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recursos-humanos\\Has recibido un CV para el aviso _Practicante de Recursos Humanos_(535).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 61, in _buffer_decode\n",
      "    codecs.utf_16_ex_decode(input, errors, 0, final)\n",
      "UnicodeDecodeError: 'utf-16-le' codec can't decode byte 0x0a in position 92420: truncated data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recursos-humanos\\Has recibido un CV para el aviso _Practicante de Recursos Humanos_(61).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\2750435797.py\", line 8, in getCandidateBumeran\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\utf_16.py\", line 61, in _buffer_decode\n",
      "    codecs.utf_16_ex_decode(input, errors, 0, final)\n",
      "UnicodeDecodeError: 'utf-16-le' codec can't decode byte 0x0a in position 78026: truncated data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se terminó de procesar Bumeran\n",
      "analista-calidad\\New application_ Analista de calidad from Wagner Fernandez Villaorduña.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 79, in getCandidateLinkedin\n",
      "    startDate = datetime.datetime.strptime(spanTag.split(\" - \")[0], \"%Y\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py\", line 568, in _strptime_datetime\n",
      "    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py\", line 349, in _strptime\n",
      "    raise ValueError(\"time data %r does not match format %r\" %\n",
      "ValueError: time data 'u' does not match format '%Y'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\G&S_ Spincorp, DWS Latinoamérica and BBVA Continental are looking for candidates like you..html\n",
      "\n",
      "bandeja-entrada\\New application_ .NET Developer from Cesar Ospino.html\n",
      "\n",
      "bandeja-entrada\\New application_ .NET Developer from Cesar Ospino.html\n",
      "\n",
      "bandeja-entrada\\New application_ .NET Developer from Cesar Ospino.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3301910123.py\", line 5, in getEncoding\n",
      "    encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 70047: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 7, in getCandidateLinkedin\n",
      "    encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 70047: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 23, in getCandidateLinkedin\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 41719: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\New application_ .NET Developer from Wilder Jesus Ramirez Huamaccto.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 67, in getCandidateLinkedin\n",
      "    candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[1])\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\New application_ Consultor Preventa Cloud (Azure) from María José Leiva Pereyra.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 79, in getCandidateLinkedin\n",
      "    startDate = datetime.datetime.strptime(spanTag.split(\" - \")[0], \"%Y\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py\", line 568, in _strptime_datetime\n",
      "    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py\", line 349, in _strptime\n",
      "    raise ValueError(\"time data %r does not match format %r\" %\n",
      "ValueError: time data '' does not match format '%Y'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\New application_ Desarrollador .NET from Cesar Ospino(3).html\n",
      "\n",
      "bandeja-entrada\\New application_ Desarrollador .NET from Cesar Ospino(3).html\n",
      "\n",
      "bandeja-entrada\\New application_ Desarrollador .NET from Cesar Ospino(3).html\n",
      "\n",
      "bandeja-entrada\\New application_ Desarrollador .NET from Cesar Ospino(4).html\n",
      "\n",
      "bandeja-entrada\\New application_ Desarrollador .NET from Cesar Ospino(4).html\n",
      "\n",
      "bandeja-entrada\\New application_ Desarrollador .NET from Cesar Ospino(4).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3301910123.py\", line 5, in getEncoding\n",
      "    encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 70088: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 7, in getCandidateLinkedin\n",
      "    encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 70088: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 23, in getCandidateLinkedin\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 41747: invalid start byte\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3301910123.py\", line 5, in getEncoding\n",
      "    encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 70695: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 7, in getCandidateLinkedin\n",
      "    encoding = 'windows-1252' if \"charset=windows-1252\" in f.read() else 'utf-16'\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 70695: character maps to <undefined>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 23, in getCandidateLinkedin\n",
      "    soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\codecs.py\", line 322, in decode\n",
      "    (result, consumed) = self._buffer_decode(data, self.errors, final)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 41747: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\New application_ Desarrollador .NET from Diana Ysabel Rodriguez Mendoza.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 163, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"color:#0A66C2;text-decoration:none;text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\New application_ Desarrollador .NET from Wilder Jesus Ramirez Huamaccto.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 67, in getCandidateLinkedin\n",
      "    candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[1])\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\New application_ Desarrollador Java from Cesar Miguel Illesca Cangalaya.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 67, in getCandidateLinkedin\n",
      "    candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[1])\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\New application_ Diseñador UX_UI from Julie Guillen ramos.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 79, in getCandidateLinkedin\n",
      "    startDate = datetime.datetime.strptime(spanTag.split(\" - \")[0], \"%Y\")\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py\", line 568, in _strptime_datetime\n",
      "    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n",
      "  File \"c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\_strptime.py\", line 349, in _strptime\n",
      "    raise ValueError(\"time data %r does not match format %r\" %\n",
      "ValueError: time data '' does not match format '%Y'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\New application_ Mobile Developer from gean angulo inchicaque.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 67, in getCandidateLinkedin\n",
      "    candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[1])\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\Your job post is live!(1).html\n",
      "\n",
      "bandeja-entrada\\Your job post is live!(10).html\n",
      "\n",
      "bandeja-entrada\\Your job post is live!(11).html\n",
      "\n",
      "bandeja-entrada\\Your job post is live!(2).html\n",
      "\n",
      "bandeja-entrada\\Your job post is live!(3).html\n",
      "\n",
      "bandeja-entrada\\Your job post is live!(4).html\n",
      "\n",
      "bandeja-entrada\\Your job post is live!(5).html\n",
      "\n",
      "bandeja-entrada\\Your job post is live!(6).html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandeja-entrada\\Your job post is live!(7).html\n",
      "\n",
      "bandeja-entrada\\Your job post is live!(8).html\n",
      "\n",
      "bandeja-entrada\\Your job post is live!(9).html\n",
      "\n",
      "bandeja-entrada\\Your job post is live!.html\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_5304\\3591020669.py\", line 38, in getCandidateLinkedin\n",
      "    candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
      "AttributeError: 'NoneType' object has no attribute 'text'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se terminó de procesar Linkedin\n",
      "Se terminó de unir la data principal\n",
      "Fin: 2023-05-10 01:44:02.253971\n",
      "Tiempo: 0:03:11.506573\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  startTime = datetime.datetime.now()\n",
    "  print(\"Inicio: \" + str(startTime))\n",
    "  print(\"Se inició el procesamiento\")\n",
    "\n",
    "  # El dataset principal que sea el de bumeran\n",
    "  # Los otros archivos que solo se usen para actualizar la variable objetivo\n",
    "  # Esto porque los otros orígenes están incompletos y costaría llenar los campos (incluso el excel que se hizo)\n",
    "  isLoadedBumeran = False\n",
    "  isLoadedLinkedin = False\n",
    "  isMergedMain = False\n",
    "  #False\n",
    "\n",
    "  # Leyendo archivos de entrada\n",
    "  bumeranData = readJson(os.path.join(intermFilesFolder, 'bumeran.json')) if isLoadedBumeran else readAndWriteMain('bumeran')\n",
    "  print(\"Se terminó de procesar Bumeran\")\n",
    "\n",
    "  linkedinData = readJson(os.path.join(intermFilesFolder, 'linkedin.json')) if isLoadedLinkedin else readAndWriteMain('linkedin')\n",
    "  print(\"Se terminó de procesar Linkedin\")\n",
    "\n",
    "  # Uniendo la data principal (bumeran + linkedin)\n",
    "  mergedMainData = readJson(os.path.join(mergedMainFolder, 'result.json')) if isMergedMain else readAndWriteMergedMain([bumeranData, linkedinData])\n",
    "  print(\"Se terminó de unir la data principal\")\n",
    "  \n",
    "  endTime = datetime.datetime.now()\n",
    "\n",
    "  print(\"Fin: \" + str(endTime))\n",
    "  print(\"Tiempo: \" + str(endTime-startTime))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
