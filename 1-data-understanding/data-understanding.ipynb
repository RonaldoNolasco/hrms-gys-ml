{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "6793a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "import datetime\n",
    "import traceback\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import jellyfish\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "125e31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "sourceDataFolder = \"1-source-data\"\n",
    "\n",
    "bumeraniterationNumber = \"4\"\n",
    "bumeranRootPath = sourceDataFolder + r\"\\main\\bumeran\\iteration-\" + bumeraniterationNumber\n",
    "\n",
    "linkediniterationNumber = \"2\"\n",
    "linkedinRootPath = sourceDataFolder + r\"\\main\\linkedin\\iteration-\" + linkediniterationNumber\n",
    "\n",
    "intermFilesFolder = \"2-intermediate-files\"\n",
    "mergedMainFolder = \"3-merged-main\"\n",
    "logsFolder = \"4-logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "85e41e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones utilitarias\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "\n",
    "def parseLineBreaksAndAccents(text):\n",
    "  return unidecode(\" \".join(text.split()))\n",
    "\n",
    "def parseNames(text):\n",
    "  return unidecode(text).strip().title()\n",
    "\n",
    "def findTags(tag, isBeforeChange):\n",
    "  return tag.find(\"span\", {\"style\": 'font-size:10.0pt;font-family:\"Arial\",sans-serif;mso-fareast-font-family:\\n\"Times New Roman\";color:' + ('#2192C9' if isBeforeChange else '#0A26EE') })\n",
    "\n",
    "def getChildIndex(mainChildTags, title, isBeforeChange):\n",
    "  return next((index for index, tag in enumerate(mainChildTags) if ( findTags(tag, isBeforeChange).text == title if findTags(tag, isBeforeChange) else False )), None)\n",
    "\n",
    "def readJson(path, encoding='utf-8', errors=None):\n",
    "  with open (path, \"r\", encoding=encoding, errors=errors) as f:\n",
    "    data = json.loads(f.read())\n",
    "  return data\n",
    "\n",
    "def writeJson(data, pathJson, encoding='utf-8'):\n",
    "  with open(pathJson, 'w', encoding=encoding) as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def writeCsv(data, pathCsv, encoding='utf-8'):\n",
    "  with open(pathCsv, 'w', newline='', encoding=encoding) as f:\n",
    "    if data:\n",
    "      writer = csv.DictWriter(f, fieldnames=data[0].keys(), lineterminator='\\n')\n",
    "      writer.writeheader()\n",
    "      writer.writerows(data)\n",
    "    else:\n",
    "      f.write(\"\")\n",
    "\n",
    "def writeTxt(data, pathTxt, encoding='utf-8'):\n",
    "  with open(pathTxt, 'w', encoding=encoding) as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "bbd47f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones principales\n",
    "def getFiles(rootPath):\n",
    "  # Obteniendo todas las carpetas de los perfiles\n",
    "  folders = [f for f in os.listdir(rootPath) if os.path.isdir(os.path.join(rootPath, f))]\n",
    "\n",
    "  # Definiendo la lista de archivos final\n",
    "  files = []\n",
    "\n",
    "  # Iterando sobre las carpetas\n",
    "  for folder in folders:\n",
    "    # Obteniendo los archivos por cada carpeta\n",
    "    folderFiles = [os.path.join(rootPath, folder, f) for f in os.listdir(os.path.join(rootPath, folder)) if os.path.isfile(os.path.join(rootPath, folder, f))]\n",
    "\n",
    "    # Agregando esos archivos a la lista de archivos final\n",
    "    files.extend(folderFiles)\n",
    "\n",
    "  # Filtros para considerar un archivo especifico\n",
    "  filterIsIn = [\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad_(76).html\"\n",
    "  ]\n",
    "  filesFilteredIsIn = [f for f in files if ( f in filterIsIn if filterIsIn else True )]\n",
    "\n",
    "  # Filtros para omitir un archivo especifico\n",
    "  filterIsNotIn = [\n",
    "    \n",
    "  ]\n",
    "  filesFilteredNotIn = [f for f in filesFilteredIsIn if ( f not in filterIsNotIn if filterIsNotIn else True )]\n",
    "\n",
    "  # Limites superiores e inferiores en la búsqueda de archivos\n",
    "  startLimit = None\n",
    "  topLimit = None\n",
    "  filesPartitioned = filesFilteredNotIn[(startLimit-1 if startLimit else 0): (topLimit if topLimit else len(files))]\n",
    "\n",
    "  return filesPartitioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "21425e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncodingBumeran(file, stringLog):\n",
    "  encoding = \"windows-1252\"\n",
    "  try:\n",
    "    with open(file, \"r\", encoding=\"utf-16-le\") as f:\n",
    "      if \"charset=unicode\" in f.read():\n",
    "        encoding = 'utf-16-le'\n",
    "      else:\n",
    "        raise Exception\n",
    "  except Exception as e:\n",
    "    try:\n",
    "      with open(file, \"r\", encoding=\"windows-1252\") as f:\n",
    "        if \"charset=windows-1252\" in f.read():\n",
    "          encoding = 'windows-1252'\n",
    "        else:\n",
    "          encoding = encoding\n",
    "    except Exception as e:\n",
    "      print(file)\n",
    "      stringLog = stringLog + file + \"\\n\"\n",
    "      traceback.print_exc()\n",
    "      stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "      print()\n",
    "      stringLog = stringLog + \"\\n\"\n",
    "      pass\n",
    "      \n",
    "  return encoding, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c06d9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncodingLinkedin(file, stringLog):\n",
    "  encoding = \"windows-1256\"\n",
    "  try:\n",
    "    with open(file, \"r\", encoding=\"utf-16-le\") as f:\n",
    "      if \"charset=unicode\" in f.read():\n",
    "        encoding = 'utf-16-le'\n",
    "      else:\n",
    "        raise Exception\n",
    "  except Exception as e:\n",
    "    try:\n",
    "      with open(file, \"r\", encoding=\"windows-1256\") as f:\n",
    "        if \"charset=windows-1256\" in f.read():\n",
    "          encoding = 'windows-1256'\n",
    "        else:\n",
    "          encoding = encoding\n",
    "    except Exception as e:\n",
    "      print(file)\n",
    "      stringLog = stringLog + file + \"\\n\"\n",
    "      traceback.print_exc()\n",
    "      stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "      print()\n",
    "      stringLog = stringLog + \"\\n\"\n",
    "      pass\n",
    "      \n",
    "  return encoding, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c6d1455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidateBumeran(file, encoding, stringLog):\n",
    "  candidateData = {}\n",
    " \n",
    "  try:\n",
    "  # Abriendo el archivo\n",
    "    with open(file, \"r\", encoding=encoding) as myFile:\n",
    "      #Parseando el archivo html a soup\n",
    "      soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
    "\n",
    "      # Obteniendo cada uno de los campos para la data\n",
    "\n",
    "      # Id del postulante\n",
    "      #candidateData[\"id\"] = str(index + 1)\n",
    "\n",
    "      # Fecha de postulación\n",
    "      rawPostulationDate = soup.find_all(\"span\", {\"style\": \"color:black\"})[3].text\n",
    "      postulationDate = datetime.datetime.strptime(rawPostulationDate, \"%A, %B %d, %Y %I:%M %p\")\n",
    "      candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "      # Definiendo los colores a usar para las búsquedas según las fechas\n",
    "      isBeforeChange = True if (postulationDate <= datetime.datetime(2020,6,11,12,5,0)) else False\n",
    "      # Linkedin comenzo a usarse en 22/04/25 23:06\n",
    "      # El primer punto de inflexión es 22/09/23 02:15\n",
    "      # El otro no tiene fecha definida, cambia muy poco el diseño pero agrega lo de adquirir más candidatos\n",
    "\n",
    "      # Nombre del perfil\n",
    "      candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(soup.findAll(\"span\", {\"style\": (\"color:#008599\" if isBeforeChange else \"color:#E90066\") })[0].text))\n",
    "\n",
    "      # Nombre del postulante\n",
    "      rawcandidateName = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")[0].text # El split join tambien quita saltos de línea\n",
    "      candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(rawcandidateName))\n",
    "\n",
    "      # Pais de residencia\n",
    "      tagResidenceCountry = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")[2].text\n",
    "      if tagResidenceCountry.find(\",\") == -1:\n",
    "        candidateData[\"residenceCountry\"] = \"\"\n",
    "      else:\n",
    "        rawResidenceCountry = tagResidenceCountry[0:tagResidenceCountry.find(\",\")]\n",
    "        candidateData[\"residenceCountry\"] = parseNames(parseLineBreaksAndAccents(rawResidenceCountry))\n",
    "\n",
    "      # Canal\n",
    "      candidateData[\"channel\"] = \"Bumeran\"\n",
    "\n",
    "      # Obteniendo todas las etiquetas principales\n",
    "      mainDivTag = soup.find_all(\"div\", {\"style\": 'background-position-x:50%;background-position-y:100%'})[0]\n",
    "      mainChildTags = mainDivTag.find_all(recursive=False)\n",
    "\n",
    "      # Experiencia laboral\n",
    "      workExperienceIndex = getChildIndex(mainChildTags, \"Experiencia laboral\", isBeforeChange)\n",
    "      educationIndex = getChildIndex(mainChildTags, \"Educación\", isBeforeChange)\n",
    "\n",
    "      if workExperienceIndex and educationIndex:\n",
    "        workExperienceTags = mainChildTags[workExperienceIndex+2:educationIndex]\n",
    "        candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(workExperienceTags[0].find_all(\"b\")[0].text))\n",
    "        candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(workExperienceTags[1].find_all(\"b\")[0].text))\n",
    "\n",
    "        # Hay un caso que tiene span ya de por si en las experiencias laborales, el html 22, revisar\n",
    "        daysOfExperience = 0\n",
    "        for index in range(0, len(workExperienceTags), 2):\n",
    "          startDate = datetime.datetime.strptime(parseLineBreaksAndAccents(workExperienceTags[index].text)[0: parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" - \")] , \"%d-%m-%Y\")\n",
    "          endDateText = parseLineBreaksAndAccents(workExperienceTags[index].text)[parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" - \")+3: parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" | \")]\n",
    "          endDate = datetime.datetime.strptime(endDateText, \"%d-%m-%Y\") if endDateText != \"Presente\" else datetime.datetime.strptime(rawPostulationDate, \"%A, %B %d, %Y %I:%M %p\")\n",
    "          daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "        candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "        candidateData[\"worksNumber\"] = int(len(workExperienceTags)/2)\n",
    "      else:\n",
    "        candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "        candidateData[\"yearsOfExperience\"] = 0\n",
    "        candidateData[\"worksNumber\"] = 0\n",
    "\n",
    "      # Carrera profesional (última alcanzada)\n",
    "      educationIndex = getChildIndex(mainChildTags, \"Educación\", isBeforeChange)\n",
    "      informaticsIndex = getChildIndex(mainChildTags, \"Informática\", isBeforeChange)\n",
    "\n",
    "      if educationIndex and informaticsIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        educationTags = mainChildTags[educationIndex+2:informaticsIndex]\n",
    "\n",
    "        boldTags0 = educationTags[0].find_all(\"b\")\n",
    "        if len(boldTags0) == 0:\n",
    "          candidateData[\"studyCenter\"] = \"\"\n",
    "          candidateData[\"careerField\"] = \"\"\n",
    "        elif len(boldTags0) == 1:\n",
    "          #print(\"GA\")\n",
    "          if (parseLineBreaksAndAccents(educationTags[0].text).find(\",\") - parseLineBreaksAndAccents(educationTags[0].text).find(\" | \") == 3):\n",
    "            candidateData[\"studyCenter\"] = \"\"\n",
    "            candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "          else:\n",
    "            candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "            candidateData[\"careerField\"] = \"\"\n",
    "        else:\n",
    "          #print(\"AG\")\n",
    "          #print(educationTags[0].find_all(\"b\")[0])\n",
    "          candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "          candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(boldTags0[1].text.strip()))\n",
    "        \n",
    "        haveBoldTags1 = True if len(educationTags[1].find_all(\"b\")) > 0 else False\n",
    "        #if len(boldTags1) == 1:\n",
    "        tempTags = educationTags[1].find_all(\"span\")\n",
    "        #print(tempTags[1:])\n",
    "        statusDegreeIndex = next(((index+1 if haveBoldTags1 else index) for index, x in enumerate( tempTags[1:] if haveBoldTags1 else tempTags ) if \",\" in x.text), None)\n",
    "        #print([x.text for index, x in enumerate(tempTags[1:])])\n",
    "        #print(statusDegreeIndex)\n",
    "        \n",
    "        if statusDegreeIndex is not None:\n",
    "          candidateData[\"careerStatus\"] = parseNames(parseLineBreaksAndAccents(educationTags[1].find_all(\"span\")[statusDegreeIndex].text.split(\",\")[1].strip()))\n",
    "          candidateData[\"careerDegree\"] = parseNames(parseLineBreaksAndAccents(educationTags[1].find_all(\"span\")[statusDegreeIndex].text.split(\",\")[2].strip()[:-1]))\n",
    "          candidateData[\"studiesNumber\"] = int(len(educationTags)/2)\n",
    "        else:\n",
    "          candidateData[\"careerStatus\"] = candidateData[\"careerDegree\"] = \"\"\n",
    "          candidateData[\"studiesNumber\"] = 0\n",
    "      else:\n",
    "        candidateData[\"studyCenter\"] = candidateData[\"careerField\"] = candidateData[\"careerStatus\"] = candidateData[\"careerDegree\"] = \"\"\n",
    "        candidateData[\"studiesNumber\"] = 0\n",
    "      #print(file)\n",
    "      #print(candidateData[\"careerStatus\"])\n",
    "      #print(candidateData[\"careerDegree\"])\n",
    "      #print()\n",
    "\n",
    "      # Habilidades técnicas\n",
    "      informaticsIndex = getChildIndex(mainChildTags, \"Informática\", isBeforeChange)\n",
    "      languageIndex = getChildIndex(mainChildTags, \"Idiomas\", isBeforeChange)\n",
    "\n",
    "      if informaticsIndex and languageIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        technicalSkillsTags = mainChildTags[informaticsIndex+2:languageIndex][0].find_all(\"span\")\n",
    "        candidateData[\"technicalSkills\"] = int(len(technicalSkillsTags)/4)\n",
    "\n",
    "      else:\n",
    "        candidateData[\"technicalSkills\"] = 0\n",
    "\n",
    "      # Falta habilidades blandas\n",
    "\n",
    "      # Lenguajes\n",
    "      languageIndex = getChildIndex(mainChildTags, \"Idiomas\", isBeforeChange)\n",
    "      otherKnowledgesIndex = getChildIndex(mainChildTags, \"Otros Conocimientos\", isBeforeChange)\n",
    "\n",
    "      if languageIndex and otherKnowledgesIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        languagesTags = mainChildTags[languageIndex+2:otherKnowledgesIndex][0].find_all(\"span\")\n",
    "        candidateData[\"languages\"] = int(len(languagesTags)/7)\n",
    "\n",
    "      else:\n",
    "        candidateData[\"languages\"] = 1\n",
    "\n",
    "      # Otros conocimientos\n",
    "      otherKnowledgesIndex = getChildIndex(mainChildTags, \"Otros Conocimientos\", isBeforeChange)\n",
    "      endIndex = len(mainChildTags)-1\n",
    "\n",
    "      if languageIndex and otherKnowledgesIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        otherKnowledgesTags = mainChildTags[otherKnowledgesIndex+2:endIndex][0].find_all(\"span\")\n",
    "        candidateData[\"anotherSkills\"] = int(len(otherKnowledgesTags)/3)\n",
    "      else:\n",
    "        candidateData[\"anotherSkills\"] = 0\n",
    "\n",
    "      candidateData[\"references\"] = 0\n",
    "\n",
    "      # Salario pretendido\n",
    "      tagsSalary = [index for index, tag in enumerate(soup.find_all(\"span\")) if \"Sueldo pretendido\" in tag.text]\n",
    "      if len(tagsSalary) > 0:\n",
    "        rawSalary = soup.find_all(\"span\")[tagsSalary[0]+1].text\n",
    "        candidateData[\"salary\"] = int(float(parseLineBreaksAndAccents(\" \".join(rawSalary.split()))[1:].title()))\n",
    "      else:\n",
    "        candidateData[\"salary\"] = 0\n",
    "\n",
    "  except Exception as e:\n",
    "    candidateData = {}\n",
    "    print(file)\n",
    "    stringLog = stringLog + str(file) + \"\\n\"\n",
    "    traceback.print_exc()\n",
    "    stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "    print()\n",
    "    stringLog = stringLog + \"\\n\"\n",
    "    pass\n",
    "\n",
    "  return candidateData, stringLog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "54cef587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidateLinkedin(file, encoding, stringLog):\n",
    "  candidateData = {}\n",
    "\n",
    "  try:\n",
    "  # Abriendo el archivo\n",
    "    with open(file, \"r\", encoding=encoding) as myFile:\n",
    "      #Parseando el archivo html a soup\n",
    "      \n",
    "      soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
    "\n",
    "      rawPostulationDate = soup.find_all(\"span\", {\"style\": \"color:black\"})[3].text\n",
    "      postulationDate = datetime.datetime.strptime(rawPostulationDate, \"%A, %B %d, %Y %I:%M %p\")\n",
    "\n",
    "      rawProfileName = parseLineBreaksAndAccents(soup.find_all(\"span\", {\"style\": \"color:black\"})[7].text)\n",
    "      startIndexProfileName = rawProfileName.find(\": \")\n",
    "      endIndexProfileName = rawProfileName.find(\" from \")\n",
    "\n",
    "      if postulationDate <= datetime.datetime(2022,9,23,2,15,0):\n",
    "        \n",
    "        candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(rawProfileName[startIndexProfileName+1:endIndexProfileName]))\n",
    "\n",
    "        candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
    "\n",
    "        tempSpanTags = soup.find_all(\"span\", {\"style\": 'font-size:9.0pt;font-family:\\n            \"Helvetica\",sans-serif;color:#737373'})\n",
    "        existsCountry = True if len(tempSpanTags) > 1 else False\n",
    "        candidateData[\"residenceCountry\"] = parseNames(parseLineBreaksAndAccents(tempSpanTags[len(tempSpanTags)-1].text)) if existsCountry else \"\"\n",
    "\n",
    "        candidateData[\"channel\"] = \"Linkedin\"\n",
    "\n",
    "        tableTags = soup.find_all(\"table\")\n",
    "\n",
    "        notHaveScreening = True if \"Screening qualifications\" not in str(soup) else False\n",
    "        startTag = 15 if notHaveScreening else 16\n",
    "        endTag = len(tableTags)-3\n",
    "        findedTableTags = tableTags[startTag:endTag]\n",
    "\n",
    "        haveTags = [None, None, None, None, None]\n",
    "\n",
    "        for index, tag in enumerate(findedTableTags):\n",
    "          haveTags[0] = index if \"Current experience\" in tag.text else haveTags[0]\n",
    "          haveTags[1] = index if \"Past experience\" in tag.text else haveTags[1]\n",
    "          haveTags[2] = index if \"Education\" in tag.text else haveTags[2]\n",
    "          haveTags[3] = index if \"Skills matching your job\" in tag.text else haveTags[3]\n",
    "          haveTags[4] = index if \"Highlight\" in tag.text else haveTags[4]\n",
    "\n",
    "        for index, haveTag in enumerate(haveTags):\n",
    "          if index == 0:\n",
    "            if haveTag is not None:\n",
    "              #spanTags = findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\") Caso particular que no vale la pena\n",
    "              #startSpanIndex = 0 if len(spanTags) == 2 else len(spanTags)-3\n",
    "              candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[1])\n",
    "              candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[0])\n",
    "            else:\n",
    "              candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "          \n",
    "          elif index == 1:\n",
    "            if haveTag is not None:\n",
    "              daysOfExperience = 0\n",
    "              trTag = findedTableTags[haveTag].find_all(\"tr\")[1]\n",
    "              pTags = trTag.find_all(\"p\")\n",
    "              for pTag in pTags:\n",
    "                spanTag = parseLineBreaksAndAccents(pTag.find_all(\"span\")[1].text)\n",
    "                startDate = datetime.datetime.strptime(spanTag.split(\" - \")[0], \"%Y\")\n",
    "                endDate = datetime.datetime.strptime(spanTag.split(\" - \")[1], \"%Y\")\n",
    "                daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "              candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "              candidateData[\"worksNumber\"] = int(len(pTags))\n",
    "            else:\n",
    "              candidateData[\"yearsOfExperience\"] = 0\n",
    "              candidateData[\"worksNumber\"] = 0\n",
    "\n",
    "          elif index == 2:\n",
    "            # No se tiene el careerStatus en linkedin\n",
    "            if haveTag is not None:\n",
    "              trTags = findedTableTags[haveTag].find_all(\"tr\")[1:]\n",
    "              #print(trTags[0])\n",
    "              firstCenterWithDateIndex = -1\n",
    "              studiesNumber = 0\n",
    "              for index, trTag in enumerate(trTags):\n",
    "                if(len(trTag.find_all(\"span\"))>1):\n",
    "                  if(len(trTags[index-1].find_all(\"span\")) == 1):\n",
    "                    if firstCenterWithDateIndex == -1:\n",
    "                      firstCenterWithDateIndex = index-1\n",
    "                if(len(trTag.find_all(\"span\"))==1):\n",
    "                  studiesNumber = studiesNumber + 1\n",
    "              \n",
    "              #print(firstCenterWithDateIndex)\n",
    "              #print(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \")[1])\n",
    "              #print(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \"))\n",
    "              #print(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \")[1]))\n",
    "\n",
    "              if firstCenterWithDateIndex != -1:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex].text))\n",
    "                tempTagArray = trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")\n",
    "                candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")[1])) if len(tempTagArray) > 1 else \"\"\n",
    "                candidateData[\"careerStatus\"] = \"En Curso\" if (\"Present\" in parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[1].text)) else \"Graduado\"\n",
    "                tempText = parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")[0])\n",
    "                candidateData[\"careerDegree\"] = parseNames(tempText) if not tempText[0:4].isnumeric() else \"\"\n",
    "              else:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[0].text))\n",
    "                candidateData[\"careerField\"] = \"\"\n",
    "                candidateData[\"careerStatus\"] = \"\"\n",
    "                candidateData[\"careerDegree\"] = \"\"\n",
    "              \n",
    "              candidateData[\"studiesNumber\"] = studiesNumber\n",
    "            else:\n",
    "              candidateData[\"studyCenter\"] = \"\"\n",
    "              candidateData[\"careerField\"] = \"\"\n",
    "              candidateData[\"careerStatus\"] = \"\"\n",
    "              candidateData[\"careerDegree\"] = \"\"\n",
    "              candidateData[\"studiesNumber\"] = 0\n",
    "          elif index == 3:\n",
    "            if haveTag is not None:\n",
    "              skillsCounter = 0\n",
    "              spanTags = findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")\n",
    "              for spanTag in spanTags:\n",
    "                if \"\".join(spanTag[\"style\"].split()) == 'font-size:10.5pt;font-family:\"Helvetica\",sans-serif;mso-fareast-font-family:\"TimesNewRoman\";color:#4D4D4D':\n",
    "                  skillsCounter = skillsCounter + 1\n",
    "              \n",
    "              candidateData[\"technicalSkills\"] = skillsCounter\n",
    "            else:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "            \n",
    "            candidateData[\"languages\"] = 1\n",
    "            candidateData[\"anotherSkills\"] = 0 if notHaveScreening else int(parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text)[parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text).find(\": \")+2: parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text).find(\"/\")])\n",
    "          elif index == 4:\n",
    "            if haveTag is not None:\n",
    "              highlightText = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)\n",
    "              isKnows = True if (\"knows\" in highlightText) else False\n",
    "              #print(isKnows)\n",
    "              isMoreThanTwo = True if (\"others\" in highlightText) else False\n",
    "              if isKnows and isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" and \")+5:highlightText.find(\" others \")])\n",
    "              elif isKnows and not isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText.count(\" and \") + 1)\n",
    "              else:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" hired \")+7:highlightText.find(\" people \")])\n",
    "            else:\n",
    "              candidateData[\"references\"] = 0\n",
    "        candidateData[\"salary\"] = 0\n",
    "        \n",
    "      else:\n",
    "        candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(rawProfileName[startIndexProfileName+1:endIndexProfileName]))\n",
    "\n",
    "        candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"color:#0A66C2;text-decoration:none;text-underline:none\"}).text))\n",
    "        \n",
    "        tempSpanTags = soup.find_all(\"span\", {\"style\": 'font-size:10.5pt;font-family:\"Helvetica\",sans-serif;\\n          color:#737373'})\n",
    "        existsCountry = True if len(tempSpanTags) > 1 else False\n",
    "        candidateData[\"residenceCountry\"] = parseNames(parseLineBreaksAndAccents(tempSpanTags[len(tempSpanTags)-1].text)) if existsCountry else \"\"\n",
    "\n",
    "        candidateData[\"channel\"] = \"Linkedin\"\n",
    "\n",
    "        tableTags = soup.find_all(\"table\")\n",
    "\n",
    "        startTag = 14\n",
    "        endTag = len(tableTags)-3\n",
    "        findedTableTags = tableTags[startTag:endTag]\n",
    "\n",
    "        haveTags = [None, None, None, None, None]\n",
    "\n",
    "        for index, tag in enumerate(findedTableTags):\n",
    "          haveTags[0] = index if \"Current experience\" in tag.text else haveTags[0]\n",
    "          haveTags[1] = index if \"Past experience\" in tag.text else haveTags[1]\n",
    "          haveTags[2] = index if \"Education\" in tag.text else haveTags[2]\n",
    "          haveTags[3] = index if \"Screening qualifications\" in tag.text else haveTags[3]\n",
    "          haveTags[4] = index if \"Highlight\" in tag.text else haveTags[4]\n",
    "        \n",
    "        for index, haveTag in enumerate(haveTags):\n",
    "          if index == 0:\n",
    "            if haveTag is not None:\n",
    "              tempTrTags = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")\n",
    "              #print(tempTrTags[1].find_all(\"span\")[0].text)\n",
    "              tempWorkCenter = tempTrTags[1] if len(tempTrTags) > 1 else \"\"\n",
    "              candidateData[\"lastWorkCenter\"] = parseNames(tempWorkCenter[0:tempWorkCenter.rfind(\" - \")-4]) if tempWorkCenter != \"\" else \"\"\n",
    "              candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[0])\n",
    "            else:\n",
    "              candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "          \n",
    "          elif index == 1:\n",
    "            if haveTag is not None:\n",
    "              daysOfExperience = 0\n",
    "              trTags = [x for x in findedTableTags[haveTag].find_all(\"tr\") if x.find(\"span\", {\"style\": 'font-size:9.0pt;font-family:\"Helvetica\",sans-serif;\\n          color:#737373'})]\n",
    "              #print(trTags)\n",
    "              for trTag in trTags:\n",
    "                #print(pTag.text)\n",
    "                spanTag = parseLineBreaksAndAccents(trTag.find_all(\"span\")[0].text)\n",
    "                #print(spanTag)\n",
    "                #print(\"\".isnumeric())\n",
    "                if spanTag[spanTag.rfind(\" - \")-4:spanTag.rfind(\" - \")].isnumeric() and spanTag[spanTag.rfind(\" - \")+3:spanTag.rfind(\" - \")+7].isnumeric():\n",
    "                  startDate = datetime.datetime.strptime(spanTag[spanTag.rfind(\" - \")-4:spanTag.rfind(\" - \")], \"%Y\")\n",
    "                  endDate = datetime.datetime.strptime(spanTag[spanTag.rfind(\" - \")+3:spanTag.rfind(\" - \")+7], \"%Y\")\n",
    "                  daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "              candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "              candidateData[\"worksNumber\"] = int(len(trTags))\n",
    "            else:\n",
    "              candidateData[\"yearsOfExperience\"] = 0\n",
    "              candidateData[\"worksNumber\"] = 0\n",
    "\n",
    "          elif index == 2:\n",
    "            # No se tiene el careerStatus en linkedin\n",
    "            if haveTag is not None:\n",
    "              trTags = findedTableTags[haveTag].find_all(\"tr\")[1:]\n",
    "              #print(trTags[0])\n",
    "              firstCenterWithDateIndex = -1\n",
    "              studiesNumber = 0\n",
    "              for index, trTag in enumerate(trTags):\n",
    "                if \" - \" in parseLineBreaksAndAccents(trTag.text):\n",
    "                  if \" - \" not in parseLineBreaksAndAccents(trTags[index-1].text):\n",
    "                    if firstCenterWithDateIndex == -1:\n",
    "                      firstCenterWithDateIndex = index-1\n",
    "                if(\" - \" not in parseLineBreaksAndAccents(trTag.text)):\n",
    "                  studiesNumber = studiesNumber + 1\n",
    "              #print(firstCenterWithDateIndex)\n",
    "              if firstCenterWithDateIndex != -1:\n",
    "                #print(\"GA\")\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex].text))\n",
    "                tempTagArray = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find(\"span\").text))\n",
    "                candidateData[\"careerField\"] = parseNames(tempTagArray[tempTagArray.find(\", \")+1:tempTagArray.rfind(\" - \")-4])\n",
    "                candidateData[\"careerStatus\"] = \"En Curso\" if (\"Present\" in tempTagArray) else \"Graduado\"\n",
    "                candidateData[\"careerDegree\"] = parseNames(tempTagArray[0:tempTagArray.find(\", \")]) if tempTagArray.find(\", \") != -1 else \"\"\n",
    "                #print(candidateData)\n",
    "              else:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[0].text))\n",
    "                candidateData[\"careerField\"] = \"\"\n",
    "                candidateData[\"careerStatus\"] = \"\"\n",
    "                candidateData[\"careerDegree\"] = \"\"\n",
    "              \n",
    "              candidateData[\"studiesNumber\"] = studiesNumber\n",
    "            else:\n",
    "              candidateData[\"studyCenter\"] = \"\"\n",
    "              candidateData[\"careerField\"] = \"\"\n",
    "              candidateData[\"careerStatus\"] = \"\"\n",
    "              candidateData[\"careerDegree\"] = \"\"\n",
    "              candidateData[\"studiesNumber\"] = 0\n",
    "          \n",
    "          elif index == 3:\n",
    "            if haveTag is not None:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "              candidateData[\"languages\"] = 1\n",
    "              candidateData[\"anotherSkills\"] = int(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)[0])\n",
    "            else:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "              candidateData[\"languages\"] = 1\n",
    "              candidateData[\"anotherSkills\"] = 0\n",
    "            \n",
    "          elif index == 4:\n",
    "            if haveTag is not None:\n",
    "              highlightText = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)\n",
    "              #print(highlightText)\n",
    "              isKnows = True if (\"knows\" in highlightText) else False\n",
    "              #print(isKnows)\n",
    "              isMoreThanTwo = True if (\"others\" in highlightText) else False\n",
    "              if isKnows and isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" and \")+5:highlightText.find(\" others \")])\n",
    "              elif isKnows and not isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText.count(\" and \") + 1)\n",
    "              else:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" hired \")+7:highlightText.find(\" people \")])\n",
    "            else:\n",
    "              candidateData[\"references\"] = 0\n",
    "        candidateData[\"salary\"] = 0\n",
    "      \n",
    "  except Exception as e:\n",
    "    candidateData = {}\n",
    "    print(file)\n",
    "    stringLog = stringLog + str(file) + \"\\n\"\n",
    "    traceback.print_exc()\n",
    "    stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "    print()\n",
    "    stringLog = stringLog + \"\\n\"\n",
    "    pass\n",
    "  \n",
    "  return candidateData, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "1799b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateFiles(files, source):\n",
    "  # Definiendo el log de errores\n",
    "  stringLog = \"\"\n",
    "\n",
    "  # Definiendo la data final de candidatos\n",
    "  data = []\n",
    "  \n",
    "  # Iterando por cada archivo\n",
    "  for file in files:\n",
    "    # Obteniendo el encoding por cada archivo\n",
    "    encoding, stringLog = getEncodingBumeran(file, stringLog) if source == 'bumeran' else getEncodingLinkedin(file, stringLog)\n",
    "\n",
    "    # Obteniendo los datos por cada archivo\n",
    "    candidate, stringLog = getCandidateBumeran(file, encoding, stringLog) if source == 'bumeran' else getCandidateLinkedin(file, encoding, stringLog)\n",
    "    \n",
    "    # Añadiendo los datos del candidato a la data final\n",
    "    if (candidate):\n",
    "      data.append(candidate)\n",
    "\n",
    "  return data, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "472c3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndWriteMain(source):\n",
    "  # Definiendo la carpeta raiz de los archivos a buscar, según el origen\n",
    "  rootPath = bumeranRootPath if source == \"bumeran\" else linkedinRootPath\n",
    "\n",
    "  # Obteniendo la lista de archivos, según el origen\n",
    "  files = getFiles(rootPath)\n",
    "\n",
    "  # Iterando sobre los archivos, calculando la data y el log de error\n",
    "  data, stringLog = iterateFiles(files, source)\n",
    "\n",
    "  # Escribiendo la data de los candidatos (json y csv)\n",
    "  writeJson(data, os.path.join(intermFilesFolder, source + '.json'))\n",
    "  writeCsv(data, os.path.join(intermFilesFolder, source + '.csv'))\n",
    "\n",
    "  # Escribiendo el log de errores\n",
    "  writeTxt(stringLog, os.path.join(logsFolder, source, datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".txt\"), 'utf-16')\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "a8528b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndWriteMergedMain(mainData):\n",
    "  mainMergeddata = []\n",
    "  for elem in mainData:\n",
    "    mainMergeddata.extend(elem)\n",
    "\n",
    "  writeJson(mainMergeddata, os.path.join(mergedMainFolder, \"result.json\"), 'utf-8')\n",
    "  writeCsv(mainMergeddata, os.path.join(mergedMainFolder, \"result.csv\"), 'utf-8')\n",
    "\n",
    "  return mainMergeddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "c9021c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio: 2023-05-10 03:39:16.342546\n",
      "Se inició el procesamiento\n",
      "Se terminó de procesar Bumeran\n",
      "Ga\n",
      "Ga\n",
      "Ga\n",
      "2459\n",
      "3\n",
      "Se terminó de procesar Linkedin\n",
      "Se terminó de unir la data principal\n",
      "Fin: 2023-05-10 03:39:16.924858\n",
      "Tiempo: 0:00:00.582312\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  # Definiendo el inicio del proceso\n",
    "  startTime = datetime.datetime.now()\n",
    "  print(\"Inicio: \" + str(startTime))\n",
    "  print(\"Se inició el procesamiento\")\n",
    "\n",
    "  # El dataset principal que sea el de bumeran\n",
    "  # Los otros archivos que solo se usen para actualizar la variable objetivo\n",
    "  # Esto porque los otros orígenes están incompletos y costaría llenar los campos (incluso el excel que se hizo)\n",
    "  isLoadedBumeran = False\n",
    "  isLoadedLinkedin = True\n",
    "  isMergedMain = True\n",
    "  #False\n",
    "\n",
    "  # Leyendo o calculando bumeran\n",
    "  bumeranData = readJson(os.path.join(intermFilesFolder, 'bumeran.json')) if isLoadedBumeran else readAndWriteMain('bumeran')\n",
    "  print(\"Se terminó de procesar Bumeran\")\n",
    "\n",
    "  # Leyendo o calculando linkedin\n",
    "  linkedinData = readJson(os.path.join(intermFilesFolder, 'linkedin.json')) if isLoadedLinkedin else readAndWriteMain('linkedin')\n",
    "  print(\"Se terminó de procesar Linkedin\")\n",
    "\n",
    "  # Uniendo la data principal (bumeran + linkedin)\n",
    "  mergedMainData = readJson(os.path.join(mergedMainFolder, 'result.json')) if isMergedMain else readAndWriteMergedMain([bumeranData, linkedinData])\n",
    "  print(\"Se terminó de unir la data principal\")\n",
    "  \n",
    "  # Definiendo el fin del proceso\n",
    "  endTime = datetime.datetime.now()\n",
    "  print(\"Fin: \" + str(endTime))\n",
    "  print(\"Tiempo: \" + str(endTime-startTime))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
