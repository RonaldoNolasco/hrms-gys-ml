{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "6793a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "import datetime\n",
    "import traceback\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import jellyfish\n",
    "from collections import OrderedDict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "125e31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "sourceDataFolder = \"1-source-data\"\n",
    "\n",
    "bumeraniterationNumber = \"4\"\n",
    "bumeranRootPath = sourceDataFolder + r\"\\main\\bumeran\\iteration-\" + bumeraniterationNumber\n",
    "\n",
    "linkediniterationNumber = \"2\"\n",
    "linkedinRootPath = sourceDataFolder + r\"\\main\\linkedin\\iteration-\" + linkediniterationNumber\n",
    "\n",
    "intermFilesFolder = \"2-intermediate-files\"\n",
    "mergedMainFolder = \"3-merged-main\"\n",
    "logsFolder = \"4-logs\"\n",
    "\n",
    "dataVisualizationTopLimit = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "85e41e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones utilitarias\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "\n",
    "def parseLineBreaksAndAccents(text):\n",
    "  return unidecode(\" \".join(text.split()))\n",
    "\n",
    "def parseNames(text):\n",
    "  return text.strip().title()\n",
    "\n",
    "def findTags(tag, color):\n",
    "  return tag.find(\"span\", {\"style\": 'font-size:10.0pt;font-family:\"Arial\",sans-serif;mso-fareast-font-family:\\n\"Times New Roman\";color:' + color })\n",
    "\n",
    "def getChildIndex(mainChildTags, title, color):\n",
    "  return next((index for index, tag in enumerate(mainChildTags) if ( findTags(tag, color).text == title if findTags(tag, color) else False )), None)\n",
    "\n",
    "def getSectionsIndexes(mainChildTags, color):\n",
    "  sectionsIndexes = []\n",
    "  sectionsTitle = [\"Experiencia laboral\", \"Educación\", \"Informática\", \"Idiomas\", \"Otros Conocimientos\"]\n",
    "  for sectionTitle in sectionsTitle:\n",
    "    sectionIndex = getChildIndex(mainChildTags, sectionTitle, color)\n",
    "    sectionsIndexes.append(sectionIndex)\n",
    "  \n",
    "  sectionsIndexes.append(len(mainChildTags)-1)\n",
    "  return sectionsIndexes\n",
    "\n",
    "def getNextSectionIndexValid(sectionsIndexes, i):\n",
    "  while(not sectionsIndexes[i]):\n",
    "    i = i + 1\n",
    "\n",
    "  return sectionsIndexes[i]\n",
    "\n",
    "\n",
    "def readJson(path, encoding='utf-8', errors=None):\n",
    "  with open (path, \"r\", encoding=encoding, errors=errors) as f:\n",
    "    data = json.loads(f.read())\n",
    "  return data\n",
    "\n",
    "def writeJson(data, pathJson, encoding='utf-8'):\n",
    "  with open(pathJson, 'w', encoding=encoding) as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def writeCsv(data, pathCsv, encoding='utf-8'):\n",
    "  with open(pathCsv, 'w', newline='', encoding=encoding) as f:\n",
    "    if data:\n",
    "      writer = csv.DictWriter(f, fieldnames=data[0].keys(), lineterminator='\\n')\n",
    "      writer.writeheader()\n",
    "      writer.writerows(data)\n",
    "    else:\n",
    "      f.write(\"\")\n",
    "\n",
    "def writeTxt(data, pathTxt, encoding='utf-8'):\n",
    "  with open(pathTxt, 'w', encoding=encoding) as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "bbd47f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones principales\n",
    "def getFiles(rootPath, source):\n",
    "  # Obteniendo todas las carpetas de los perfiles\n",
    "  folders = [f for f in os.listdir(rootPath) if os.path.isdir(os.path.join(rootPath, f))]\n",
    "\n",
    "  # Definiendo la lista de archivos final\n",
    "  files = []\n",
    "\n",
    "  # Iterando sobre las carpetas\n",
    "  for folder in folders:\n",
    "    # Obteniendo los archivos por cada carpeta\n",
    "    folderFiles = [os.path.join(rootPath, folder, f) for f in os.listdir(os.path.join(rootPath, folder)) if os.path.isfile(os.path.join(rootPath, folder, f))]\n",
    "\n",
    "    # Agregando esos archivos a la lista de archivos final\n",
    "    if folderFiles:\n",
    "      files.extend(folderFiles)\n",
    "\n",
    "  # Filtros específicos por cada origen\n",
    "  if source == \"bumeran\":\n",
    "    filesFiltered = [f for f in files if (\"\\Has recibido un CV para el aviso\" in f)]\n",
    "  else:\n",
    "    filesFiltered = files\n",
    "\n",
    "  # Filtros para considerar un archivo especifico\n",
    "  filterIsIn = [\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad_(76).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\analista-funcional\\Has recibido un CV para el aviso _Analista Funcional_(110).html\"\n",
    "    #r\"1-source-data\\main\\linkedin\\iteration-2\\bandeja-entrada\\New application_ .NET Developer from Cesar Ospino.html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\a-considerar\\Has recibido un CV para el aviso _Practicante de Infrastructure & Cloud_(1).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\a-considerar\\Has recibido un CV para el aviso _Practicante de Infrastructure & Cloud_.html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad Sr. (Test Lead)_(1).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad_(1).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\bandeja-entrada\\Has recibido un CV para el aviso _Analista Programador Senior_Full Stack_(2).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\bandeja-entrada\\Has recibido un CV para el aviso _Analista Programador_(6).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\programador-net\\Has recibido un CV para el aviso _Programador .Net Senior_(4).html\"\n",
    "  ]\n",
    "  filesFilteredIsIn = [f for f in filesFiltered if ( f in filterIsIn if filterIsIn else True )]\n",
    "\n",
    "  # Filtros para omitir un archivo especifico\n",
    "  filterIsNotIn = [\n",
    "    # 3 archivos con data incompleta\n",
    "    r\"1-source-data\\main\\bumeran\\iteration-4\\bandeja-entrada\\Has recibido un CV para el aviso _Analista Programador Senior_Full Stack_(2).html\",\n",
    "    r\"1-source-data\\main\\bumeran\\iteration-4\\bandeja-entrada\\Has recibido un CV para el aviso _Analista Programador_(6).html\",\n",
    "    r\"1-source-data\\main\\bumeran\\iteration-4\\programador-net\\Has recibido un CV para el aviso _Programador .Net Senior_(4).html\",\n",
    "    \n",
    "  ]\n",
    "  filesFilteredNotIn = [f for f in filesFilteredIsIn if ( f not in filterIsNotIn if filterIsNotIn else True )]\n",
    "\n",
    "  # Limites superiores e inferiores en la búsqueda de archivos\n",
    "  startLimit = None\n",
    "  topLimit = None\n",
    "  filesFilteredLimits = filesFilteredNotIn[(startLimit-1 if startLimit else 0): (topLimit if topLimit else len(files))]\n",
    "  print(len(filesFilteredLimits))\n",
    "\n",
    "  return filesFilteredLimits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "21425e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncodingBumeran(file, stringLog):\n",
    "  encoding = \"windows-1252\"\n",
    "  try:\n",
    "    with open(file, \"r\", encoding=\"utf-16-le\") as f:\n",
    "      if \"charset=unicode\" in f.read():\n",
    "        encoding = 'utf-16-le'\n",
    "      else:\n",
    "        raise Exception\n",
    "  except Exception as e:\n",
    "    try:\n",
    "      with open(file, \"r\", encoding=\"windows-1252\") as f:\n",
    "        if \"charset=windows-1252\" in f.read():\n",
    "          encoding = 'windows-1252'\n",
    "        else:\n",
    "          encoding = encoding\n",
    "    except Exception as e:\n",
    "      print(file)\n",
    "      stringLog = stringLog + file + \"\\n\"\n",
    "      traceback.print_exc()\n",
    "      stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "      print()\n",
    "      stringLog = stringLog + \"\\n\"\n",
    "      pass\n",
    "      \n",
    "  return encoding, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "c06d9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncodingLinkedin(file, stringLog):\n",
    "  encoding = \"windows-1256\"\n",
    "  try:\n",
    "    with open(file, \"r\", encoding=\"utf-16-le\") as f:\n",
    "      if \"charset=unicode\" in f.read():\n",
    "        encoding = 'utf-16-le'\n",
    "      else:\n",
    "        raise Exception\n",
    "  except Exception as e:\n",
    "    try:\n",
    "      with open(file, \"r\", encoding=\"windows-1256\") as f:\n",
    "        if \"charset=windows-1256\" in f.read():\n",
    "          encoding = 'windows-1256'\n",
    "        else:\n",
    "          encoding = encoding\n",
    "    except Exception as e:\n",
    "      print(file)\n",
    "      stringLog = stringLog + file + \"\\n\"\n",
    "      traceback.print_exc()\n",
    "      stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "      print()\n",
    "      stringLog = stringLog + \"\\n\"\n",
    "      pass\n",
    "      \n",
    "  return encoding, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "c6d1455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidateBumeran(file, encoding, stringLog):\n",
    "  candidateData = {}\n",
    " \n",
    "  try:\n",
    "  # Abriendo el archivo\n",
    "    with open(file, \"r\", encoding=encoding) as myFile:\n",
    "      #Parseando el archivo html a soup\n",
    "      soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
    "\n",
    "      # Obteniendo cada uno de los campos para la data\n",
    "\n",
    "      # Fecha de postulación\n",
    "      spanDates = soup.find_all(\"span\", {\"style\": \"color:black\"})\n",
    "      if len(spanDates) > 4:\n",
    "        rawPostulationDate = spanDates[3].text\n",
    "        postulationDate = datetime.datetime.strptime(spanDates[3].text, \"%A, %B %d, %Y %I:%M %p\")\n",
    "      else:\n",
    "        spanDates2 = soup.find_all(\"span\", {\"style\": 'font-family:\"Calibri\",sans-serif;color:black'})\n",
    "        rawPostulationDate = spanDates2[3].text\n",
    "        postulationDate = datetime.datetime.strptime(spanDates2[3].text, \"%A, %B %d, %Y %I:%M %p\")\n",
    "        \n",
    "      candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "      # Definiendo los colores a usar para las búsquedas según las fechas\n",
    "      # En la fecha 2020-06-11 cambio el color de los titulos de cada sección\n",
    "      colorTitle = \"#008599\" if (postulationDate <= datetime.datetime(2020,6,11,12,5,0)) else \"#E90066\"\n",
    "      colorSections = \"#2192C9\" if (postulationDate <= datetime.datetime(2020,6,11,12,5,0)) else \"#0A26EE\"\n",
    "\n",
    "      \"\"\"# Nombre del perfil\n",
    "      candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(soup.findAll(\"span\", {\"style\": (\"color:\" + colorTitle) })[0].text))\n",
    "\n",
    "      # Nombre del postulante\n",
    "      rawcandidateName = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")[0].text # El split join tambien quita saltos de línea\n",
    "      candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(rawcandidateName))\n",
    "\n",
    "      # Pais de residencia\n",
    "      tagResidenceCountry = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")\n",
    "      if len(tagResidenceCountry) > 2:\n",
    "        if tagResidenceCountry[2].text.find(\",\") != -1:\n",
    "          residenceCountry = parseNames(parseLineBreaksAndAccents(tagResidenceCountry[2].text[0:tagResidenceCountry[2].text.find(\",\")]))\n",
    "          if residenceCountry != \"\":\n",
    "            candidateData[\"residenceCountry\"] = residenceCountry\n",
    "          else:\n",
    "            raise Exception(\"Error no mapeado 1\")\n",
    "        else:\n",
    "          # Intentando sacarlo del pais de nacimiento\n",
    "          if tagResidenceCountry[8].text.find(\",\") != -1:\n",
    "            residenceCountry = parseNames(parseLineBreaksAndAccents(tagResidenceCountry[8].text[tagResidenceCountry[8].text.rfind(\",\")+2:]))\n",
    "            if residenceCountry != \"\":\n",
    "              candidateData[\"residenceCountry\"] = residenceCountry\n",
    "            else:\n",
    "              raise Exception(\"Error no mapeado 3\")\n",
    "          else:\n",
    "            # Analizar si permitir o no\n",
    "            raise Exception(\"Error no mapeado 2\")\n",
    "      else:\n",
    "        raise Exception(\"Error no mapeado 4 (posiblemente data incompleta como los 3 casos)\")\n",
    "      \"\"\"\n",
    "      \n",
    "      mainDivTag = soup.find_all(\"div\", {\"style\": 'background-position-x:50%;background-position-y:100%'})[0]\n",
    "      mainChildTags = mainDivTag.find_all(recursive=False)\n",
    "\n",
    "      sectionsIndexes = getSectionsIndexes(mainChildTags, colorSections)\n",
    "      \n",
    "      # Experiencia laboral\n",
    "      startIndex, endIndex = sectionsIndexes[0], getNextSectionIndexValid(sectionsIndexes, 1)\n",
    "\n",
    "      if startIndex and endIndex:\n",
    "        workExperienceTags = mainChildTags[startIndex+2:endIndex]\n",
    "        candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(workExperienceTags[0].find_all(\"b\")[0].text))\n",
    "        candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(workExperienceTags[1].find_all(\"b\")[0].text))\n",
    "\n",
    "        # Hay un caso que tiene span ya de por si en las experiencias laborales, el html 22, revisar\n",
    "        daysOfExperience = 0\n",
    "        for index in range(0, len(workExperienceTags), 2):\n",
    "          startDate = datetime.datetime.strptime(parseLineBreaksAndAccents(workExperienceTags[index].text)[0: parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" - \")] , \"%d-%m-%Y\")\n",
    "          endDateText = parseLineBreaksAndAccents(workExperienceTags[index].text)[parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" - \")+3: parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" | \")]\n",
    "          endDate = datetime.datetime.strptime(endDateText, \"%d-%m-%Y\") if endDateText != \"Presente\" else datetime.datetime.strptime(rawPostulationDate, \"%A, %B %d, %Y %I:%M %p\")\n",
    "          daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "        candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "        candidateData[\"worksNumber\"] = int(len(workExperienceTags)/2)\n",
    "      else:\n",
    "        # No tienen esta sección, se comprobo con busquedas\n",
    "        # Analizar si permitir o no\n",
    "        #candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "        #candidateData[\"yearsOfExperience\"] = 0\n",
    "        #candidateData[\"worksNumber\"] = 0\n",
    "        raise Exception(\"561 casos mapeados (no tienen experiencia laboral)\")\n",
    "      \n",
    "\n",
    "      \"\"\"\n",
    "      # Carrera profesional (última alcanzada)\n",
    "      educationIndex = getChildIndex(mainChildTags, \"Educación\", color)\n",
    "      informaticsIndex = getChildIndex(mainChildTags, \"Informática\", color)\n",
    "\n",
    "      if educationIndex and informaticsIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        educationTags = mainChildTags[educationIndex+2:informaticsIndex]\n",
    "\n",
    "        boldTags0 = educationTags[0].find_all(\"b\")\n",
    "        if len(boldTags0) == 0:\n",
    "          candidateData[\"studyCenter\"] = \"\"\n",
    "          candidateData[\"careerField\"] = \"\"\n",
    "        elif len(boldTags0) == 1:\n",
    "          #print(\"GA\")\n",
    "          if (parseLineBreaksAndAccents(educationTags[0].text).find(\",\") - parseLineBreaksAndAccents(educationTags[0].text).find(\" | \") == 3):\n",
    "            candidateData[\"studyCenter\"] = \"\"\n",
    "            candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "          else:\n",
    "            candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "            candidateData[\"careerField\"] = \"\"\n",
    "        else:\n",
    "          #print(\"AG\")\n",
    "          #print(educationTags[0].find_all(\"b\")[0])\n",
    "          candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "          candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(boldTags0[1].text.strip()))\n",
    "        \n",
    "        haveBoldTags1 = True if len(educationTags[1].find_all(\"b\")) > 0 else False\n",
    "        #if len(boldTags1) == 1:\n",
    "        tempTags = educationTags[1].find_all(\"span\")\n",
    "        #print(tempTags[1:])\n",
    "        statusDegreeIndex = next(((index+1 if haveBoldTags1 else index) for index, x in enumerate( tempTags[1:] if haveBoldTags1 else tempTags ) if \",\" in x.text), None)\n",
    "        #print([x.text for index, x in enumerate(tempTags[1:])])\n",
    "        #print(statusDegreeIndex)\n",
    "        \n",
    "        if statusDegreeIndex is not None:\n",
    "          candidateData[\"careerStatus\"] = parseNames(parseLineBreaksAndAccents(educationTags[1].find_all(\"span\")[statusDegreeIndex].text.split(\",\")[1].strip()))\n",
    "          candidateData[\"careerDegree\"] = parseNames(parseLineBreaksAndAccents(educationTags[1].find_all(\"span\")[statusDegreeIndex].text.split(\",\")[2].strip()[:-1]))\n",
    "          candidateData[\"studiesNumber\"] = int(len(educationTags)/2)\n",
    "        else:\n",
    "          candidateData[\"careerStatus\"] = candidateData[\"careerDegree\"] = \"\"\n",
    "          candidateData[\"studiesNumber\"] = 0\n",
    "      else:\n",
    "        candidateData[\"studyCenter\"] = candidateData[\"careerField\"] = candidateData[\"careerStatus\"] = candidateData[\"careerDegree\"] = \"\"\n",
    "        candidateData[\"studiesNumber\"] = 0\n",
    "      #print(file)\n",
    "      #print(candidateData[\"careerStatus\"])\n",
    "      #print(candidateData[\"careerDegree\"])\n",
    "      #print()\n",
    "\n",
    "      # Habilidades técnicas\n",
    "      informaticsIndex = getChildIndex(mainChildTags, \"Informática\", color)\n",
    "      languageIndex = getChildIndex(mainChildTags, \"Idiomas\", color)\n",
    "\n",
    "      if informaticsIndex and languageIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        technicalSkillsTags = mainChildTags[informaticsIndex+2:languageIndex][0].find_all(\"span\")\n",
    "        candidateData[\"technicalSkills\"] = int(len(technicalSkillsTags)/4)\n",
    "\n",
    "      else:\n",
    "        candidateData[\"technicalSkills\"] = 0\n",
    "\n",
    "      # Falta habilidades blandas\n",
    "\n",
    "      # Lenguajes\n",
    "      languageIndex = getChildIndex(mainChildTags, \"Idiomas\", color)\n",
    "      otherKnowledgesIndex = getChildIndex(mainChildTags, \"Otros Conocimientos\", color)\n",
    "\n",
    "      if languageIndex and otherKnowledgesIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        languagesTags = mainChildTags[languageIndex+2:otherKnowledgesIndex][0].find_all(\"span\")\n",
    "        candidateData[\"languages\"] = int(len(languagesTags)/7)\n",
    "\n",
    "      else:\n",
    "        candidateData[\"languages\"] = 1\n",
    "\n",
    "      # Otros conocimientos\n",
    "      otherKnowledgesIndex = getChildIndex(mainChildTags, \"Otros Conocimientos\", color)\n",
    "      endIndex = len(mainChildTags)-1\n",
    "\n",
    "      if languageIndex and otherKnowledgesIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        otherKnowledgesTags = mainChildTags[otherKnowledgesIndex+2:endIndex][0].find_all(\"span\")\n",
    "        candidateData[\"anotherSkills\"] = int(len(otherKnowledgesTags)/3)\n",
    "      else:\n",
    "        candidateData[\"anotherSkills\"] = 0\n",
    "\n",
    "      candidateData[\"references\"] = 0\n",
    "\n",
    "      # Salario pretendido\n",
    "      tagsSalary = [index for index, tag in enumerate(soup.find_all(\"span\")) if \"Sueldo pretendido\" in tag.text]\n",
    "      if len(tagsSalary) > 0:\n",
    "        rawSalary = soup.find_all(\"span\")[tagsSalary[0]+1].text\n",
    "        candidateData[\"salary\"] = int(float(parseLineBreaksAndAccents(\" \".join(rawSalary.split()))[1:].title()))\n",
    "      else:\n",
    "        candidateData[\"salary\"] = 0\"\"\"\n",
    "\n",
    "  except Exception as e:\n",
    "    candidateData = {}\n",
    "    print(file)\n",
    "    stringLog = stringLog + str(file) + \"\\n\"\n",
    "    traceback.print_exc()\n",
    "    stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "    print()\n",
    "    stringLog = stringLog + \"\\n\"\n",
    "    pass\n",
    "\n",
    "  return candidateData, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "54cef587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidateLinkedin(file, encoding, stringLog):\n",
    "  candidateData = {}\n",
    "\n",
    "  try:\n",
    "  # Abriendo el archivo\n",
    "    with open(file, \"r\", encoding=encoding) as myFile:\n",
    "      #Parseando el archivo html a soup\n",
    "      \n",
    "      soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
    "\n",
    "      spanBlack = soup.find_all(\"span\", {\"style\": \"color:black\"})\n",
    "      if len(spanBlack) > 4:\n",
    "        postulationDate = datetime.datetime.strptime(spanBlack[3].text, \"%A, %B %d, %Y %I:%M %p\")\n",
    "      else:\n",
    "        spanBlack2 = soup.find_all(\"span\", {\"style\": 'font-family:\"Calibri\",sans-serif;color:black'})\n",
    "        postulationDate = datetime.datetime.strptime(spanBlack2[3].text, \"%A, %B %d, %Y %I:%M %p\")\n",
    "\n",
    "      # Cambiar el lugar de donde se saca, sacarlo del body no del asunto\n",
    "      if len(spanBlack) > 7:\n",
    "        rawProfileName = parseLineBreaksAndAccents(spanBlack[7].text)\n",
    "      else:\n",
    "        spanBlack2 = soup.find_all(\"span\", {\"style\": 'font-family:\"Calibri\",sans-serif;color:black'})\n",
    "        rawProfileName = parseLineBreaksAndAccents(spanBlack2[7].text)\n",
    "\n",
    "      startIndexProfileName = rawProfileName.find(\": \")\n",
    "      endIndexProfileName = rawProfileName.find(\" from \")\n",
    "\n",
    "      if postulationDate <= datetime.datetime(2022,9,23,2,15,0):\n",
    "        \n",
    "        candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(rawProfileName[startIndexProfileName+1:endIndexProfileName]))\n",
    "\n",
    "        candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
    "\n",
    "        tempSpanTags = soup.find_all(\"span\", {\"style\": 'font-size:9.0pt;font-family:\\n            \"Helvetica\",sans-serif;color:#737373'})\n",
    "        existsCountry = True if len(tempSpanTags) > 1 else False\n",
    "        candidateData[\"residenceCountry\"] = parseNames(parseLineBreaksAndAccents(tempSpanTags[len(tempSpanTags)-1].text)) if existsCountry else \"\"\n",
    "\n",
    "        candidateData[\"channel\"] = \"Linkedin\"\n",
    "\n",
    "        tableTags = soup.find_all(\"table\")\n",
    "\n",
    "        notHaveScreening = True if \"Screening qualifications\" not in str(soup) else False\n",
    "        startTag = 15 if notHaveScreening else 16\n",
    "        endTag = len(tableTags)-3\n",
    "        findedTableTags = tableTags[startTag:endTag]\n",
    "\n",
    "        haveTags = [None, None, None, None, None]\n",
    "\n",
    "        for index, tag in enumerate(findedTableTags):\n",
    "          haveTags[0] = index if \"Current experience\" in tag.text else haveTags[0]\n",
    "          haveTags[1] = index if \"Past experience\" in tag.text else haveTags[1]\n",
    "          haveTags[2] = index if \"Education\" in tag.text else haveTags[2]\n",
    "          haveTags[3] = index if \"Skills matching your job\" in tag.text else haveTags[3]\n",
    "          haveTags[4] = index if \"Highlight\" in tag.text else haveTags[4]\n",
    "\n",
    "        for index, haveTag in enumerate(haveTags):\n",
    "          if index == 0:\n",
    "            if haveTag is not None:\n",
    "              #spanTags = findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\") Caso particular que no vale la pena\n",
    "              #startSpanIndex = 0 if len(spanTags) == 2 else len(spanTags)-3\n",
    "              candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[1])\n",
    "              candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[0])\n",
    "            else:\n",
    "              candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "          \n",
    "          elif index == 1:\n",
    "            if haveTag is not None:\n",
    "              daysOfExperience = 0\n",
    "              trTag = findedTableTags[haveTag].find_all(\"tr\")[1]\n",
    "              pTags = trTag.find_all(\"p\")\n",
    "              for pTag in pTags:\n",
    "                spanTag = parseLineBreaksAndAccents(pTag.find_all(\"span\")[1].text)\n",
    "                startDate = datetime.datetime.strptime(spanTag.split(\" - \")[0], \"%Y\")\n",
    "                endDate = datetime.datetime.strptime(spanTag.split(\" - \")[1], \"%Y\")\n",
    "                daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "              candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "              candidateData[\"worksNumber\"] = int(len(pTags))\n",
    "            else:\n",
    "              candidateData[\"yearsOfExperience\"] = 0\n",
    "              candidateData[\"worksNumber\"] = 0\n",
    "\n",
    "          elif index == 2:\n",
    "            # No se tiene el careerStatus en linkedin\n",
    "            if haveTag is not None:\n",
    "              trTags = findedTableTags[haveTag].find_all(\"tr\")[1:]\n",
    "              #print(trTags[0])\n",
    "              firstCenterWithDateIndex = -1\n",
    "              studiesNumber = 0\n",
    "              for index, trTag in enumerate(trTags):\n",
    "                if(len(trTag.find_all(\"span\"))>1):\n",
    "                  if(len(trTags[index-1].find_all(\"span\")) == 1):\n",
    "                    if firstCenterWithDateIndex == -1:\n",
    "                      firstCenterWithDateIndex = index-1\n",
    "                if(len(trTag.find_all(\"span\"))==1):\n",
    "                  studiesNumber = studiesNumber + 1\n",
    "              \n",
    "              #print(firstCenterWithDateIndex)\n",
    "              #print(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \")[1])\n",
    "              #print(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \"))\n",
    "              #print(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \")[1]))\n",
    "\n",
    "              if firstCenterWithDateIndex != -1:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex].text))\n",
    "                tempTagArray = trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")\n",
    "                candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")[1])) if len(tempTagArray) > 1 else \"\"\n",
    "                candidateData[\"careerStatus\"] = \"En Curso\" if (\"Present\" in parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[1].text)) else \"Graduado\"\n",
    "                tempText = parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")[0])\n",
    "                candidateData[\"careerDegree\"] = parseNames(parseLineBreaksAndAccents(tempText)) if not tempText[0:4].isnumeric() else \"\"\n",
    "              else:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[0].text))\n",
    "                candidateData[\"careerField\"] = \"\"\n",
    "                candidateData[\"careerStatus\"] = \"\"\n",
    "                candidateData[\"careerDegree\"] = \"\"\n",
    "              \n",
    "              candidateData[\"studiesNumber\"] = studiesNumber\n",
    "            else:\n",
    "              candidateData[\"studyCenter\"] = \"\"\n",
    "              candidateData[\"careerField\"] = \"\"\n",
    "              candidateData[\"careerStatus\"] = \"\"\n",
    "              candidateData[\"careerDegree\"] = \"\"\n",
    "              candidateData[\"studiesNumber\"] = 0\n",
    "          elif index == 3:\n",
    "            if haveTag is not None:\n",
    "              skillsCounter = 0\n",
    "              spanTags = findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")\n",
    "              for spanTag in spanTags:\n",
    "                if \"\".join(spanTag[\"style\"].split()) == 'font-size:10.5pt;font-family:\"Helvetica\",sans-serif;mso-fareast-font-family:\"TimesNewRoman\";color:#4D4D4D':\n",
    "                  skillsCounter = skillsCounter + 1\n",
    "              \n",
    "              candidateData[\"technicalSkills\"] = skillsCounter\n",
    "            else:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "            \n",
    "            candidateData[\"languages\"] = 1\n",
    "            candidateData[\"anotherSkills\"] = 0 if notHaveScreening else int(parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text)[parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text).find(\": \")+2: parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text).find(\"/\")])\n",
    "          elif index == 4:\n",
    "            if haveTag is not None:\n",
    "              highlightText = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)\n",
    "              isKnows = True if (\"knows\" in highlightText) else False\n",
    "              #print(isKnows)\n",
    "              isMoreThanTwo = True if (\"others\" in highlightText) else False\n",
    "              if isKnows and isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" and \")+5:highlightText.find(\" others \")])\n",
    "              elif isKnows and not isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText.count(\" and \") + 1)\n",
    "              else:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" hired \")+7:highlightText.find(\" people \")])\n",
    "            else:\n",
    "              candidateData[\"references\"] = 0\n",
    "        candidateData[\"salary\"] = 0\n",
    "        \n",
    "      else:\n",
    "        candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(rawProfileName[startIndexProfileName+1:endIndexProfileName]))\n",
    "\n",
    "        candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"color:#0A66C2;text-decoration:none;text-underline:none\"}).text))\n",
    "        \n",
    "        tempSpanTags = soup.find_all(\"span\", {\"style\": 'font-size:10.5pt;font-family:\"Helvetica\",sans-serif;\\n          color:#737373'})\n",
    "        existsCountry = True if len(tempSpanTags) > 1 else False\n",
    "        candidateData[\"residenceCountry\"] = parseNames(parseLineBreaksAndAccents(tempSpanTags[len(tempSpanTags)-1].text)) if existsCountry else \"\"\n",
    "\n",
    "        candidateData[\"channel\"] = \"Linkedin\"\n",
    "\n",
    "        tableTags = soup.find_all(\"table\")\n",
    "\n",
    "        startTag = 14\n",
    "        endTag = len(tableTags)-3\n",
    "        findedTableTags = tableTags[startTag:endTag]\n",
    "\n",
    "        haveTags = [None, None, None, None, None]\n",
    "\n",
    "        for index, tag in enumerate(findedTableTags):\n",
    "          haveTags[0] = index if \"Current experience\" in tag.text else haveTags[0]\n",
    "          haveTags[1] = index if \"Past experience\" in tag.text else haveTags[1]\n",
    "          haveTags[2] = index if \"Education\" in tag.text else haveTags[2]\n",
    "          haveTags[3] = index if \"Screening qualifications\" in tag.text else haveTags[3]\n",
    "          haveTags[4] = index if \"Highlight\" in tag.text else haveTags[4]\n",
    "        \n",
    "        for index, haveTag in enumerate(haveTags):\n",
    "          if index == 0:\n",
    "            if haveTag is not None:\n",
    "              tempTrTags = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")\n",
    "              #print(tempTrTags[1].find_all(\"span\")[0].text)\n",
    "              tempWorkCenter = tempTrTags[1] if len(tempTrTags) > 1 else \"\"\n",
    "              candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(tempWorkCenter[0:tempWorkCenter.rfind(\" - \")-4])) if tempWorkCenter != \"\" else \"\"\n",
    "              candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[0])\n",
    "            else:\n",
    "              candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "          \n",
    "          elif index == 1:\n",
    "            if haveTag is not None:\n",
    "              daysOfExperience = 0\n",
    "              trTags = [x for x in findedTableTags[haveTag].find_all(\"tr\") if x.find(\"span\", {\"style\": 'font-size:9.0pt;font-family:\"Helvetica\",sans-serif;\\n          color:#737373'})]\n",
    "              #print(trTags)\n",
    "              for trTag in trTags:\n",
    "                #print(pTag.text)\n",
    "                spanTag = parseLineBreaksAndAccents(trTag.find_all(\"span\")[0].text)\n",
    "                #print(spanTag)\n",
    "                #print(\"\".isnumeric())\n",
    "                if spanTag[spanTag.rfind(\" - \")-4:spanTag.rfind(\" - \")].isnumeric() and spanTag[spanTag.rfind(\" - \")+3:spanTag.rfind(\" - \")+7].isnumeric():\n",
    "                  startDate = datetime.datetime.strptime(spanTag[spanTag.rfind(\" - \")-4:spanTag.rfind(\" - \")], \"%Y\")\n",
    "                  endDate = datetime.datetime.strptime(spanTag[spanTag.rfind(\" - \")+3:spanTag.rfind(\" - \")+7], \"%Y\")\n",
    "                  daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "              candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "              candidateData[\"worksNumber\"] = int(len(trTags))\n",
    "            else:\n",
    "              candidateData[\"yearsOfExperience\"] = 0\n",
    "              candidateData[\"worksNumber\"] = 0\n",
    "\n",
    "          elif index == 2:\n",
    "            # No se tiene el careerStatus en linkedin\n",
    "            if haveTag is not None:\n",
    "              trTags = findedTableTags[haveTag].find_all(\"tr\")[1:]\n",
    "              #print(trTags[0])\n",
    "              firstCenterWithDateIndex = -1\n",
    "              studiesNumber = 0\n",
    "              for index, trTag in enumerate(trTags):\n",
    "                if \" - \" in parseLineBreaksAndAccents(trTag.text):\n",
    "                  if \" - \" not in parseLineBreaksAndAccents(trTags[index-1].text):\n",
    "                    if firstCenterWithDateIndex == -1:\n",
    "                      firstCenterWithDateIndex = index-1\n",
    "                if(\" - \" not in parseLineBreaksAndAccents(trTag.text)):\n",
    "                  studiesNumber = studiesNumber + 1\n",
    "              #print(firstCenterWithDateIndex)\n",
    "              if firstCenterWithDateIndex != -1:\n",
    "                #print(\"GA\")\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex].text))\n",
    "                tempTagArray = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find(\"span\").text))\n",
    "                candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(tempTagArray[tempTagArray.find(\", \")+1:tempTagArray.rfind(\" - \")-4]))\n",
    "                candidateData[\"careerStatus\"] = \"En Curso\" if (\"Present\" in tempTagArray) else \"Graduado\"\n",
    "                candidateData[\"careerDegree\"] = parseNames(parseLineBreaksAndAccents(tempTagArray[0:tempTagArray.find(\", \")])) if tempTagArray.find(\", \") != -1 else \"\"\n",
    "                #print(candidateData)\n",
    "              else:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[0].text))\n",
    "                candidateData[\"careerField\"] = \"\"\n",
    "                candidateData[\"careerStatus\"] = \"\"\n",
    "                candidateData[\"careerDegree\"] = \"\"\n",
    "              \n",
    "              candidateData[\"studiesNumber\"] = studiesNumber\n",
    "            else:\n",
    "              candidateData[\"studyCenter\"] = \"\"\n",
    "              candidateData[\"careerField\"] = \"\"\n",
    "              candidateData[\"careerStatus\"] = \"\"\n",
    "              candidateData[\"careerDegree\"] = \"\"\n",
    "              candidateData[\"studiesNumber\"] = 0\n",
    "          \n",
    "          elif index == 3:\n",
    "            if haveTag is not None:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "              candidateData[\"languages\"] = 1\n",
    "              candidateData[\"anotherSkills\"] = int(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)[0])\n",
    "            else:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "              candidateData[\"languages\"] = 1\n",
    "              candidateData[\"anotherSkills\"] = 0\n",
    "            \n",
    "          elif index == 4:\n",
    "            if haveTag is not None:\n",
    "              highlightText = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)\n",
    "              #print(highlightText)\n",
    "              isKnows = True if (\"knows\" in highlightText) else False\n",
    "              #print(isKnows)\n",
    "              isMoreThanTwo = True if (\"others\" in highlightText) else False\n",
    "              if isKnows and isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" and \")+5:highlightText.find(\" others \")])\n",
    "              elif isKnows and not isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText.count(\" and \") + 1)\n",
    "              else:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" hired \")+7:highlightText.find(\" people \")])\n",
    "            else:\n",
    "              candidateData[\"references\"] = 0\n",
    "        candidateData[\"salary\"] = 0\n",
    "      \n",
    "  except Exception as e:\n",
    "    candidateData = {}\n",
    "    print(file)\n",
    "    stringLog = stringLog + str(file) + \"\\n\"\n",
    "    traceback.print_exc()\n",
    "    stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "    print()\n",
    "    stringLog = stringLog + \"\\n\"\n",
    "    pass\n",
    "  \n",
    "  return candidateData, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "1799b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateFiles(files, source):\n",
    "  # Definiendo el log de errores\n",
    "  stringLog = \"\"\n",
    "\n",
    "  # Definiendo la data final de candidatos\n",
    "  data = []\n",
    "  \n",
    "  # Iterando por cada archivo\n",
    "  for file in files:\n",
    "    # Obteniendo el encoding por cada archivo\n",
    "    encoding, stringLog = getEncodingBumeran(file, stringLog) if source == 'bumeran' else getEncodingLinkedin(file, stringLog)\n",
    "\n",
    "    # Obteniendo los datos por cada archivo\n",
    "    candidate, stringLog = getCandidateBumeran(file, encoding, stringLog) if source == 'bumeran' else getCandidateLinkedin(file, encoding, stringLog)\n",
    "    \n",
    "    # Añadiendo los datos del candidato a la data final\n",
    "    if (candidate):\n",
    "      data.append(candidate)\n",
    "\n",
    "  return data, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "472c3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndWriteMain(source):\n",
    "  # Definiendo la carpeta raiz de los archivos a buscar, según el origen\n",
    "  rootPath = bumeranRootPath if source == \"bumeran\" else linkedinRootPath\n",
    "\n",
    "  # Obteniendo la lista de archivos, según el origen\n",
    "  files = getFiles(rootPath, source)\n",
    "\n",
    "  # Iterando sobre los archivos, calculando la data y el log de error\n",
    "  data, stringLog = iterateFiles(files, source)\n",
    "\n",
    "  # Escribiendo la data de los candidatos (json y csv)\n",
    "  writeJson(data, os.path.join(intermFilesFolder, source + '.json'))\n",
    "  writeCsv(data, os.path.join(intermFilesFolder, source + '.csv'))\n",
    "\n",
    "  # Escribiendo el log de errores\n",
    "  writeTxt(stringLog, os.path.join(logsFolder, source, datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".txt\"), 'utf-16')\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a8528b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndWriteMergedMain(mainData):\n",
    "  mainMergeddata = []\n",
    "  for elem in mainData:\n",
    "    if (elem):\n",
    "      mainMergeddata.extend(elem)\n",
    "\n",
    "  writeJson(mainMergeddata, os.path.join(mergedMainFolder, \"result.json\"), 'utf-8')\n",
    "  writeCsv(mainMergeddata, os.path.join(mergedMainFolder, \"result.csv\"), 'utf-8')\n",
    "\n",
    "  return mainMergeddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "2925ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeData(mergedMainData):\n",
    "  df = pd.DataFrame(mergedMainData)\n",
    "\n",
    "  print(df.count())\n",
    "\n",
    "  #columns = [\"profileName\", \"residenceCountry\", \"lastWorkCenter\", \"lastWorkPosition\", \"yearsOfExperience\", \"worksNumber\"]\n",
    "  columns = [\"lastWorkCenter\", \"lastWorkPosition\", \"yearsOfExperience\", \"worksNumber\"]\n",
    "  for column in columns:\n",
    "    top10 = df[column].value_counts()[:dataVisualizationTopLimit]\n",
    "    print(top10)\n",
    "    y_axis = list(reversed(top10.index))\n",
    "    x_axis = list(reversed(top10.values))\n",
    "    plt.ylabel(column)\n",
    "    plt.barh(y_axis, x_axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "c9021c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio: 2023-05-11 00:09:07.104276\n",
      "Se inició el procesamiento\n",
      "9794\n",
      "[4, 12, 16, 19, 22, 25]\n",
      "[4, 14, 18, 21, 24, 27]\n",
      "[4, 14, 20, 23, 26, 29]\n",
      "[4, 12, 18, 21, 24, 27]\n",
      "[4, 18, 26, 29, 32, 35]\n",
      "[4, 28, 32, 35, 38, 41]\n",
      "[4, 12, 20, 23, 26, 29]\n",
      "[4, 28, None, 40, 43, 46]\n",
      "[4, 16, 20, 23, 26, 29]\n",
      "[4, 14, 26, 29, None, 32]\n",
      "[4, 20, 24, 27, 30, 33]\n",
      "[4, 20, None, 28, 31, 34]\n",
      "[4, 26, 36, 39, 42, 45]\n",
      "[4, 16, 24, 27, 30, 33]\n",
      "[4, 22, 32, 35, 38, 41]\n",
      "[4, 20, 26, 29, 32, 35]\n",
      "[4, 10, 18, 21, 24, 27]\n",
      "[4, 16, 30, 33, 36, 39]\n",
      "[4, 16, 22, 25, 28, 31]\n",
      "[4, 18, 34, 37, 40, 43]\n",
      "[4, 22, 48, 51, 54, 57]\n",
      "[4, 8, 18, 21, 24, 27]\n",
      "[4, 10, 18, None, 21, 24]\n",
      "[4, 8, 12, 15, 18, 21]\n",
      "[4, 10, 16, 19, 22, 25]\n",
      "[None, 4, 8, 11, 14, 17]\n",
      "1-source-data\\main\\bumeran\\iteration-4\\a-considerar\\Has recibido un CV para el aviso _Practicante de Infrastructure & Cloud_.html\n",
      "\n",
      "[4, 18, 26, 29, 32, 35]\n",
      "[4, 40, 56, 59, 62, 65]\n",
      "[4, 40, 46, 49, None, 52]\n",
      "[4, 14, 18, 21, 24, 27]\n",
      "[4, 22, 52, 55, 58, 61]\n",
      "[4, 18, None, 24, 27, 30]\n",
      "[4, 8, 12, 15, None, 18]\n",
      "[4, 26, 30, 33, 36, 39]\n",
      "[4, 10, 16, 19, None, 22]\n",
      "[4, 12, 16, 19, 22, 25]\n",
      "[4, 24, 28, 31, None, 34]\n",
      "[4, 20, 24, None, None, 27]\n",
      "[4, 18, 24, 27, None, 30]\n",
      "[4, 20, 26, 29, 32, 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_17716\\3955206961.py\", line 91, in getCandidateBumeran\n",
      "    raise Exception(\"Casos no mapeados 1\")\n",
      "Exception: Casos no mapeados 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[403], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTiempo: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(endTime\u001b[39m-\u001b[39mstartTime))\n\u001b[0;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m   main()\n",
      "Cell \u001b[1;32mIn[403], line 16\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m isMergedMain \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#False\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[39m# Leyendo o calculando bumeran\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m bumeranData \u001b[39m=\u001b[39m readJson(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(intermFilesFolder, \u001b[39m'\u001b[39m\u001b[39mbumeran.json\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39mif\u001b[39;00m isLoadedBumeran \u001b[39melse\u001b[39;00m readAndWriteMain(\u001b[39m'\u001b[39;49m\u001b[39mbumeran\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSe terminó de procesar Bumeran\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39m# Leyendo o calculando linkedin\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[400], line 9\u001b[0m, in \u001b[0;36mreadAndWriteMain\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m      6\u001b[0m files \u001b[39m=\u001b[39m getFiles(rootPath, source)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Iterando sobre los archivos, calculando la data y el log de error\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m data, stringLog \u001b[39m=\u001b[39m iterateFiles(files, source)\n\u001b[0;32m     11\u001b[0m \u001b[39m# Escribiendo la data de los candidatos (json y csv)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m writeJson(data, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(intermFilesFolder, source \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m))\n",
      "Cell \u001b[1;32mIn[399], line 14\u001b[0m, in \u001b[0;36miterateFiles\u001b[1;34m(files, source)\u001b[0m\n\u001b[0;32m     11\u001b[0m encoding, stringLog \u001b[39m=\u001b[39m getEncodingBumeran(file, stringLog) \u001b[39mif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbumeran\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m getEncodingLinkedin(file, stringLog)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Obteniendo los datos por cada archivo\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m candidate, stringLog \u001b[39m=\u001b[39m getCandidateBumeran(file, encoding, stringLog) \u001b[39mif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbumeran\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m getCandidateLinkedin(file, encoding, stringLog)\n\u001b[0;32m     16\u001b[0m \u001b[39m# Añadiendo los datos del candidato a la data final\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mif\u001b[39;00m (candidate):\n",
      "Cell \u001b[1;32mIn[397], line 94\u001b[0m, in \u001b[0;36mgetCandidateBumeran\u001b[1;34m(file, encoding, stringLog)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m       \u001b[39m# No tienen esta sección, se comprobo con busquedas\u001b[39;00m\n\u001b[0;32m     88\u001b[0m       \u001b[39m#candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\u001b[39;00m\n\u001b[0;32m     89\u001b[0m       \u001b[39m#candidateData[\"yearsOfExperience\"] = 0\u001b[39;00m\n\u001b[0;32m     90\u001b[0m       \u001b[39m#candidateData[\"worksNumber\"] = 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCasos no mapeados 1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39m    # Carrera profesional (última alcanzada)\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[39m    educationIndex = getChildIndex(mainChildTags, \"Educación\", color)\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[39m    informaticsIndex = getChildIndex(mainChildTags, \"Informática\", color)\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m \u001b[39m    if educationIndex and informaticsIndex:\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39m      # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m      educationTags = mainChildTags[educationIndex+2:informaticsIndex]\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[39m      boldTags0 = educationTags[0].find_all(\"b\")\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m      if len(boldTags0) == 0:\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m        candidateData[\"studyCenter\"] = \"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39m        candidateData[\"careerField\"] = \"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39m      elif len(boldTags0) == 1:\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m        #print(\"GA\")\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39m        if (parseLineBreaksAndAccents(educationTags[0].text).find(\",\") - parseLineBreaksAndAccents(educationTags[0].text).find(\" | \") == 3):\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[39m          candidateData[\"studyCenter\"] = \"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m          candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39m        else:\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[39m          candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[39m          candidateData[\"careerField\"] = \"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39m      else:\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m        #print(\"AG\")\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39m        #print(educationTags[0].find_all(\"b\")[0])\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m        candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39m        candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(boldTags0[1].text.strip()))\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m      \u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[39m      haveBoldTags1 = True if len(educationTags[1].find_all(\"b\")) > 0 else False\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39m      #if len(boldTags1) == 1:\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m      tempTags = educationTags[1].find_all(\"span\")\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m      #print(tempTags[1:])\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39m      statusDegreeIndex = next(((index+1 if haveBoldTags1 else index) for index, x in enumerate( tempTags[1:] if haveBoldTags1 else tempTags ) if \",\" in x.text), None)\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39m      #print([x.text for index, x in enumerate(tempTags[1:])])\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39m      #print(statusDegreeIndex)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m      \u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m      if statusDegreeIndex is not None:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m        candidateData[\"careerStatus\"] = parseNames(parseLineBreaksAndAccents(educationTags[1].find_all(\"span\")[statusDegreeIndex].text.split(\",\")[1].strip()))\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m        candidateData[\"careerDegree\"] = parseNames(parseLineBreaksAndAccents(educationTags[1].find_all(\"span\")[statusDegreeIndex].text.split(\",\")[2].strip()[:-1]))\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m        candidateData[\"studiesNumber\"] = int(len(educationTags)/2)\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m      else:\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m        candidateData[\"careerStatus\"] = candidateData[\"careerDegree\"] = \"\"\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[39m        candidateData[\"studiesNumber\"] = 0\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m    else:\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[39m      candidateData[\"studyCenter\"] = candidateData[\"careerField\"] = candidateData[\"careerStatus\"] = candidateData[\"careerDegree\"] = \"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39m      candidateData[\"studiesNumber\"] = 0\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39m    #print(file)\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[39m    #print(candidateData[\"careerStatus\"])\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39m    #print(candidateData[\"careerDegree\"])\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39m    #print()\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[39m    # Habilidades técnicas\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[39m    informaticsIndex = getChildIndex(mainChildTags, \"Informática\", color)\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39m    languageIndex = getChildIndex(mainChildTags, \"Idiomas\", color)\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \n\u001b[0;32m    148\u001b[0m \u001b[39m    if informaticsIndex and languageIndex:\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39m      # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39m      technicalSkillsTags = mainChildTags[informaticsIndex+2:languageIndex][0].find_all(\"span\")\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[39m      candidateData[\"technicalSkills\"] = int(len(technicalSkillsTags)/4)\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[0;32m    153\u001b[0m \u001b[39m    else:\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m      candidateData[\"technicalSkills\"] = 0\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[39m    # Falta habilidades blandas\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \n\u001b[0;32m    158\u001b[0m \u001b[39m    # Lenguajes\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39m    languageIndex = getChildIndex(mainChildTags, \"Idiomas\", color)\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m    otherKnowledgesIndex = getChildIndex(mainChildTags, \"Otros Conocimientos\", color)\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[0;32m    162\u001b[0m \u001b[39m    if languageIndex and otherKnowledgesIndex:\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m      # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39m      languagesTags = mainChildTags[languageIndex+2:otherKnowledgesIndex][0].find_all(\"span\")\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[39m      candidateData[\"languages\"] = int(len(languagesTags)/7)\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[39m    else:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[39m      candidateData[\"languages\"] = 1\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[39m    # Otros conocimientos\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m    otherKnowledgesIndex = getChildIndex(mainChildTags, \"Otros Conocimientos\", color)\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m    endIndex = len(mainChildTags)-1\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \n\u001b[0;32m    174\u001b[0m \u001b[39m    if languageIndex and otherKnowledgesIndex:\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39m      # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39m      otherKnowledgesTags = mainChildTags[otherKnowledgesIndex+2:endIndex][0].find_all(\"span\")\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[39m      candidateData[\"anotherSkills\"] = int(len(otherKnowledgesTags)/3)\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[39m    else:\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39m      candidateData[\"anotherSkills\"] = 0\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \n\u001b[0;32m    181\u001b[0m \u001b[39m    candidateData[\"references\"] = 0\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[39m    # Salario pretendido\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[39m    tagsSalary = [index for index, tag in enumerate(soup.find_all(\"span\")) if \"Sueldo pretendido\" in tag.text]\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39m    if len(tagsSalary) > 0:\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39m      rawSalary = soup.find_all(\"span\")[tagsSalary[0]+1].text\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39m      candidateData[\"salary\"] = int(float(parseLineBreaksAndAccents(\" \".join(rawSalary.split()))[1:].title()))\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39m    else:\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m      candidateData[\"salary\"] = 0\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    192\u001b[0m   candidateData \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  # Definiendo el inicio del proceso\n",
    "  startTime = datetime.datetime.now()\n",
    "  print(\"Inicio: \" + str(startTime))\n",
    "  print(\"Se inició el procesamiento\")\n",
    "\n",
    "  # El dataset principal que sea el de bumeran\n",
    "  # Los otros archivos que solo se usen para actualizar la variable objetivo\n",
    "  # Esto porque los otros orígenes están incompletos y costaría llenar los campos (incluso el excel que se hizo)\n",
    "  isLoadedBumeran = False\n",
    "  isLoadedLinkedin = True\n",
    "  isMergedMain = True\n",
    "  #False\n",
    "\n",
    "  # Leyendo o calculando bumeran\n",
    "  bumeranData = readJson(os.path.join(intermFilesFolder, 'bumeran.json')) if isLoadedBumeran else readAndWriteMain('bumeran')\n",
    "  print(\"Se terminó de procesar Bumeran\")\n",
    "\n",
    "  # Leyendo o calculando linkedin\n",
    "  linkedinData = readJson(os.path.join(intermFilesFolder, 'linkedin.json')) if isLoadedLinkedin else readAndWriteMain('linkedin')\n",
    "  print(\"Se terminó de procesar Linkedin\")\n",
    "\n",
    "  # Uniendo la data principal (bumeran + linkedin)\n",
    "  mergedMainData = readJson(os.path.join(mergedMainFolder, 'result.json')) if isMergedMain else readAndWriteMergedMain([bumeranData, linkedinData])\n",
    "  print(\"Se terminó de unir la data principal\")\n",
    "\n",
    "  #visualizeData(mergedMainData)\n",
    "  \n",
    "  # Definiendo el fin del proceso\n",
    "  endTime = datetime.datetime.now()\n",
    "  print(\"Fin: \" + str(endTime))\n",
    "  print(\"Tiempo: \" + str(endTime-startTime))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
