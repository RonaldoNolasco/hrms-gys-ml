{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, confusion_matrix, accuracy_score, recall_score\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763cd073",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = 0.2\n",
    "randomState = 0\n",
    "partitionsNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ac9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer datos de un archivo csv\n",
    "def readData(filePath, delimiter, encoding, header):\n",
    "  data = pd.read_csv(filePath, delimiter=delimiter,encoding=encoding, header=header)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingData(data):\n",
    "  # Aca no se realizará ni parseo ni nada, ya vendrá desde la fuente\n",
    "  # Solo se leerá, se dividirá y se entrenará\n",
    "\n",
    "  # Desordenando la data (filas)\n",
    "  data = data.sample(frac = 1, random_state=randomState).reset_index(drop=True)\n",
    "\n",
    "  # Filtrar filas nulas\n",
    "  #data = data.dropna()\n",
    "\n",
    "  # Eliminando columnas que no se usan para el modelo\n",
    "  nonModelColumns = [\"postulationDate\", \"candidateName\"]\n",
    "  # , \"lastWorkCenter\", \"lastWorkPosition\"\n",
    "  data = data.drop(nonModelColumns, axis=1)\n",
    "\n",
    "  # Aplicando OneHotEncoding a las variables categóricas (transformación a numéricas y normalización)\n",
    "  categoricalColumns = [\"primaryRole\", \"secondaryRole\", \"companyArea\", \"profileLevel\", \"residenceCountry\", \"channel\", \"lastWorkCenter\", \"lastWorkPosition\", \"studyCenterCountry\", \"studyCenterType\", \"studyCenterSector\", \"careerField\", \"careerStatus\", \"careerDegree\"]\n",
    "  # , \"lastWorkCenter\", \"lastWorkPosition\"\n",
    "  transformer = make_column_transformer( (OneHotEncoder(sparse=False), categoricalColumns), remainder='passthrough')\n",
    "  transformed = transformer.fit_transform(data)\n",
    "  data = pd.DataFrame(transformed, columns=transformer.get_feature_names())\n",
    "\n",
    "  # Aplicando MinMaxScaler a las variables numéricas (normalización)\n",
    "  numericNonScaledColumns = [\"yearsOfExperience\", \"worksNumber\", \"studiesNumber\", \"technicalSkills\", \"languages\", \"anotherSkills\", \"references\", \"salary\"]\n",
    "  mms = MinMaxScaler()\n",
    "  data[numericNonScaledColumns] = mms.fit_transform(data[numericNonScaledColumns])\n",
    "\n",
    "  # Estandarizando el tipo de la variable objetivo a entero\n",
    "  objectiveColumn = \"hired\"\n",
    "  data[objectiveColumn] = data[objectiveColumn].astype(int)\n",
    "\n",
    "  # Lectura de las variables de características y objetivo\n",
    "  X = data.drop([objectiveColumn], axis=1)\n",
    "  y = data[objectiveColumn]\n",
    "\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X, y, partitionNumber):\n",
    "  # Dividiendo los dataframes de entrenamiento y prueba\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testSize, random_state=randomState)\n",
    "\n",
    "  if partitionNumber != 0:\n",
    "    # Obteniendo el total de filas del dataframe de testeo\n",
    "    X_train, X_test, y_train, y_test = X_train.reset_index(drop=True), X_test.reset_index(drop=True), y_train.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "    totalRows = len(X_train)\n",
    "\n",
    "    # Determinando el límite inferior (primera fila) de la partición\n",
    "    bottomLimit = int(totalRows*testSize*(partitionNumber-1)) + 1\n",
    "\n",
    "    # Determinando el límite superior (última fila) de la partición\n",
    "    topLimit = int(totalRows*testSize*partitionNumber)\n",
    "\n",
    "    # Determinando una lista con todas los numeros de las filas con la partición\n",
    "    testList = [x for x in range(bottomLimit-1, topLimit)]\n",
    "\n",
    "    # Determinando los dataframes de las categorías\n",
    "    X_train, X_test = X_train[~X_train.index.isin(testList)], X_train[X_train.index.isin(testList)]\n",
    "\n",
    "    # Determinando los dataframes de los objetivos\n",
    "    y_train, y_test = y_train[~y_train.index.isin(testList)], y_train[y_train.index.isin(testList)]\n",
    "\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fae5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createClassifier(modelName, parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
