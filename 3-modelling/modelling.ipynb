{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dad0ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, confusion_matrix, accuracy_score, recall_score\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "import datetime\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "763cd073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "sourceDataFolder = \"1-source-data\"\n",
    "\n",
    "intermFilesFolder = \"2-intermediate-files\"\n",
    "resultsFolder = \"3-results\"\n",
    "logsFolder = \"4-logs\"\n",
    "\n",
    "dataVisualizationTopLimit = 20\n",
    "\n",
    "counterIn = 0\n",
    "counterOut = 0\n",
    "\n",
    "testSize = 0.2\n",
    "randomState = 0\n",
    "partitionsNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "919ac9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer datos de un archivo csv\n",
    "def readData(filePath, delimiter, encoding, header):\n",
    "  data = pd.read_csv(filePath, delimiter=delimiter,encoding=encoding, header=header)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "311c6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingData(data):\n",
    "  # Aca no se realizará ni parseo ni nada, ya vendrá desde la fuente\n",
    "  # Solo se leerá, se dividirá y se entrenará\n",
    "\n",
    "  # Desordenando la data (filas)\n",
    "  data = data.sample(frac = 1, random_state=randomState).reset_index(drop=True)\n",
    "\n",
    "  # Filtrar filas nulas\n",
    "  #data = data.dropna()\n",
    "\n",
    "  # Eliminando columnas que no se usan para el modelo\n",
    "  nonModelColumns = [\"postulationDate\", \"candidateName\"]\n",
    "  # , \"lastWorkCenter\", \"lastWorkPosition\"\n",
    "  data = data.drop(nonModelColumns, axis=1)\n",
    "\n",
    "  # Aplicando OneHotEncoding a las variables categóricas (transformación a numéricas y normalización)\n",
    "  categoricalColumns = [\"profileName\", \"residenceCountry\", \"lastWorkCenter\", \"lastWorkPosition\", \"studyCenter\", \"careerField\", \"careerStatus\", \"careerDegree\"]\n",
    "  transformer = make_column_transformer( (OneHotEncoder(sparse=False), categoricalColumns), remainder='passthrough')\n",
    "  transformed = transformer.fit_transform(data)\n",
    "  data = pd.DataFrame(transformed, columns=transformer.get_feature_names())\n",
    "\n",
    "  # Aplicando MinMaxScaler a las variables numéricas (normalización)\n",
    "  numericNonScaledColumns = [\"yearsOfExperience\", \"worksNumber\", \"studiesNumber\", \"technicalSkills\", \"languages\", \"anotherSkills\", \"salary\"]\n",
    "  mms = MinMaxScaler()\n",
    "  data[numericNonScaledColumns] = mms.fit_transform(data[numericNonScaledColumns])\n",
    "\n",
    "  # Estandarizando el tipo de la variable objetivo a entero\n",
    "  objectiveColumn = \"hired\"\n",
    "  data[objectiveColumn] = data[objectiveColumn].astype(int)\n",
    "\n",
    "  # Lectura de las variables de características y objetivo\n",
    "  X = data.drop([objectiveColumn], axis=1)\n",
    "  y = data[objectiveColumn]\n",
    "\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49ddd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X, y, partitionNumber):\n",
    "  # Dividiendo los dataframes de entrenamiento y prueba\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testSize, random_state=randomState)\n",
    "\n",
    "  if partitionNumber != 0:\n",
    "    # Obteniendo el total de filas del dataframe de testeo\n",
    "    X_train, X_test, y_train, y_test = X_train.reset_index(drop=True), X_test.reset_index(drop=True), y_train.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "    totalRows = len(X_train)\n",
    "\n",
    "    # Determinando el límite inferior (primera fila) de la partición\n",
    "    bottomLimit = int(totalRows*testSize*(partitionNumber-1)) + 1\n",
    "\n",
    "    # Determinando el límite superior (última fila) de la partición\n",
    "    topLimit = int(totalRows*testSize*partitionNumber)\n",
    "\n",
    "    # Determinando una lista con todas los numeros de las filas con la partición\n",
    "    testList = [x for x in range(bottomLimit-1, topLimit)]\n",
    "\n",
    "    # Determinando los dataframes de las categorías\n",
    "    X_train, X_test = X_train[~X_train.index.isin(testList)], X_train[X_train.index.isin(testList)]\n",
    "\n",
    "    # Determinando los dataframes de los objetivos\n",
    "    y_train, y_test = y_train[~y_train.index.isin(testList)], y_train[y_train.index.isin(testList)]\n",
    "\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18fae5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createClassifier(modelName, parameters):\n",
    "  if modelName == \"KNN\":\n",
    "    return KNeighborsClassifier(parameters) if parameters is not None else KNeighborsClassifier()\n",
    "  elif modelName == \"LR\":\n",
    "    return LogisticRegression(parameters) if parameters is not None else LogisticRegression()\n",
    "  elif modelName == \"GNB\":\n",
    "    return GaussianNB(parameters) if parameters is not None else GaussianNB()\n",
    "  elif modelName == \"DT\":\n",
    "    return DecisionTreeClassifier(parameters) if parameters is not None else DecisionTreeClassifier()\n",
    "  elif modelName == \"SVM\":\n",
    "    return SVC(parameters) if parameters is not None else SVC()\n",
    "  elif modelName == \"RF\":\n",
    "    return RandomForestClassifier(parameters) if parameters is not None else RandomForestClassifier()\n",
    "  elif modelName == \"GB\":\n",
    "    return GradientBoostingClassifier(parameters) if parameters is not None else GradientBoostingClassifier()\n",
    "  else:\n",
    "    return KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2be135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(X_train, X_test, y_train, y_test, modelName, parameters = None):\n",
    "  # Creación del clasificador KNN\n",
    "  clf = createClassifier(modelName, parameters)\n",
    "\n",
    "  # Entrenamiento del clasificador KNN\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  # Calculando la predicción del modelo con la data de prueba\n",
    "  y_pred = clf.predict(X_test)\n",
    "\n",
    "  return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1887988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(y_train, y_test, y_pred, startDate, endDate, partitionNumber, algorithm = \"KNN\"):\n",
    "  trainRows = len(y_train)\n",
    "  testRows = len(y_test)\n",
    "\n",
    "  # Calculando la exactitud del modelo\n",
    "  accuracy = \"{:.2%}\".format(accuracy_score(y_test, y_pred))\n",
    "\n",
    "  # Calculando la precisión del modelo\n",
    "  precision = \"{:.2%}\".format(precision_score(y_test, y_pred))\n",
    "\n",
    "  # Calculando el valor F del modelo\n",
    "  f1Score = \"{:.2%}\".format(f1_score(y_test, y_pred))\n",
    "\n",
    "  # Calculando la sensibilidad del modelo\n",
    "  recall = \"{:.2%}\".format(recall_score(y_test, y_pred))\n",
    "\n",
    "  # Calculando el tiempo de ejecución del modelo\n",
    "  executionTime = str(int((endDate - startDate).total_seconds() * 1000)) + \"ms\"\n",
    "\n",
    "  confussionMatrix = str(confusion_matrix(y_test, y_pred).tolist())\n",
    "  \n",
    "  return {\n",
    "    \"algoritmo\": algorithm,\n",
    "    \"tipo\": \"Total de datos\" if partitionNumber == 0 else \"Particion \" + str(partitionNumber),\n",
    "    \"registrosEntrenamiento\": trainRows,\n",
    "    \"registrosPrueba\": testRows,\n",
    "    \"tiempoEjecucion\": executionTime,\n",
    "    \"matrizConfusion\": confussionMatrix,\n",
    "    \"exactitud\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"valorF\": f1Score,\n",
    "    \"sensibilidad\": recall,\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83f3c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  # Definiendo el inicio del proceso\n",
    "  startTime = datetime.datetime.now()\n",
    "  print(\"Inicio: \" + str(startTime))\n",
    "  print(\"Se inició el procesamiento\")\n",
    "\n",
    "  # Leyendo la data\n",
    "  data = readData('1-source-data/result.csv', ',', 'utf-8', 0)\n",
    "\n",
    "  # Determinando los dataframes de las categorías (X) y el objetivo (y)\n",
    "  X, y = preprocessingData(data)\n",
    "\n",
    "  # Creando el arreglo de metricas de cada partición\n",
    "  metricsList = []\n",
    "\n",
    "  # Iterando sobre cada partición\n",
    "  for partitionNumber in range(0,partitionsNumber+1):\n",
    "    # Separando data para el entrenamiento y testeo\n",
    "    X_train, X_test, y_train, y_test = splitData(X, y, partitionNumber)\n",
    "\n",
    "    models = [\"KNN\", \"LR\", \"GNB\", \"DT\", \"SVM\", \"RF\", \"GB\"]\n",
    "\n",
    "    for model in models:\n",
    "      print(\"Calculando para el algoritmo {}\".format(model))\n",
    "\n",
    "      # Inicio de ejecución del modelo\n",
    "      startDate = datetime.datetime.now()\n",
    "      \n",
    "      # Realizar entrenamiento del modelo\n",
    "      y_test, y_pred = trainModel(X_train, X_test, y_train, y_test, model)\n",
    "\n",
    "      # Fin de ejecución del modelo\n",
    "      endDate = datetime.datetime.now()\n",
    "\n",
    "      # Obteniendo las métricas de la partición del modelo\n",
    "      metrics = getMetrics(y_train, y_test, y_pred, startDate, endDate, partitionNumber, model)\n",
    "\n",
    "      # Añadiendo la métrica de la partición a la lista de métricas\n",
    "      metricsList.append(metrics)\n",
    "\n",
    "  # Ordenando las métricas\n",
    "  metricsList = sorted(metricsList, key=lambda x: (x[\"algoritmo\"], x[\"tipo\"]))\n",
    "\n",
    "  # Mostrando las métricas\n",
    "  metricsListPretty = json.dumps(metricsList, indent=4)\n",
    "  print(metricsListPretty)\n",
    "    \n",
    "  # Escribiendo las metricas en un archivo de salida\n",
    "  with open(os.path.join(resultsFolder, datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".json\"), \"w\") as f:\n",
    "      json.dump(metricsList, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "  # Definiendo el fin del proceso\n",
    "  endTime = datetime.datetime.now()\n",
    "  print(\"Fin: \" + str(endTime))\n",
    "  print(\"Tiempo: \" + str(endTime-startTime))\n",
    "  \n",
    "  # Retornando la lista de métricas\n",
    "  return metricsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c95c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio: 2023-05-12 02:55:31.086382\n",
      "Se inició el procesamiento\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando para el algoritmo KNN\n",
      "Calculando para el algoritmo LR\n",
      "Calculando para el algoritmo GNB\n",
      "Calculando para el algoritmo DT\n",
      "Calculando para el algoritmo SVM\n",
      "Calculando para el algoritmo RF\n",
      "Calculando para el algoritmo GB\n",
      "[\n",
      "    {\n",
      "        \"algoritmo\": \"DT\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 4972,\n",
      "        \"registrosPrueba\": 1244,\n",
      "        \"tiempoEjecucion\": \"17798ms\",\n",
      "        \"matrizConfusion\": \"[[1145, 12], [54, 33]]\",\n",
      "        \"exactitud\": \"94.69%\",\n",
      "        \"precision\": \"73.33%\",\n",
      "        \"valorF\": \"50.00%\",\n",
      "        \"sensibilidad\": \"37.93%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"GB\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 4972,\n",
      "        \"registrosPrueba\": 1244,\n",
      "        \"tiempoEjecucion\": \"26609ms\",\n",
      "        \"matrizConfusion\": \"[[1157, 0], [70, 17]]\",\n",
      "        \"exactitud\": \"94.37%\",\n",
      "        \"precision\": \"100.00%\",\n",
      "        \"valorF\": \"32.69%\",\n",
      "        \"sensibilidad\": \"19.54%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"GNB\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 4972,\n",
      "        \"registrosPrueba\": 1244,\n",
      "        \"tiempoEjecucion\": \"737ms\",\n",
      "        \"matrizConfusion\": \"[[855, 302], [34, 53]]\",\n",
      "        \"exactitud\": \"72.99%\",\n",
      "        \"precision\": \"14.93%\",\n",
      "        \"valorF\": \"23.98%\",\n",
      "        \"sensibilidad\": \"60.92%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"KNN\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 4972,\n",
      "        \"registrosPrueba\": 1244,\n",
      "        \"tiempoEjecucion\": \"775ms\",\n",
      "        \"matrizConfusion\": \"[[1147, 10], [59, 28]]\",\n",
      "        \"exactitud\": \"94.45%\",\n",
      "        \"precision\": \"73.68%\",\n",
      "        \"valorF\": \"44.80%\",\n",
      "        \"sensibilidad\": \"32.18%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"LR\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 4972,\n",
      "        \"registrosPrueba\": 1244,\n",
      "        \"tiempoEjecucion\": \"2203ms\",\n",
      "        \"matrizConfusion\": \"[[1157, 0], [68, 19]]\",\n",
      "        \"exactitud\": \"94.53%\",\n",
      "        \"precision\": \"100.00%\",\n",
      "        \"valorF\": \"35.85%\",\n",
      "        \"sensibilidad\": \"21.84%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"RF\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 4972,\n",
      "        \"registrosPrueba\": 1244,\n",
      "        \"tiempoEjecucion\": \"7774ms\",\n",
      "        \"matrizConfusion\": \"[[1157, 0], [58, 29]]\",\n",
      "        \"exactitud\": \"95.34%\",\n",
      "        \"precision\": \"100.00%\",\n",
      "        \"valorF\": \"50.00%\",\n",
      "        \"sensibilidad\": \"33.33%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"SVM\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 4972,\n",
      "        \"registrosPrueba\": 1244,\n",
      "        \"tiempoEjecucion\": \"54423ms\",\n",
      "        \"matrizConfusion\": \"[[1157, 0], [69, 18]]\",\n",
      "        \"exactitud\": \"94.45%\",\n",
      "        \"precision\": \"100.00%\",\n",
      "        \"valorF\": \"34.29%\",\n",
      "        \"sensibilidad\": \"20.69%\"\n",
      "    }\n",
      "]\n",
      "Fin: 2023-05-12 02:57:23.178232\n",
      "Tiempo: 0:01:52.091850\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
