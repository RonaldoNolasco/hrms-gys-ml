{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "6793a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "import datetime\n",
    "import traceback\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import jellyfish\n",
    "from collections import OrderedDict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "125e31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "sourceDataFolder = \"1-source-data\"\n",
    "\n",
    "bumeraniterationNumber = \"4\"\n",
    "bumeranRootPath = sourceDataFolder + r\"\\main\\bumeran\\iteration-\" + bumeraniterationNumber\n",
    "\n",
    "linkediniterationNumber = \"2\"\n",
    "linkedinRootPath = sourceDataFolder + r\"\\main\\linkedin\\iteration-\" + linkediniterationNumber\n",
    "\n",
    "intermFilesFolder = \"2-intermediate-files\"\n",
    "mergedMainFolder = \"3-merged-main\"\n",
    "logsFolder = \"4-logs\"\n",
    "\n",
    "dataVisualizationTopLimit = 20\n",
    "\n",
    "counterIn = 0\n",
    "counterOut = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "85e41e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones utilitarias\n",
    "def find_nth(haystack, needle, n):\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "\n",
    "def parseLineBreaksAndAccents(text):\n",
    "  return unidecode(\" \".join(text.split()))\n",
    "\n",
    "def parseNames(text):\n",
    "  return text.strip().title()\n",
    "\n",
    "def findTags(tag, color):\n",
    "  return tag.find(\"span\", {\"style\": 'font-size:10.0pt;font-family:\"Arial\",sans-serif;mso-fareast-font-family:\\n\"Times New Roman\";color:' + color })\n",
    "\n",
    "def getChildIndex(mainChildTags, title, color):\n",
    "  return next((index for index, tag in enumerate(mainChildTags) if ( findTags(tag, color).text == title if findTags(tag, color) else False )), None)\n",
    "\n",
    "def getSectionsIndexes(mainChildTags, color):\n",
    "  sectionsIndexes = []\n",
    "  sectionsTitle = [\"Experiencia laboral\", \"Educación\", \"Informática\", \"Idiomas\", \"Otros Conocimientos\"]\n",
    "  \n",
    "  for sectionTitle in sectionsTitle:\n",
    "    sectionIndex = getChildIndex(mainChildTags, sectionTitle, color)\n",
    "    sectionsIndexes.append(sectionIndex)\n",
    "  \n",
    "  sectionsIndexes.append(len(mainChildTags)-1)\n",
    "  return sectionsIndexes\n",
    "\n",
    "def getNextSectionIndexValid(sectionsIndexes, i):\n",
    "  while(not sectionsIndexes[i]):\n",
    "    i = i + 1\n",
    "\n",
    "  return sectionsIndexes[i]\n",
    "\n",
    "def readJson(path, encoding='utf-8', errors=None):\n",
    "  with open (path, \"r\", encoding=encoding, errors=errors) as f:\n",
    "    data = json.loads(f.read())\n",
    "  return data\n",
    "\n",
    "def writeJson(data, pathJson, encoding='utf-8'):\n",
    "  with open(pathJson, 'w', encoding=encoding) as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def writeCsv(data, pathCsv, encoding='utf-8'):\n",
    "  with open(pathCsv, 'w', newline='', encoding=encoding) as f:\n",
    "    if data:\n",
    "      writer = csv.DictWriter(f, fieldnames=data[0].keys(), lineterminator='\\n')\n",
    "      writer.writeheader()\n",
    "      writer.writerows(data)\n",
    "    else:\n",
    "      f.write(\"\")\n",
    "\n",
    "def writeTxt(data, pathTxt, encoding='utf-8'):\n",
    "  with open(pathTxt, 'w', encoding=encoding) as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "bbd47f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones principales\n",
    "def getFiles(rootPath, source):\n",
    "  # Obteniendo todas las carpetas de los perfiles\n",
    "  folders = [f for f in os.listdir(rootPath) if os.path.isdir(os.path.join(rootPath, f))]\n",
    "\n",
    "  # Definiendo la lista de archivos final\n",
    "  files = []\n",
    "\n",
    "  # Iterando sobre las carpetas\n",
    "  for folder in folders:\n",
    "    # Obteniendo los archivos por cada carpeta\n",
    "    folderFiles = [os.path.join(rootPath, folder, f) for f in os.listdir(os.path.join(rootPath, folder)) if os.path.isfile(os.path.join(rootPath, folder, f))]\n",
    "\n",
    "    # Agregando esos archivos a la lista de archivos final\n",
    "    if folderFiles:\n",
    "      files.extend(folderFiles)\n",
    "\n",
    "  # Filtros específicos por cada origen\n",
    "  if source == \"bumeran\":\n",
    "    filesFiltered = [f for f in files if (\"\\Has recibido un CV para el aviso\" in f)]\n",
    "  else:\n",
    "    filesFiltered = files\n",
    "\n",
    "  # Filtros para considerar un archivo especifico\n",
    "  filterIsIn = [\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad_(76).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\analista-funcional\\Has recibido un CV para el aviso _Analista Funcional_(110).html\"\n",
    "    #r\"1-source-data\\main\\linkedin\\iteration-2\\bandeja-entrada\\New application_ .NET Developer from Cesar Ospino.html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\a-considerar\\Has recibido un CV para el aviso _Practicante de Infrastructure & Cloud_(1).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\a-considerar\\Has recibido un CV para el aviso _Practicante de Infrastructure & Cloud_.html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad Sr. (Test Lead)_(1).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\analista-calidad\\Has recibido un CV para el aviso _Analista de Calidad_(1).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\bandeja-entrada\\Has recibido un CV para el aviso _Analista Programador Senior_Full Stack_(2).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\bandeja-entrada\\Has recibido un CV para el aviso _Analista Programador_(6).html\"\n",
    "    #r\"1-source-data\\main\\bumeran\\iteration-4\\programador-net\\Has recibido un CV para el aviso _Programador .Net Senior_(4).html\"\n",
    "  ]\n",
    "  filesFilteredIsIn = [f for f in filesFiltered if ( f in filterIsIn if filterIsIn else True )]\n",
    "\n",
    "  # Filtros para omitir un archivo especifico\n",
    "  filterIsNotIn = [\n",
    "    # 3 archivos con data incompleta\n",
    "    r\"1-source-data\\main\\bumeran\\iteration-4\\bandeja-entrada\\Has recibido un CV para el aviso _Analista Programador Senior_Full Stack_(2).html\",\n",
    "    r\"1-source-data\\main\\bumeran\\iteration-4\\bandeja-entrada\\Has recibido un CV para el aviso _Analista Programador_(6).html\",\n",
    "    r\"1-source-data\\main\\bumeran\\iteration-4\\programador-net\\Has recibido un CV para el aviso _Programador .Net Senior_(4).html\",\n",
    "    \n",
    "  ]\n",
    "  filesFilteredNotIn = [f for f in filesFilteredIsIn if ( f not in filterIsNotIn if filterIsNotIn else True )]\n",
    "\n",
    "  # Limites superiores e inferiores en la búsqueda de archivos\n",
    "  startLimit = None\n",
    "  topLimit = None\n",
    "  filesFilteredLimits = filesFilteredNotIn[(startLimit-1 if startLimit else 0): (topLimit if topLimit else len(files))]\n",
    "\n",
    "  return filesFilteredLimits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "21425e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncodingBumeran(file, stringLog):\n",
    "  encoding = \"windows-1252\"\n",
    "  try:\n",
    "    with open(file, \"r\", encoding=\"utf-16-le\") as f:\n",
    "      if \"charset=unicode\" in f.read():\n",
    "        encoding = 'utf-16-le'\n",
    "      else:\n",
    "        raise Exception\n",
    "  except Exception as e:\n",
    "    try:\n",
    "      with open(file, \"r\", encoding=\"windows-1252\") as f:\n",
    "        if \"charset=windows-1252\" in f.read():\n",
    "          encoding = 'windows-1252'\n",
    "        else:\n",
    "          encoding = encoding\n",
    "    except Exception as e:\n",
    "      print(file)\n",
    "      stringLog = stringLog + file + \"\\n\"\n",
    "      traceback.print_exc()\n",
    "      stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "      print()\n",
    "      stringLog = stringLog + \"\\n\"\n",
    "      pass\n",
    "      \n",
    "  return encoding, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "c06d9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEncodingLinkedin(file, stringLog):\n",
    "  encoding = \"windows-1256\"\n",
    "  try:\n",
    "    with open(file, \"r\", encoding=\"utf-16-le\") as f:\n",
    "      if \"charset=unicode\" in f.read():\n",
    "        encoding = 'utf-16-le'\n",
    "      else:\n",
    "        raise Exception\n",
    "  except Exception as e:\n",
    "    try:\n",
    "      with open(file, \"r\", encoding=\"windows-1256\") as f:\n",
    "        if \"charset=windows-1256\" in f.read():\n",
    "          encoding = 'windows-1256'\n",
    "        else:\n",
    "          encoding = encoding\n",
    "    except Exception as e:\n",
    "      print(file)\n",
    "      stringLog = stringLog + file + \"\\n\"\n",
    "      traceback.print_exc()\n",
    "      stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "      print()\n",
    "      stringLog = stringLog + \"\\n\"\n",
    "      pass\n",
    "      \n",
    "  return encoding, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "c6d1455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidateBumeran(file, encoding, stringLog):\n",
    "  candidateData = {}\n",
    " \n",
    "  try:\n",
    "  # Abriendo el archivo\n",
    "    with open(file, \"r\", encoding=encoding) as myFile:\n",
    "      #Parseando el archivo html a soup\n",
    "      soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
    "\n",
    "      # Obteniendo cada uno de los campos para la data\n",
    "\n",
    "      # Fecha de postulación\n",
    "      spanDates = soup.find_all(\"span\", {\"style\": \"color:black\"})\n",
    "      if len(spanDates) > 4:\n",
    "        rawPostulationDate = spanDates[3].text\n",
    "        postulationDate = datetime.datetime.strptime(spanDates[3].text, \"%A, %B %d, %Y %I:%M %p\")\n",
    "      else:\n",
    "        spanDates2 = soup.find_all(\"span\", {\"style\": 'font-family:\"Calibri\",sans-serif;color:black'})\n",
    "        rawPostulationDate = spanDates2[3].text\n",
    "        postulationDate = datetime.datetime.strptime(spanDates2[3].text, \"%A, %B %d, %Y %I:%M %p\")\n",
    "        \n",
    "      candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "      # Definiendo los colores a usar para las búsquedas según las fechas\n",
    "      # En la fecha 2020-06-11 cambio el color de los titulos de cada sección\n",
    "      inflexionDate = datetime.datetime(2020,6,11,12,5,0)\n",
    "      colorTitle, colorSections = (\"#008599\", \"#2192C9\") if postulationDate <= inflexionDate else (\"#E90066\", \"#0A26EE\")\n",
    "\n",
    "      \"\"\"# Nombre del perfil\n",
    "      candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(soup.findAll(\"span\", {\"style\": (\"color:\" + colorTitle) })[0].text))\n",
    "\n",
    "      # Nombre del postulante\n",
    "      rawcandidateName = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")[0].text # El split join tambien quita saltos de línea\n",
    "      candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(rawcandidateName))\n",
    "\n",
    "      # Pais de residencia\n",
    "      tagResidenceCountry = soup.find_all(\"ul\", {\"type\": \"disc\"})[0].find_all(\"span\")\n",
    "      if len(tagResidenceCountry) > 2:\n",
    "        if tagResidenceCountry[2].text.find(\",\") != -1:\n",
    "          residenceCountry = parseNames(parseLineBreaksAndAccents(tagResidenceCountry[2].text[0:tagResidenceCountry[2].text.find(\",\")]))\n",
    "          if residenceCountry != \"\":\n",
    "            candidateData[\"residenceCountry\"] = residenceCountry\n",
    "          else:\n",
    "            raise Exception(\"Error no mapeado 1\")\n",
    "        else:\n",
    "          # Intentando sacarlo del pais de nacimiento\n",
    "          if tagResidenceCountry[8].text.find(\",\") != -1:\n",
    "            residenceCountry = parseNames(parseLineBreaksAndAccents(tagResidenceCountry[8].text[tagResidenceCountry[8].text.rfind(\",\")+2:]))\n",
    "            if residenceCountry != \"\":\n",
    "              candidateData[\"residenceCountry\"] = residenceCountry\n",
    "            else:\n",
    "              raise Exception(\"Error no mapeado 3\")\n",
    "          else:\n",
    "            # Analizar si permitir o no\n",
    "            raise Exception(\"Error no mapeado 2\")\n",
    "      else:\n",
    "        raise Exception(\"Error no mapeado 4 (posiblemente data incompleta como los 3 casos)\")\n",
    "      \"\"\"\n",
    "      \n",
    "      mainDivTag = soup.find_all(\"div\", {\"style\": 'background-position-x:50%;background-position-y:100%'})[0]\n",
    "      mainChildTags = mainDivTag.find_all(recursive=False)\n",
    "\n",
    "      sectionsIndexes = getSectionsIndexes(mainChildTags, colorSections)\n",
    "      \n",
    "      \"\"\"# Experiencia laboral\n",
    "      startIndex, endIndex = sectionsIndexes[0], getNextSectionIndexValid(sectionsIndexes, 1)\n",
    "\n",
    "      if startIndex and endIndex:\n",
    "        workExperienceTags = mainChildTags[startIndex+2:endIndex]\n",
    "        candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(workExperienceTags[0].find_all(\"b\")[0].text))\n",
    "        candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(workExperienceTags[1].find_all(\"b\")[0].text))\n",
    "\n",
    "        # Hay un caso que tiene span ya de por si en las experiencias laborales, el html 22, revisar\n",
    "        daysOfExperience = 0\n",
    "        for index in range(0, len(workExperienceTags), 2):\n",
    "          startDate = datetime.datetime.strptime(parseLineBreaksAndAccents(workExperienceTags[index].text)[0: parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" - \")] , \"%d-%m-%Y\")\n",
    "          endDateText = parseLineBreaksAndAccents(workExperienceTags[index].text)[parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" - \")+3: parseLineBreaksAndAccents(workExperienceTags[index].text).find(\" | \")]\n",
    "          endDate = datetime.datetime.strptime(endDateText, \"%d-%m-%Y\") if endDateText != \"Presente\" else datetime.datetime.strptime(rawPostulationDate, \"%A, %B %d, %Y %I:%M %p\")\n",
    "          daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "        candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "        candidateData[\"worksNumber\"] = int(len(workExperienceTags)/2)\n",
    "      else:\n",
    "        # No tienen esta sección, se comprobo con busquedas\n",
    "        # Analizar si permitir o no\n",
    "        #candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "        #candidateData[\"yearsOfExperience\"] = 0\n",
    "        #candidateData[\"worksNumber\"] = 0\n",
    "        raise Exception(\"561 casos mapeados (no tienen experiencia laboral)\")\n",
    "      \"\"\"\n",
    "\n",
    "      \n",
    "      # Carrera profesional (última alcanzada)\n",
    "      startIndex, endIndex = sectionsIndexes[1], getNextSectionIndexValid(sectionsIndexes, 2)\n",
    "\n",
    "      if startIndex and endIndex:\n",
    "        educationTags = mainChildTags[startIndex+2:endIndex]\n",
    "\n",
    "        boldTags0 = educationTags[0].find_all(\"b\")\n",
    "        if len(boldTags0) == 0:\n",
    "          candidateData[\"studyCenter\"] = \"\"\n",
    "          candidateData[\"careerField\"] = \"\"\n",
    "        elif len(boldTags0) == 1:\n",
    "          #print(\"GA\")\n",
    "          if (parseLineBreaksAndAccents(educationTags[0].text).find(\",\") - parseLineBreaksAndAccents(educationTags[0].text).find(\" | \") == 3):\n",
    "            candidateData[\"studyCenter\"] = \"\"\n",
    "            candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "          else:\n",
    "            candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "            candidateData[\"careerField\"] = \"\"\n",
    "        else:\n",
    "          #print(\"AG\")\n",
    "          #print(educationTags[0].find_all(\"b\")[0])\n",
    "          candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(boldTags0[0].text.strip()))\n",
    "          candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(boldTags0[1].text.strip()))\n",
    "        \n",
    "        haveBoldTags1 = True if len(educationTags[1].find_all(\"b\")) > 0 else False\n",
    "\n",
    "        tempTags = educationTags[1].find_all(\"span\")\n",
    "\n",
    "        statusDegreeIndex = next(((index+1 if haveBoldTags1 else index) for index, x in enumerate( tempTags[1:] if haveBoldTags1 else tempTags ) if \",\" in x.text), None)\n",
    "        \n",
    "        if statusDegreeIndex is not None:\n",
    "          candidateData[\"careerStatus\"] = parseNames(parseLineBreaksAndAccents(educationTags[1].find_all(\"span\")[statusDegreeIndex].text.split(\",\")[1].strip()))\n",
    "          candidateData[\"careerDegree\"] = parseNames(parseLineBreaksAndAccents(educationTags[1].find_all(\"span\")[statusDegreeIndex].text.split(\",\")[2].strip()[:-1]))\n",
    "          candidateData[\"studiesNumber\"] = int(len(educationTags)/2)\n",
    "        else:\n",
    "          candidateData[\"careerStatus\"] = candidateData[\"careerDegree\"] = \"\"\n",
    "          candidateData[\"studiesNumber\"] = 0\n",
    "      else:\n",
    "        candidateData[\"studyCenter\"] = candidateData[\"careerField\"] = candidateData[\"careerStatus\"] = candidateData[\"careerDegree\"] = \"\"\n",
    "        candidateData[\"studiesNumber\"] = 0\n",
    "\n",
    "      \"\"\"\n",
    "\n",
    "      # Habilidades técnicas\n",
    "      informaticsIndex = getChildIndex(mainChildTags, \"Informática\", color)\n",
    "      languageIndex = getChildIndex(mainChildTags, \"Idiomas\", color)\n",
    "\n",
    "      if informaticsIndex and languageIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        technicalSkillsTags = mainChildTags[informaticsIndex+2:languageIndex][0].find_all(\"span\")\n",
    "        candidateData[\"technicalSkills\"] = int(len(technicalSkillsTags)/4)\n",
    "\n",
    "      else:\n",
    "        candidateData[\"technicalSkills\"] = 0\n",
    "\n",
    "      # Falta habilidades blandas\n",
    "\n",
    "      # Lenguajes\n",
    "      languageIndex = getChildIndex(mainChildTags, \"Idiomas\", color)\n",
    "      otherKnowledgesIndex = getChildIndex(mainChildTags, \"Otros Conocimientos\", color)\n",
    "\n",
    "      if languageIndex and otherKnowledgesIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        languagesTags = mainChildTags[languageIndex+2:otherKnowledgesIndex][0].find_all(\"span\")\n",
    "        candidateData[\"languages\"] = int(len(languagesTags)/7)\n",
    "\n",
    "      else:\n",
    "        candidateData[\"languages\"] = 1\n",
    "\n",
    "      # Otros conocimientos\n",
    "      otherKnowledgesIndex = getChildIndex(mainChildTags, \"Otros Conocimientos\", color)\n",
    "      endIndex = len(mainChildTags)-1\n",
    "\n",
    "      if languageIndex and otherKnowledgesIndex:\n",
    "        # Falta mejorar la validación (algunos tienen solo u, solo carrera o ninguno)\n",
    "        otherKnowledgesTags = mainChildTags[otherKnowledgesIndex+2:endIndex][0].find_all(\"span\")\n",
    "        candidateData[\"anotherSkills\"] = int(len(otherKnowledgesTags)/3)\n",
    "      else:\n",
    "        candidateData[\"anotherSkills\"] = 0\n",
    "\n",
    "      candidateData[\"references\"] = 0\n",
    "\n",
    "      # Salario pretendido\n",
    "      tagsSalary = [index for index, tag in enumerate(soup.find_all(\"span\")) if \"Sueldo pretendido\" in tag.text]\n",
    "      if len(tagsSalary) > 0:\n",
    "        rawSalary = soup.find_all(\"span\")[tagsSalary[0]+1].text\n",
    "        candidateData[\"salary\"] = int(float(parseLineBreaksAndAccents(\" \".join(rawSalary.split()))[1:].title()))\n",
    "      else:\n",
    "        candidateData[\"salary\"] = 0\"\"\"\n",
    "\n",
    "  except Exception as e:\n",
    "    candidateData = {}\n",
    "    print(file)\n",
    "    stringLog = stringLog + str(file) + \"\\n\"\n",
    "    traceback.print_exc()\n",
    "    stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "    print()\n",
    "    stringLog = stringLog + \"\\n\"\n",
    "    pass\n",
    "\n",
    "  return candidateData, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "54cef587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidateLinkedin(file, encoding, stringLog):\n",
    "  candidateData = {}\n",
    "\n",
    "  try:\n",
    "  # Abriendo el archivo\n",
    "    with open(file, \"r\", encoding=encoding) as myFile:\n",
    "      #Parseando el archivo html a soup\n",
    "      \n",
    "      soup = BeautifulSoup(myFile.read(), \"lxml\")\n",
    "\n",
    "      spanBlack = soup.find_all(\"span\", {\"style\": \"color:black\"})\n",
    "      if len(spanBlack) > 4:\n",
    "        postulationDate = datetime.datetime.strptime(spanBlack[3].text, \"%A, %B %d, %Y %I:%M %p\")\n",
    "      else:\n",
    "        spanBlack2 = soup.find_all(\"span\", {\"style\": 'font-family:\"Calibri\",sans-serif;color:black'})\n",
    "        postulationDate = datetime.datetime.strptime(spanBlack2[3].text, \"%A, %B %d, %Y %I:%M %p\")\n",
    "\n",
    "      # Cambiar el lugar de donde se saca, sacarlo del body no del asunto\n",
    "      if len(spanBlack) > 7:\n",
    "        rawProfileName = parseLineBreaksAndAccents(spanBlack[7].text)\n",
    "      else:\n",
    "        spanBlack2 = soup.find_all(\"span\", {\"style\": 'font-family:\"Calibri\",sans-serif;color:black'})\n",
    "        rawProfileName = parseLineBreaksAndAccents(spanBlack2[7].text)\n",
    "\n",
    "      startIndexProfileName = rawProfileName.find(\": \")\n",
    "      endIndexProfileName = rawProfileName.find(\" from \")\n",
    "\n",
    "      if postulationDate <= datetime.datetime(2022,9,23,2,15,0):\n",
    "        \n",
    "        candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(rawProfileName[startIndexProfileName+1:endIndexProfileName]))\n",
    "\n",
    "        candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"font-size:10.5pt;color:#262626;text-decoration:none;\\n            text-underline:none\"}).text))\n",
    "\n",
    "        tempSpanTags = soup.find_all(\"span\", {\"style\": 'font-size:9.0pt;font-family:\\n            \"Helvetica\",sans-serif;color:#737373'})\n",
    "        existsCountry = True if len(tempSpanTags) > 1 else False\n",
    "        candidateData[\"residenceCountry\"] = parseNames(parseLineBreaksAndAccents(tempSpanTags[len(tempSpanTags)-1].text)) if existsCountry else \"\"\n",
    "\n",
    "        candidateData[\"channel\"] = \"Linkedin\"\n",
    "\n",
    "        tableTags = soup.find_all(\"table\")\n",
    "\n",
    "        notHaveScreening = True if \"Screening qualifications\" not in str(soup) else False\n",
    "        startTag = 15 if notHaveScreening else 16\n",
    "        endTag = len(tableTags)-3\n",
    "        findedTableTags = tableTags[startTag:endTag]\n",
    "\n",
    "        haveTags = [None, None, None, None, None]\n",
    "\n",
    "        for index, tag in enumerate(findedTableTags):\n",
    "          haveTags[0] = index if \"Current experience\" in tag.text else haveTags[0]\n",
    "          haveTags[1] = index if \"Past experience\" in tag.text else haveTags[1]\n",
    "          haveTags[2] = index if \"Education\" in tag.text else haveTags[2]\n",
    "          haveTags[3] = index if \"Skills matching your job\" in tag.text else haveTags[3]\n",
    "          haveTags[4] = index if \"Highlight\" in tag.text else haveTags[4]\n",
    "\n",
    "        for index, haveTag in enumerate(haveTags):\n",
    "          if index == 0:\n",
    "            if haveTag is not None:\n",
    "              #spanTags = findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\") Caso particular que no vale la pena\n",
    "              #startSpanIndex = 0 if len(spanTags) == 2 else len(spanTags)-3\n",
    "              candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[1])\n",
    "              candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[0])\n",
    "            else:\n",
    "              candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "          \n",
    "          elif index == 1:\n",
    "            if haveTag is not None:\n",
    "              daysOfExperience = 0\n",
    "              trTag = findedTableTags[haveTag].find_all(\"tr\")[1]\n",
    "              pTags = trTag.find_all(\"p\")\n",
    "              for pTag in pTags:\n",
    "                spanTag = parseLineBreaksAndAccents(pTag.find_all(\"span\")[1].text)\n",
    "                startDate = datetime.datetime.strptime(spanTag.split(\" - \")[0], \"%Y\")\n",
    "                endDate = datetime.datetime.strptime(spanTag.split(\" - \")[1], \"%Y\")\n",
    "                daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "              candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "              candidateData[\"worksNumber\"] = int(len(pTags))\n",
    "            else:\n",
    "              candidateData[\"yearsOfExperience\"] = 0\n",
    "              candidateData[\"worksNumber\"] = 0\n",
    "\n",
    "          elif index == 2:\n",
    "            # No se tiene el careerStatus en linkedin\n",
    "            if haveTag is not None:\n",
    "              trTags = findedTableTags[haveTag].find_all(\"tr\")[1:]\n",
    "              #print(trTags[0])\n",
    "              firstCenterWithDateIndex = -1\n",
    "              studiesNumber = 0\n",
    "              for index, trTag in enumerate(trTags):\n",
    "                if(len(trTag.find_all(\"span\"))>1):\n",
    "                  if(len(trTags[index-1].find_all(\"span\")) == 1):\n",
    "                    if firstCenterWithDateIndex == -1:\n",
    "                      firstCenterWithDateIndex = index-1\n",
    "                if(len(trTag.find_all(\"span\"))==1):\n",
    "                  studiesNumber = studiesNumber + 1\n",
    "              \n",
    "              #print(firstCenterWithDateIndex)\n",
    "              #print(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \")[1])\n",
    "              #print(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \"))\n",
    "              #print(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\", \")[1]))\n",
    "\n",
    "              if firstCenterWithDateIndex != -1:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex].text))\n",
    "                tempTagArray = trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")\n",
    "                candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")[1])) if len(tempTagArray) > 1 else \"\"\n",
    "                candidateData[\"careerStatus\"] = \"En Curso\" if (\"Present\" in parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[1].text)) else \"Graduado\"\n",
    "                tempText = parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find_all(\"span\")[0].text.split(\",\")[0])\n",
    "                candidateData[\"careerDegree\"] = parseNames(parseLineBreaksAndAccents(tempText)) if not tempText[0:4].isnumeric() else \"\"\n",
    "              else:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[0].text))\n",
    "                candidateData[\"careerField\"] = \"\"\n",
    "                candidateData[\"careerStatus\"] = \"\"\n",
    "                candidateData[\"careerDegree\"] = \"\"\n",
    "              \n",
    "              candidateData[\"studiesNumber\"] = studiesNumber\n",
    "            else:\n",
    "              candidateData[\"studyCenter\"] = \"\"\n",
    "              candidateData[\"careerField\"] = \"\"\n",
    "              candidateData[\"careerStatus\"] = \"\"\n",
    "              candidateData[\"careerDegree\"] = \"\"\n",
    "              candidateData[\"studiesNumber\"] = 0\n",
    "          elif index == 3:\n",
    "            if haveTag is not None:\n",
    "              skillsCounter = 0\n",
    "              spanTags = findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")\n",
    "              for spanTag in spanTags:\n",
    "                if \"\".join(spanTag[\"style\"].split()) == 'font-size:10.5pt;font-family:\"Helvetica\",sans-serif;mso-fareast-font-family:\"TimesNewRoman\";color:#4D4D4D':\n",
    "                  skillsCounter = skillsCounter + 1\n",
    "              \n",
    "              candidateData[\"technicalSkills\"] = skillsCounter\n",
    "            else:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "            \n",
    "            candidateData[\"languages\"] = 1\n",
    "            candidateData[\"anotherSkills\"] = 0 if notHaveScreening else int(parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text)[parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text).find(\": \")+2: parseLineBreaksAndAccents(soup.find_all(\"table\")[10].text).find(\"/\")])\n",
    "          elif index == 4:\n",
    "            if haveTag is not None:\n",
    "              highlightText = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)\n",
    "              isKnows = True if (\"knows\" in highlightText) else False\n",
    "              #print(isKnows)\n",
    "              isMoreThanTwo = True if (\"others\" in highlightText) else False\n",
    "              if isKnows and isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" and \")+5:highlightText.find(\" others \")])\n",
    "              elif isKnows and not isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText.count(\" and \") + 1)\n",
    "              else:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" hired \")+7:highlightText.find(\" people \")])\n",
    "            else:\n",
    "              candidateData[\"references\"] = 0\n",
    "        candidateData[\"salary\"] = 0\n",
    "        \n",
    "      else:\n",
    "        candidateData[\"postulationDate\"] = postulationDate.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        candidateData[\"profileName\"] = parseNames(parseLineBreaksAndAccents(rawProfileName[startIndexProfileName+1:endIndexProfileName]))\n",
    "\n",
    "        candidateData[\"candidateName\"] = parseNames(parseLineBreaksAndAccents(soup.find(\"span\", {\"style\": \"color:#0A66C2;text-decoration:none;text-underline:none\"}).text))\n",
    "        \n",
    "        tempSpanTags = soup.find_all(\"span\", {\"style\": 'font-size:10.5pt;font-family:\"Helvetica\",sans-serif;\\n          color:#737373'})\n",
    "        existsCountry = True if len(tempSpanTags) > 1 else False\n",
    "        candidateData[\"residenceCountry\"] = parseNames(parseLineBreaksAndAccents(tempSpanTags[len(tempSpanTags)-1].text)) if existsCountry else \"\"\n",
    "\n",
    "        candidateData[\"channel\"] = \"Linkedin\"\n",
    "\n",
    "        tableTags = soup.find_all(\"table\")\n",
    "\n",
    "        startTag = 14\n",
    "        endTag = len(tableTags)-3\n",
    "        findedTableTags = tableTags[startTag:endTag]\n",
    "\n",
    "        haveTags = [None, None, None, None, None]\n",
    "\n",
    "        for index, tag in enumerate(findedTableTags):\n",
    "          haveTags[0] = index if \"Current experience\" in tag.text else haveTags[0]\n",
    "          haveTags[1] = index if \"Past experience\" in tag.text else haveTags[1]\n",
    "          haveTags[2] = index if \"Education\" in tag.text else haveTags[2]\n",
    "          haveTags[3] = index if \"Screening qualifications\" in tag.text else haveTags[3]\n",
    "          haveTags[4] = index if \"Highlight\" in tag.text else haveTags[4]\n",
    "        \n",
    "        for index, haveTag in enumerate(haveTags):\n",
    "          if index == 0:\n",
    "            if haveTag is not None:\n",
    "              tempTrTags = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")\n",
    "              #print(tempTrTags[1].find_all(\"span\")[0].text)\n",
    "              tempWorkCenter = tempTrTags[1] if len(tempTrTags) > 1 else \"\"\n",
    "              candidateData[\"lastWorkCenter\"] = parseNames(parseLineBreaksAndAccents(tempWorkCenter[0:tempWorkCenter.rfind(\" - \")-4])) if tempWorkCenter != \"\" else \"\"\n",
    "              candidateData[\"lastWorkPosition\"] = parseNames(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].find_all(\"span\")[0].text).split(\" at \")[0])\n",
    "            else:\n",
    "              candidateData[\"lastWorkCenter\"] = candidateData[\"lastWorkPosition\"] = \"\"\n",
    "          \n",
    "          elif index == 1:\n",
    "            if haveTag is not None:\n",
    "              daysOfExperience = 0\n",
    "              trTags = [x for x in findedTableTags[haveTag].find_all(\"tr\") if x.find(\"span\", {\"style\": 'font-size:9.0pt;font-family:\"Helvetica\",sans-serif;\\n          color:#737373'})]\n",
    "              #print(trTags)\n",
    "              for trTag in trTags:\n",
    "                #print(pTag.text)\n",
    "                spanTag = parseLineBreaksAndAccents(trTag.find_all(\"span\")[0].text)\n",
    "                #print(spanTag)\n",
    "                #print(\"\".isnumeric())\n",
    "                if spanTag[spanTag.rfind(\" - \")-4:spanTag.rfind(\" - \")].isnumeric() and spanTag[spanTag.rfind(\" - \")+3:spanTag.rfind(\" - \")+7].isnumeric():\n",
    "                  startDate = datetime.datetime.strptime(spanTag[spanTag.rfind(\" - \")-4:spanTag.rfind(\" - \")], \"%Y\")\n",
    "                  endDate = datetime.datetime.strptime(spanTag[spanTag.rfind(\" - \")+3:spanTag.rfind(\" - \")+7], \"%Y\")\n",
    "                  daysOfExperience = daysOfExperience + (endDate - startDate).days\n",
    "              candidateData[\"yearsOfExperience\"] = int(daysOfExperience/365)\n",
    "              candidateData[\"worksNumber\"] = int(len(trTags))\n",
    "            else:\n",
    "              candidateData[\"yearsOfExperience\"] = 0\n",
    "              candidateData[\"worksNumber\"] = 0\n",
    "\n",
    "          elif index == 2:\n",
    "            # No se tiene el careerStatus en linkedin\n",
    "            if haveTag is not None:\n",
    "              trTags = findedTableTags[haveTag].find_all(\"tr\")[1:]\n",
    "              #print(trTags[0])\n",
    "              firstCenterWithDateIndex = -1\n",
    "              studiesNumber = 0\n",
    "              for index, trTag in enumerate(trTags):\n",
    "                if \" - \" in parseLineBreaksAndAccents(trTag.text):\n",
    "                  if \" - \" not in parseLineBreaksAndAccents(trTags[index-1].text):\n",
    "                    if firstCenterWithDateIndex == -1:\n",
    "                      firstCenterWithDateIndex = index-1\n",
    "                if(\" - \" not in parseLineBreaksAndAccents(trTag.text)):\n",
    "                  studiesNumber = studiesNumber + 1\n",
    "              #print(firstCenterWithDateIndex)\n",
    "              if firstCenterWithDateIndex != -1:\n",
    "                #print(\"GA\")\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex].text))\n",
    "                tempTagArray = parseNames(parseLineBreaksAndAccents(trTags[firstCenterWithDateIndex+1].find(\"span\").text))\n",
    "                candidateData[\"careerField\"] = parseNames(parseLineBreaksAndAccents(tempTagArray[tempTagArray.find(\", \")+1:tempTagArray.rfind(\" - \")-4]))\n",
    "                candidateData[\"careerStatus\"] = \"En Curso\" if (\"Present\" in tempTagArray) else \"Graduado\"\n",
    "                candidateData[\"careerDegree\"] = parseNames(parseLineBreaksAndAccents(tempTagArray[0:tempTagArray.find(\", \")])) if tempTagArray.find(\", \") != -1 else \"\"\n",
    "                #print(candidateData)\n",
    "              else:\n",
    "                candidateData[\"studyCenter\"] = parseNames(parseLineBreaksAndAccents(trTags[0].text))\n",
    "                candidateData[\"careerField\"] = \"\"\n",
    "                candidateData[\"careerStatus\"] = \"\"\n",
    "                candidateData[\"careerDegree\"] = \"\"\n",
    "              \n",
    "              candidateData[\"studiesNumber\"] = studiesNumber\n",
    "            else:\n",
    "              candidateData[\"studyCenter\"] = \"\"\n",
    "              candidateData[\"careerField\"] = \"\"\n",
    "              candidateData[\"careerStatus\"] = \"\"\n",
    "              candidateData[\"careerDegree\"] = \"\"\n",
    "              candidateData[\"studiesNumber\"] = 0\n",
    "          \n",
    "          elif index == 3:\n",
    "            if haveTag is not None:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "              candidateData[\"languages\"] = 1\n",
    "              candidateData[\"anotherSkills\"] = int(parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)[0])\n",
    "            else:\n",
    "              candidateData[\"technicalSkills\"] = 0\n",
    "              candidateData[\"languages\"] = 1\n",
    "              candidateData[\"anotherSkills\"] = 0\n",
    "            \n",
    "          elif index == 4:\n",
    "            if haveTag is not None:\n",
    "              highlightText = parseLineBreaksAndAccents(findedTableTags[haveTag].find_all(\"tr\")[1].text)\n",
    "              #print(highlightText)\n",
    "              isKnows = True if (\"knows\" in highlightText) else False\n",
    "              #print(isKnows)\n",
    "              isMoreThanTwo = True if (\"others\" in highlightText) else False\n",
    "              if isKnows and isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" and \")+5:highlightText.find(\" others \")])\n",
    "              elif isKnows and not isMoreThanTwo:\n",
    "                candidateData[\"references\"] = int(highlightText.count(\" and \") + 1)\n",
    "              else:\n",
    "                candidateData[\"references\"] = int(highlightText[highlightText.find(\" hired \")+7:highlightText.find(\" people \")])\n",
    "            else:\n",
    "              candidateData[\"references\"] = 0\n",
    "        candidateData[\"salary\"] = 0\n",
    "      \n",
    "  except Exception as e:\n",
    "    candidateData = {}\n",
    "    print(file)\n",
    "    stringLog = stringLog + str(file) + \"\\n\"\n",
    "    traceback.print_exc()\n",
    "    stringLog = stringLog + traceback.format_exc() + \"\\n\"\n",
    "    print()\n",
    "    stringLog = stringLog + \"\\n\"\n",
    "    pass\n",
    "  \n",
    "  return candidateData, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "1799b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterateFiles(files, source):\n",
    "  # Definiendo el log de errores\n",
    "  stringLog = \"\"\n",
    "\n",
    "  # Definiendo la data final de candidatos\n",
    "  data = []\n",
    "  \n",
    "  # Iterando por cada archivo\n",
    "  for file in files:\n",
    "    # Obteniendo el encoding por cada archivo\n",
    "    encoding, stringLog = getEncodingBumeran(file, stringLog) if source == 'bumeran' else getEncodingLinkedin(file, stringLog)\n",
    "\n",
    "    # Obteniendo los datos por cada archivo\n",
    "    candidate, stringLog = getCandidateBumeran(file, encoding, stringLog) if source == 'bumeran' else getCandidateLinkedin(file, encoding, stringLog)\n",
    "    \n",
    "    # Añadiendo los datos del candidato a la data final\n",
    "    if (candidate):\n",
    "      data.append(candidate)\n",
    "\n",
    "  return data, stringLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "472c3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndWriteMain(source):\n",
    "  # Definiendo la carpeta raiz de los archivos a buscar, según el origen\n",
    "  rootPath = bumeranRootPath if source == \"bumeran\" else linkedinRootPath\n",
    "\n",
    "  # Obteniendo la lista de archivos, según el origen\n",
    "  files = getFiles(rootPath, source)\n",
    "\n",
    "  # Iterando sobre los archivos, calculando la data y el log de error\n",
    "  data, stringLog = iterateFiles(files, source)\n",
    "\n",
    "  # Escribiendo la data de los candidatos (json y csv)\n",
    "  writeJson(data, os.path.join(intermFilesFolder, source + '.json'))\n",
    "  writeCsv(data, os.path.join(intermFilesFolder, source + '.csv'))\n",
    "\n",
    "  # Escribiendo el log de errores\n",
    "  writeTxt(stringLog, os.path.join(logsFolder, source, datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".txt\"), 'utf-16')\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a8528b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndWriteMergedMain(mainData):\n",
    "  mainMergeddata = []\n",
    "  for elem in mainData:\n",
    "    if (elem):\n",
    "      mainMergeddata.extend(elem)\n",
    "\n",
    "  writeJson(mainMergeddata, os.path.join(mergedMainFolder, \"result.json\"), 'utf-8')\n",
    "  writeCsv(mainMergeddata, os.path.join(mergedMainFolder, \"result.csv\"), 'utf-8')\n",
    "\n",
    "  return mainMergeddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "2925ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeData(mergedMainData):\n",
    "  df = pd.DataFrame(mergedMainData)\n",
    "\n",
    "  print(df.count())\n",
    "\n",
    "  #columns = [\"profileName\", \"residenceCountry\", \"lastWorkCenter\", \"lastWorkPosition\", \"yearsOfExperience\", \"worksNumber\"]\n",
    "  columns = [\"lastWorkCenter\", \"lastWorkPosition\", \"yearsOfExperience\", \"worksNumber\"]\n",
    "  for column in columns:\n",
    "    top10 = df[column].value_counts()[:dataVisualizationTopLimit]\n",
    "    print(top10)\n",
    "    y_axis = list(reversed(top10.index))\n",
    "    x_axis = list(reversed(top10.values))\n",
    "    plt.ylabel(column)\n",
    "    plt.barh(y_axis, x_axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "c9021c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio: 2023-05-11 00:21:29.574163\n",
      "Se inició el procesamiento\n",
      "9794\n",
      "Se terminó de procesar Bumeran\n",
      "Se terminó de procesar Linkedin\n",
      "Se terminó de unir la data principal\n",
      "Fin: 2023-05-11 00:22:59.874156\n",
      "Tiempo: 0:01:30.299993\n",
      "9673\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  # Definiendo el inicio del proceso\n",
    "  startTime = datetime.datetime.now()\n",
    "  print(\"Inicio: \" + str(startTime))\n",
    "  print(\"Se inició el procesamiento\")\n",
    "\n",
    "  # El dataset principal que sea el de bumeran\n",
    "  # Los otros archivos que solo se usen para actualizar la variable objetivo\n",
    "  # Esto porque los otros orígenes están incompletos y costaría llenar los campos (incluso el excel que se hizo)\n",
    "  isLoadedBumeran = False\n",
    "  isLoadedLinkedin = True\n",
    "  isMergedMain = True\n",
    "  #False\n",
    "\n",
    "  # Leyendo o calculando bumeran\n",
    "  bumeranData = readJson(os.path.join(intermFilesFolder, 'bumeran.json')) if isLoadedBumeran else readAndWriteMain('bumeran')\n",
    "  print(\"Se terminó de procesar Bumeran\")\n",
    "\n",
    "  # Leyendo o calculando linkedin\n",
    "  linkedinData = readJson(os.path.join(intermFilesFolder, 'linkedin.json')) if isLoadedLinkedin else readAndWriteMain('linkedin')\n",
    "  print(\"Se terminó de procesar Linkedin\")\n",
    "\n",
    "  # Uniendo la data principal (bumeran + linkedin)\n",
    "  mergedMainData = readJson(os.path.join(mergedMainFolder, 'result.json')) if isMergedMain else readAndWriteMergedMain([bumeranData, linkedinData])\n",
    "  print(\"Se terminó de unir la data principal\")\n",
    "\n",
    "  #visualizeData(mergedMainData)\n",
    "  \n",
    "  # Definiendo el fin del proceso\n",
    "  endTime = datetime.datetime.now()\n",
    "  print(\"Fin: \" + str(endTime))\n",
    "  print(\"Tiempo: \" + str(endTime-startTime))\n",
    "\n",
    "  print(counterIn)\n",
    "  print(counterOut)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
