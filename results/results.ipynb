{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dad0ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, precision_score, confusion_matrix, accuracy_score, recall_score\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder, OrdinalEncoder\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "763cd073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "inputFolder = \"1-input\"\n",
    "processFolder = \"2-process\"\n",
    "outputFolder = \"3-output\"\n",
    "logsFolder = \"4-logs\"\n",
    "\n",
    "inputPretestFolder = inputFolder + r\"\\1-pretest\"\n",
    "inputPosttestFolder = inputFolder + r\"\\2-posttest\"\n",
    "\n",
    "dataVisualizationTopLimit = 20\n",
    "\n",
    "testSize = 0.25\n",
    "genericRandomState = 0\n",
    "splitRandomState = 0\n",
    "samplingStrategy = 0.2\n",
    "percentileNumberStd = 90\n",
    "percentileNumberCorrelation = 90\n",
    "\n",
    "splitsNumber = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c14e4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "  \"K vecinos más cercanos\": { \"name\": \"K vecinos más cercanos\", \"acronym\": \"KNN\", \"classifier\": KNeighborsClassifier(n_neighbors=1, n_jobs=-1) }, \n",
    "  \"Máquina de vectores de soporte\": { \"name\": \"Máquina de vectores de soporte\", \"acronym\": \"SVM\", \"classifier\": SVC(random_state=genericRandomState, kernel='poly') }, \n",
    "  \"Regresión logística\": { \"name\": \"Regresión logística\", \"acronym\": \"LR\", \"classifier\": LogisticRegression(random_state=genericRandomState, max_iter=200) }, \n",
    "  \"Naive bayes gaussiano\": { \"name\": \"Naive bayes gaussiano\", \"acronym\": \"GNB\", \"classifier\": GaussianNB() }, \n",
    "  \"Árbol de decisión\": { \"name\": \"Árbol de decisión\", \"acronym\": \"DT\", \"classifier\": DecisionTreeClassifier(random_state=genericRandomState) }, \n",
    "  \"Bosque aleatorio\": { \"name\": \"Bosque aleatorio\", \"acronym\": \"RF\", \"classifier\": RandomForestClassifier(random_state=genericRandomState) }, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1b048ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValidators = {\n",
    "  \"K pliegues\": { \"name\": \"K pliegues\", \"acronym\": \"KP\", \"validator\": KFold(n_splits=splitsNumber, shuffle=True, random_state=genericRandomState) }, \n",
    "  \"K pliegues estratificados\": { \"name\": \"K pliegues estratificados\", \"acronym\": \"KPE\", \"validator\": StratifiedKFold(n_splits=splitsNumber, shuffle=True, random_state=genericRandomState) }, \n",
    "  \"División aleatoria\": { \"name\": \"División aleatoria\", \"acronym\": \"DA\", \"validator\": ShuffleSplit(n_splits=splitsNumber, test_size=testSize, random_state=genericRandomState) }, \n",
    "  \"División aleatoria estratificada\": { \"name\": \"División aleatoria estratificada\", \"acronym\": \"DAE\", \"validator\": StratifiedShuffleSplit(n_splits=splitsNumber, test_size=testSize, random_state=genericRandomState) }, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "919ac9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones utilitarias de archivos\n",
    "def readCsvAsDict(filePath, delimiter=\",\", encoding=\"utf-8\", header=0, dtype={}):\n",
    "  df = pd.read_csv(filePath, delimiter=delimiter,encoding=encoding, header=header, dtype=dtype)\n",
    "  df = df.replace(np.nan, '', regex=True)\n",
    "  data = df.to_dict('records')\n",
    "  return data\n",
    "\n",
    "def readCsvAsDf(filePath, delimiter=\",\", encoding=\"utf-8\", header=0, dtype={}):\n",
    "  df = pd.read_csv(filePath, delimiter=delimiter,encoding=encoding, header=header, dtype=dtype)\n",
    "  df = df.replace(np.nan, '', regex=True)\n",
    "  return df\n",
    "\n",
    "def writeDictToCsv(data, pathCsv, encoding='utf-8'):\n",
    "  with open(pathCsv, 'w', newline='', encoding=encoding) as f:\n",
    "    if data:\n",
    "      writer = csv.DictWriter(f, fieldnames=data[0].keys(), lineterminator='\\n')\n",
    "      writer.writeheader()\n",
    "      writer.writerows(data)\n",
    "    else:\n",
    "      f.write(\"\")\n",
    "\n",
    "def writeDfToCsv(data, pathCsv, encoding='utf-8', header=True):\n",
    "  data.to_csv(path_or_buf = pathCsv, encoding = encoding, header=header, index=False)\n",
    "\n",
    "def parseTranspose(df):\n",
    "  transposedDf = df.transpose()\n",
    "  transposedDf = transposedDf.reset_index()\n",
    "  transposedDf.columns = transposedDf.iloc[0]\n",
    "  transposedDf = transposedDf[1:]\n",
    "\n",
    "  return transposedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "311c6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingData(inputPath):\n",
    "  # Leyendo datos\n",
    "  df = readCsvAsDf(inputPath)\n",
    "\n",
    "  # Balanceo de datos: Sobremuestreo aleatorio (oversampling) (1 de cada 5)\n",
    "  objectiveColumn = \"contratado\"\n",
    "  dictResults = dict(df[objectiveColumn].value_counts().sort_index())\n",
    "\n",
    "  maxKey = max(dictResults, key=dictResults.get)\n",
    "  maxValue = max(dictResults.values())\n",
    "\n",
    "  dfClassMaxKey = df[df[objectiveColumn] == maxKey]\n",
    "\n",
    "  for key, value in dictResults.items():\n",
    "    if key != maxKey:\n",
    "      dfClass = df[df[objectiveColumn] == key]\n",
    "      dfClassSampled = dfClass.sample(int(maxValue * samplingStrategy), random_state=genericRandomState, replace=True)\n",
    "      dfClassMaxKey = pd.concat([dfClassMaxKey, dfClassSampled],axis=0)\n",
    "\n",
    "  df = dfClassMaxKey\n",
    "\n",
    "  # Aleatorizacion del orden de los registros para evitar sesgos(filas)\n",
    "  df = df.sample(frac = 1, random_state=genericRandomState).reset_index(drop=True)\n",
    "\n",
    "  # Aplicando OrdinalEncoding a las variables categóricas ordinales()\n",
    "  encoder = OrdinalEncoder(categories=[[ \"Abandonado\", \"En Curso\", \"Graduado\" ]])\n",
    "  encoder.fit(df[[\"estadoUltimoEstudio\"]])\n",
    "  df[\"estadoUltimoEstudio\"] = encoder.transform(df[[\"estadoUltimoEstudio\"]])\n",
    "  encoder = OrdinalEncoder(categories=[[ \"Otro\", \"Secundario\", \"Terciario/Tecnico\", \"Universitario\", \"Posgrado\", \"Master\", \"Doctorado\" ]])\n",
    "  encoder.fit(df[[\"gradoUltimoEstudio\"]])\n",
    "  df[\"gradoUltimoEstudio\"] = encoder.transform(df[[\"gradoUltimoEstudio\"]])\n",
    "\n",
    "  # Aplicando OneHotEncoding a las variables categóricas cardinales (transformación a numéricas mediante columnas)\n",
    "  categoricalColumns = [columnName for columnName, columnType in df.dtypes.to_dict().items() if columnName not in [ \"contratado\" ] and columnType == \"object\" ]\n",
    "  categoricalCardinalColumns = [columnName for columnName in categoricalColumns if columnName not in [ \"estadoUltimoEstudio\", \"gradoUltimoEstudio\" ]]\n",
    "  for column in categoricalCardinalColumns:\n",
    "    dummies = pd.get_dummies(df[[column]], prefix=column, dummy_na=True)\n",
    "    df = pd.concat([df, dummies], axis = 1)\n",
    "    df = df.drop(columns=[column])\n",
    "\n",
    "  # Aplicando MinMaxScaler a las variables numéricas (normalización) (esto tambien incluye a lastEducationStatus y lastEducationDegree, ya numéricas)\n",
    "  # Algunas quedaran en 0.9999, esto porque no todas manejan la misma escala (sin decimales, o solo un decimal)\n",
    "  numericalColumns = [columnName for columnName, columnType in df.dtypes.to_dict().items() if columnName not in [ \"contratado\" ] and columnType == \"float64\" ]\n",
    "  for column in numericalColumns:\n",
    "    df[column] = df[column].fillna(0.0)\n",
    "  mms = MinMaxScaler()\n",
    "  df[numericalColumns] = mms.fit_transform(df[numericalColumns])\n",
    "\n",
    "  # Eliminando columnas con varianza cercana a cero, dejando el 10% de columnas con mayor varianza (variables no afectan en el resultado del modelo)\n",
    "  df.loc['std'] = df.std()\n",
    "  stdArray = df.iloc[len(df)-1]\n",
    "  nthPercentileStd = np.percentile(stdArray, percentileNumberStd)\n",
    "  df = df.transpose()\n",
    "  df = df[df[\"std\"]>nthPercentileStd]\n",
    "  df = df.transpose()\n",
    "  df = df.drop(['std'], axis=0)\n",
    "\n",
    "  # Eliminando columnas con correlación cercana a uno, dejando el 90% de columnas con menor correlación\n",
    "  correlationMatrix = df.corr().abs()\n",
    "  correlationMatrix[correlationMatrix == 1.0] = 0.0\n",
    "  maxCorrelationValues = [max(correlationMatrix[column]) for column in correlationMatrix.columns]\n",
    "  nthPercentileCorrelation = np.percentile(maxCorrelationValues, percentileNumberCorrelation)\n",
    "  highCorrelationColumns = [column for column in correlationMatrix.columns if max(correlationMatrix[column]) > nthPercentileCorrelation]\n",
    "  df = df.drop(highCorrelationColumns, axis=1)\n",
    "\n",
    "  writeDfToCsv(df, os.path.join(processFolder, 'result.csv'))\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79259fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMetricsCharts(metricsList, context, unit):\n",
    "  metrics = [\n",
    "    {\"exactitud\": \"Exactitud\"},\n",
    "    {\"precision\": \"Precisión\"},\n",
    "    {\"sensibilidad\": \"Sensibilidad\"},\n",
    "    {\"robustez\": \"Robustez\"},\n",
    "    {\"tiempoPromedio\": \"Tiempo promedio\"},\n",
    "    {\"promedioMetricas\": \"Promedio de métricas\"},\n",
    "  ]\n",
    "\n",
    "  for metric in metrics:\n",
    "    key = list(metric.keys())[0]\n",
    "    value = metric[key]\n",
    "\n",
    "    if key != \"tiempoPromedio\":\n",
    "      data = {}\n",
    "      for elem in metricsList:\n",
    "        data[\"\\n\".join(elem[context].split(\" \"))] = float(elem[key].strip('%')) / 100\n",
    "      \n",
    "      keys = list(data.keys())\n",
    "      values = list(data.values())\n",
    "        \n",
    "      fig = plt.figure(figsize = (10, 5))\n",
    "      \n",
    "      sortedValues = sorted(values)\n",
    "      maxValue, secondMaxValue, thirdMaxValue = sortedValues[len(sortedValues)-1], sortedValues[len(sortedValues)-2], sortedValues[len(sortedValues)-3]\n",
    "      colors = ['tab:red' if (elem == maxValue) else ('tab:blue' if elem == secondMaxValue else ('tab:blue' if elem == thirdMaxValue else 'tab:blue')) for elem in values]\n",
    "      plt.bar(keys, values, width = 0.4, color=colors)\n",
    "      \n",
    "      plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "      plt.ylabel(\"Porcentaje\")\n",
    "      plt.title(\"{} por {}\".format(value, unit))\n",
    "      plt.show()\n",
    "    else:\n",
    "      data = {}\n",
    "      for elem in metricsList:\n",
    "        data[\"\\n\".join(elem[context].split(\" \"))] = float(elem[key])\n",
    "      \n",
    "      keys = list(data.keys())\n",
    "      values = list(data.values())\n",
    "        \n",
    "      fig = plt.figure(figsize = (10, 5))\n",
    "          \n",
    "      sortedValues = sorted(values, reverse=True)\n",
    "      maxValue, secondMaxValue, thirdMaxValue = sortedValues[len(sortedValues)-1], sortedValues[len(sortedValues)-2], sortedValues[len(sortedValues)-3]\n",
    "      colors = ['tab:red' if (elem == maxValue) else ('tab:blue' if elem == secondMaxValue else ('tab:blue' if elem == thirdMaxValue else 'tab:blue')) for elem in values]\n",
    "      plt.bar(keys, values, width = 0.4, color=colors)\n",
    "      \n",
    "      plt.gca().yaxis.set_major_formatter(mtick.FuncFormatter(lambda x, y: \"{:.3f}\".format(x) + \"ms\"))\n",
    "      plt.ylabel(\"Milisegundos\")\n",
    "      plt.title(\"{} por {}\".format(value, unit))\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49ddd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X, y):\n",
    "  # Dividiendo los dataframes de entrenamiento y prueba\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testSize, random_state=splitRandomState)\n",
    "\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2be135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(X_train, X_test, y_train, y_test, algorithm):\n",
    "  # Creación del clasificador\n",
    "  clf = classifiers[algorithm][\"classifier\"]\n",
    "\n",
    "  # Entrenamiento del clasificador\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  # Calculando la predicción del modelo con la data de prueba\n",
    "  y_pred = clf.predict(X_test)\n",
    "\n",
    "  return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1887988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(y_train, y_test, y_pred, startDate, endDate, algorithm, iterationNumber = None, partitionNumber = None, technique = None):\n",
    "  trainRows = len(y_train)\n",
    "  testRows = len(y_test)\n",
    "\n",
    "  # Calculando la exactitud del modelo\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "  # Calculando la precisión del modelo\n",
    "  precision = precision_score(y_test, y_pred)\n",
    "\n",
    "  # Calculando la sensibilidad del modelo\n",
    "  recall = recall_score(y_test, y_pred)\n",
    "\n",
    "  # Calculando el valor F del modelo (robustez)\n",
    "  f1Score = f1_score(y_test, y_pred)\n",
    "\n",
    "  # Calculando el promedio de métricas\n",
    "  metricsList = [accuracy, precision, recall, f1Score]\n",
    "  metricsMean = sum(metricsList) / len(metricsList)\n",
    "\n",
    "  # Calculando el tiempo de ejecución del modelo\n",
    "  executionTime = (endDate - startDate).total_seconds() * 1000\n",
    "\n",
    "  # Obteniendo la matriz de confusión\n",
    "  confussionMatrix = str(confusion_matrix(y_test, y_pred).tolist())\n",
    "  \n",
    "  return {\n",
    "    \"sigla\": crossValidators[technique][\"acronym\"],\n",
    "    \"algoritmo\": algorithm,\n",
    "    \"iteración\": \"Iteración {}\".format(iterationNumber) if iterationNumber is not None else \"Total de datos\",\n",
    "    \"particion\": \"Partición {}\".format(partitionNumber) if partitionNumber is not None else \"Total de datos\",\n",
    "    \"tecnicaValidacion\": technique if technique is not None else \"Ninguna\",\n",
    "    \"registrosEntrenamiento\": trainRows,\n",
    "    \"registrosPrueba\": testRows,\n",
    "    \"proporcionSobremuestreo\": samplingStrategy,\n",
    "    \"matrizConfusion\": confussionMatrix,\n",
    "    \"exactitud\": \"{:.2%}\".format(accuracy),\n",
    "    \"precision\": \"{:.2%}\".format(precision),\n",
    "    \"sensibilidad\": \"{:.2%}\".format(recall),\n",
    "    \"robustez\": \"{:.2%}\".format(f1Score),\n",
    "    \"tiempoPromedio\": \"{:.3f}\".format(executionTime/(trainRows + testRows)),\n",
    "    \"promedioMetricas\": \"{:.2%}\".format(metricsMean),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccf7a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(df, algorithm):\n",
    "  # Creando el arreglo de metricas de cada algoritmo\n",
    "  techniquesMetricsList = []\n",
    "\n",
    "  # Lectura de las variables de características y objetivo\n",
    "  objectiveColumn = \"contratado\"\n",
    "  X = df.drop([objectiveColumn], axis=1)\n",
    "  y = df[objectiveColumn]\n",
    "\n",
    "  # Iterando por cada validacion cruzada\n",
    "  for key, value in crossValidators.items():\n",
    "    for index, (train_index, test_index) in enumerate(value[\"validator\"].split(X, y)):\n",
    "      X_train, X_test, y_train, y_test = X.iloc[train_index, :], X.iloc[test_index, :], y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "      # Mostrando que partición se usa\n",
    "      print(\"Ejecutando para: Técnica {} - Partición {}\".format(key, index+1))\n",
    "\n",
    "      # Inicio de ejecución\n",
    "      startDate = datetime.datetime.now()\n",
    "\n",
    "      # Realizar entrenamiento del modelo\n",
    "      y_test, y_pred = trainModel(X_train, X_test, y_train, y_test, algorithm)\n",
    "\n",
    "      # Fin de ejecución del modelo\n",
    "      endDate = datetime.datetime.now()\n",
    "\n",
    "      # Obteniendo las métricas de la partición del modelo\n",
    "      partitionMetrics = getMetrics(y_train, y_test, y_pred, startDate, endDate, algorithm, partitionNumber=index+1, technique=key)\n",
    "\n",
    "      # Añadiendo la métrica de la partición a la lista de métricas\n",
    "      techniquesMetricsList.append(partitionMetrics)\n",
    "\n",
    "  # Pasando a dataframe\n",
    "  techniquesMetricsListDf = pd.DataFrame(techniquesMetricsList)\n",
    "  techniquesMetricsListTransposedDf = parseTranspose(techniquesMetricsListDf)\n",
    "\n",
    "  writeDfToCsv(techniquesMetricsListDf, os.path.join(outputFolder, 'result.csv'))\n",
    "  writeDfToCsv(techniquesMetricsListTransposedDf, os.path.join(outputFolder, 'result_transposed.csv'))\n",
    "\n",
    "  return techniquesMetricsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89109e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummary(techniquesMetricsList, context):\n",
    "  summary = []\n",
    "  for key, value in itertools.groupby(techniquesMetricsList, key=lambda x:x[context]):\n",
    "    copyValue = list(value).copy()\n",
    "    summary.append({\n",
    "      \"sigla\": crossValidators[key][\"acronym\"],\n",
    "      \"tecnicaValidacion\": key,\n",
    "      \"exactitud\": \"{:.2%}\".format(sum(float(elem[\"exactitud\"].strip('%')) / 100 for elem in copyValue) / len(copyValue)),\n",
    "      \"precision\": \"{:.2%}\".format(sum(float(elem[\"precision\"].strip('%')) / 100 for elem in copyValue) / len(copyValue)),\n",
    "      \"sensibilidad\": \"{:.2%}\".format(sum(float(elem[\"sensibilidad\"].strip('%')) / 100 for elem in copyValue) / len(copyValue)),\n",
    "      \"robustez\": \"{:.2%}\".format(sum(float(elem[\"robustez\"].strip('%')) / 100 for elem in copyValue) / len(copyValue)),\n",
    "      \"tiempoPromedio\": \"{:.3f}\".format(sum(float(elem[\"tiempoPromedio\"]) for elem in copyValue) / len(copyValue)),\n",
    "      \"promedioMetricas\": \"{:.2%}\".format(sum(float(elem[\"promedioMetricas\"].strip('%')) / 100 for elem in copyValue) / len(copyValue)),\n",
    "    })\n",
    "\n",
    "  return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83f3c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  # Definiendo el inicio del proceso\n",
    "  startTime = datetime.datetime.now()\n",
    "  print(\"Inicio: \" + str(startTime))\n",
    "\n",
    "  # Obteniendo pretest y postest\n",
    "  print(\"Obteniendo pretest y postest\")\n",
    "  preTest = readCsvAsDf(os.path.join(inputPretestFolder, 'result.csv'))\n",
    "  postTest = readCsvAsDf(os.path.join(inputPosttestFolder, 'result.csv'))\n",
    "\n",
    "  columns = [\"exactitud\", \"precision\", \"sensibilidad\", \"robustez\", \"tiempoPromedio\"]\n",
    "\n",
    "  for column in columns:\n",
    "    print(\"{}\".format(column))\n",
    "    preTestValues = preTest[column].to_numpy()\n",
    "    print(preTestValues)\n",
    "    postTestValues = postTest[column].to_numpy()\n",
    "    print(postTestValues)\n",
    "\n",
    "    pValue = stats.shapiro(preTestValues).pvalue\n",
    "    print(pValue)\n",
    "    pValue = stats.shapiro(postTestValues).pvalue\n",
    "    print(pValue)\n",
    "    pValue = stats.ttest_ind(preTestValues, postTestValues).pvalue\n",
    "    print(pValue)\n",
    "\n",
    "    print()\n",
    "\n",
    "  # Definiendo el fin del proceso\n",
    "  endTime = datetime.datetime.now()\n",
    "  print(\"Fin: \" + str(endTime))\n",
    "  print(\"Tiempo: \" + str(endTime-startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c95c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio: 2023-07-05 02:31:56.836319\n",
      "Obteniendo pretest y postest\n",
      "exactitud\n",
      "[0.9125 0.9046 0.9112 0.9089 0.9404 0.9327 0.9317 0.9377 0.883  0.8698\n",
      " 0.8794 0.8847 0.9579 0.9629 0.9619 0.9592 0.9927 0.993  0.995  0.994\n",
      " 0.8844 0.8797 0.8837 0.8834]\n",
      "[0.992  0.994  0.9975 0.9985 0.9955 0.993  0.994  0.999  0.998  0.9955\n",
      " 0.9985 0.992  0.9927 0.9927 0.992  0.994  0.9964 0.9944 0.995  0.9964\n",
      " 0.994  0.9954 0.9954 0.993 ]\n",
      "0.023081181570887566\n",
      "0.12225081771612167\n",
      "4.291083711978403e-10\n",
      "\n",
      "precision\n",
      "[0.7109 0.6875 0.7137 0.7027 1.     0.9898 0.9863 1.     0.8153 0.6957\n",
      " 0.7451 0.8016 0.8199 0.8381 0.8247 0.8222 1.     1.     1.     0.9979\n",
      " 0.9675 0.9448 0.9481 0.9744]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "0.0012874049134552479\n",
      "1.0\n",
      "6.003915713475798e-06\n",
      "\n",
      "sensibilidad\n",
      "[0.783  0.7602 0.7546 0.78   0.6349 0.5935 0.5869 0.624  0.3671 0.3577\n",
      " 0.3885 0.404  0.9513 0.9573 0.9714 0.962  0.9554 0.9573 0.9693 0.966\n",
      " 0.3022 0.2785 0.2986 0.304 ]\n",
      "[0.9498 0.9652 0.985  0.9912 0.9711 0.9615 0.9642 0.994  0.9881 0.9731\n",
      " 0.991  0.9522 0.9554 0.9569 0.9531 0.9647 0.9774 0.9664 0.9702 0.9781\n",
      " 0.9642 0.9722 0.9722 0.9583]\n",
      "0.00302948709577322\n",
      "0.2760642468929291\n",
      "1.0125984488953517e-06\n",
      "\n",
      "robustez\n",
      "[0.7452 0.722  0.7336 0.7393 0.7767 0.7421 0.7359 0.7685 0.5063 0.4725\n",
      " 0.5108 0.5372 0.8808 0.8937 0.892  0.8866 0.9772 0.9782 0.9844 0.9817\n",
      " 0.4606 0.4301 0.4541 0.4634]\n",
      "[0.9743 0.9823 0.9924 0.9956 0.9853 0.9804 0.9818 0.997  0.994  0.9864\n",
      " 0.9955 0.9755 0.9772 0.978  0.976  0.982  0.9886 0.9829 0.9849 0.9889\n",
      " 0.9818 0.9859 0.9859 0.9787]\n",
      "0.013519257307052612\n",
      "0.29270046949386597\n",
      "2.640560736941716e-08\n",
      "\n",
      "tiempoPromedio\n",
      "[0.1808 0.1786 0.1686 0.1758 1.6283 1.586  1.5818 1.6019 0.1912 0.1902\n",
      " 0.1911 0.2082 0.1572 0.1365 0.1466 0.146  0.3129 0.3109 0.3178 0.3116\n",
      " 1.2774 1.2736 1.2825 1.2731]\n",
      "[0.3463 0.3448 0.3443 0.3517 0.3476 0.3608 0.3469 0.3396 0.3632 0.3431\n",
      " 0.343  0.382  0.3457 0.3222 0.3192 0.3368 0.3095 0.3245 0.3303 0.3196\n",
      " 0.325  0.3286 0.3114 0.3106]\n",
      "1.259737564396346e-05\n",
      "0.3819613456726074\n",
      "0.027295841972276354\n",
      "\n",
      "Fin: 2023-07-05 02:31:56.845288\n",
      "Tiempo: 0:00:00.008969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ronaldo\\anaconda3\\lib\\site-packages\\scipy\\stats\\_morestats.py:1813: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "C:\\Users\\Ronaldo\\AppData\\Local\\Temp\\ipykernel_22416\\477528041.py:24: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  pValue = stats.ttest_ind(preTestValues, postTestValues).pvalue\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
