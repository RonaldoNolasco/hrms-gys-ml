{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dad0ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, confusion_matrix, accuracy_score, recall_score\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "import datetime\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "763cd073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "inputFolder = \"1-input\"\n",
    "processFolder = \"2-process\"\n",
    "outputFolder = \"3-output\"\n",
    "logsFolder = \"4-logs\"\n",
    "\n",
    "dataVisualizationTopLimit = 20\n",
    "\n",
    "testSize = 0.25\n",
    "randomState = 0\n",
    "partitionsNumber = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "919ac9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer datos de un archivo csv\n",
    "def readData(filePath, delimiter, encoding, header):\n",
    "  data = pd.read_csv(filePath, delimiter=delimiter,encoding=encoding, header=header)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "311c6377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingData(data):\n",
    "  # Aca no se realizará ni parseo ni nada, ya vendrá desde la fuente\n",
    "  # Solo se leerá, se dividirá y se entrenará\n",
    "\n",
    "  # Desordenando la data (filas)\n",
    "  data = data.sample(frac = 1, random_state=randomState).reset_index(drop=True)\n",
    "\n",
    "  # Obteniendo tipos de datos de las columnas\n",
    "  types = data.dtypes.to_dict()\n",
    "\n",
    "  # Estandarizando el tipo de la variable objetivo a entero\n",
    "  objectiveColumn = \"hired\"\n",
    "  data[objectiveColumn] = data[objectiveColumn]\n",
    "\n",
    "  # Aplicando OneHotEncoding a las variables categóricas (transformación a numéricas y normalización)\n",
    "  categoricalColumns = [columnName for columnName, columnType in types.items() if columnName not in [ \"hired\" ] and columnType == \"object\" ]\n",
    "  transformer = make_column_transformer( (OneHotEncoder(sparse=False), categoricalColumns), remainder='passthrough')\n",
    "  transformed = transformer.fit_transform(data)\n",
    "  data = pd.DataFrame(transformed, columns=transformer.get_feature_names())\n",
    "\n",
    "  # Aplicando MinMaxScaler a las variables numéricas (normalización)\n",
    "  numericalColumns = [columnName for columnName, columnType in types.items() if columnName not in [ \"hired\" ] and columnType == \"int64\" ]\n",
    "  mms = MinMaxScaler()\n",
    "  data[numericalColumns] = mms.fit_transform(data[numericalColumns])\n",
    "\n",
    "  # Lectura de las variables de características y objetivo\n",
    "  X = data.drop([objectiveColumn], axis=1)\n",
    "  y = data[objectiveColumn]\n",
    "\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49ddd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X, y, partitionNumber):\n",
    "  # Dividiendo los dataframes de entrenamiento y prueba\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testSize, random_state=randomState)\n",
    "\n",
    "  if partitionNumber != 0:\n",
    "    # Obteniendo el total de filas del dataframe de testeo\n",
    "    X_train, X_test, y_train, y_test = X_train.reset_index(drop=True), X_test.reset_index(drop=True), y_train.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "    totalRows = len(X_train)\n",
    "\n",
    "    # Determinando el límite inferior (primera fila) de la partición\n",
    "    bottomLimit = int(totalRows*testSize*(partitionNumber-1)) + 1\n",
    "\n",
    "    # Determinando el límite superior (última fila) de la partición\n",
    "    topLimit = int(totalRows*testSize*partitionNumber)\n",
    "\n",
    "    # Determinando una lista con todas los numeros de las filas con la partición\n",
    "    testList = [x for x in range(bottomLimit-1, topLimit)]\n",
    "\n",
    "    # Determinando los dataframes de las categorías\n",
    "    X_train, X_test = X_train[~X_train.index.isin(testList)], X_train[X_train.index.isin(testList)]\n",
    "\n",
    "    # Determinando los dataframes de los objetivos\n",
    "    y_train, y_test = y_train[~y_train.index.isin(testList)], y_train[y_train.index.isin(testList)]\n",
    "\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18fae5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createClassifier(modelName, parameters):\n",
    "  if modelName == \"KNN\":\n",
    "    return KNeighborsClassifier(parameters) if parameters is not None else KNeighborsClassifier()\n",
    "  elif modelName == \"LR\":\n",
    "    return LogisticRegression(parameters) if parameters is not None else LogisticRegression()\n",
    "  elif modelName == \"GNB\":\n",
    "    return GaussianNB(parameters) if parameters is not None else GaussianNB()\n",
    "  elif modelName == \"DT\":\n",
    "    return DecisionTreeClassifier(parameters) if parameters is not None else DecisionTreeClassifier()\n",
    "  elif modelName == \"SVM\":\n",
    "    return SVC(parameters) if parameters is not None else SVC()\n",
    "  elif modelName == \"RF\":\n",
    "    return RandomForestClassifier(parameters) if parameters is not None else RandomForestClassifier()\n",
    "  elif modelName == \"GB\":\n",
    "    return GradientBoostingClassifier(parameters) if parameters is not None else GradientBoostingClassifier()\n",
    "  else:\n",
    "    return KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2be135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(X_train, X_test, y_train, y_test, modelName, parameters = None):\n",
    "  # Creación del clasificador KNN\n",
    "  clf = createClassifier(modelName, parameters)\n",
    "\n",
    "  # Entrenamiento del clasificador KNN\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  # Calculando la predicción del modelo con la data de prueba\n",
    "  y_pred = clf.predict(X_test)\n",
    "\n",
    "  return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1887988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(y_train, y_test, y_pred, startDate, endDate, partitionNumber, algorithm = \"KNN\"):\n",
    "  trainRows = len(y_train)\n",
    "  testRows = len(y_test)\n",
    "\n",
    "  # Calculando la exactitud del modelo\n",
    "  accuracy = \"{:.2%}\".format(accuracy_score(y_test, y_pred))\n",
    "\n",
    "  # Calculando la precisión del modelo\n",
    "  precision = \"{:.2%}\".format(precision_score(y_test, y_pred))\n",
    "\n",
    "  # Calculando la sensibilidad del modelo\n",
    "  recall = \"{:.2%}\".format(recall_score(y_test, y_pred))\n",
    "\n",
    "  # Calculando el valor F del modelo (robustez)\n",
    "  f1Score = \"{:.2%}\".format(f1_score(y_test, y_pred))\n",
    "\n",
    "  # Calculando el tiempo de ejecución del modelo\n",
    "  executionTime = str(int((endDate - startDate).total_seconds() * 1000)) + \"ms\"\n",
    "\n",
    "  confussionMatrix = str(confusion_matrix(y_test, y_pred).tolist())\n",
    "  \n",
    "  return {\n",
    "    \"algoritmo\": algorithm,\n",
    "    \"tipo\": \"Total de datos\" if partitionNumber == 0 else \"Particion \" + str(partitionNumber),\n",
    "    \"registrosEntrenamiento\": trainRows,\n",
    "    \"registrosPrueba\": testRows,\n",
    "    \"tiempoEjecucion\": executionTime,\n",
    "    \"matrizConfusion\": confussionMatrix,\n",
    "    \"exactitud\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"sensibilidad\": recall,\n",
    "    \"valorF\": f1Score,\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83f3c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  # Definiendo el inicio del proceso\n",
    "  startTime = datetime.datetime.now()\n",
    "  print(\"Inicio: \" + str(startTime))\n",
    "  print(\"Se inició el procesamiento\")\n",
    "  print()\n",
    "\n",
    "  # Leyendo la data\n",
    "  data = readData(os.path.join(inputFolder, \"result.csv\"), ',', 'utf-8', 0)\n",
    "\n",
    "  # Determinando los dataframes de las categorías (X) y el objetivo (y)\n",
    "  X, y = preprocessingData(data)\n",
    "\n",
    "  # Creando el arreglo de metricas de cada partición\n",
    "  metricsList = []\n",
    "\n",
    "  # Iterando sobre cada partición\n",
    "  for partitionNumber in range(0,partitionsNumber+1):\n",
    "    # Separando data para el entrenamiento y testeo\n",
    "    X_train, X_test, y_train, y_test = splitData(X, y, partitionNumber)\n",
    "\n",
    "    models = [\"KNN\", \"LR\", \"GNB\", \"DT\", \"RF\", \"GB\"]\n",
    "\n",
    "    for model in models:\n",
    "      print(\"Calculando para el algoritmo {}\".format(model))\n",
    "\n",
    "      # Inicio de ejecución del modelo\n",
    "      startDate = datetime.datetime.now()\n",
    "      print(\"Inicio: \" + str(startDate))\n",
    "      \n",
    "      # Realizar entrenamiento del modelo\n",
    "      y_test, y_pred = trainModel(X_train, X_test, y_train, y_test, model)\n",
    "\n",
    "      # Fin de ejecución del modelo\n",
    "      endDate = datetime.datetime.now()\n",
    "      print(\"Fin: \" + str(endDate))\n",
    "      print(\"Tiempo: \" + str(endDate-startDate))\n",
    "      print()\n",
    "\n",
    "      # Obteniendo las métricas de la partición del modelo\n",
    "      metrics = getMetrics(y_train, y_test, y_pred, startDate, endDate, partitionNumber, model)\n",
    "\n",
    "      # Añadiendo la métrica de la partición a la lista de métricas\n",
    "      metricsList.append(metrics)\n",
    "\n",
    "  # Ordenando las métricas\n",
    "  metricsList = sorted(metricsList, key=lambda x: (x[\"algoritmo\"], x[\"tipo\"]))\n",
    "\n",
    "  # Mostrando las métricas\n",
    "  metricsListPretty = json.dumps(metricsList, indent=4)\n",
    "  print(metricsListPretty)\n",
    "    \n",
    "  # Escribiendo las metricas en un archivo de salida\n",
    "  with open(os.path.join(outputFolder, datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\") + \".json\"), \"w\") as f:\n",
    "      json.dump(metricsList, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "  # Definiendo el fin del proceso\n",
    "  endTime = datetime.datetime.now()\n",
    "  print(\"Fin: \" + str(endTime))\n",
    "  print(\"Tiempo: \" + str(endTime-startTime))\n",
    "  \n",
    "  # Retornando la lista de métricas\n",
    "  return metricsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c95c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio: 2023-05-21 22:15:19.843091\n",
      "Se inició el procesamiento\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando para el algoritmo KNN\n",
      "Inicio: 2023-05-21 22:15:24.132500\n",
      "Fin: 2023-05-21 22:15:27.152667\n",
      "Tiempo: 0:00:03.020167\n",
      "\n",
      "Calculando para el algoritmo LR\n",
      "Inicio: 2023-05-21 22:15:27.158657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ronaldo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fin: 2023-05-21 22:15:33.855286\n",
      "Tiempo: 0:00:06.696629\n",
      "\n",
      "Calculando para el algoritmo GNB\n",
      "Inicio: 2023-05-21 22:15:33.858848\n",
      "Fin: 2023-05-21 22:15:35.797995\n",
      "Tiempo: 0:00:01.939147\n",
      "\n",
      "Calculando para el algoritmo DT\n",
      "Inicio: 2023-05-21 22:15:35.802930\n",
      "Fin: 2023-05-21 22:16:23.521512\n",
      "Tiempo: 0:00:47.718582\n",
      "\n",
      "Calculando para el algoritmo RF\n",
      "Inicio: 2023-05-21 22:16:23.526495\n",
      "Fin: 2023-05-21 22:16:39.190667\n",
      "Tiempo: 0:00:15.664172\n",
      "\n",
      "Calculando para el algoritmo GB\n",
      "Inicio: 2023-05-21 22:16:39.194654\n",
      "Fin: 2023-05-21 22:17:40.937822\n",
      "Tiempo: 0:01:01.743168\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"algoritmo\": \"DT\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 7666,\n",
      "        \"registrosPrueba\": 2556,\n",
      "        \"tiempoEjecucion\": \"47718ms\",\n",
      "        \"matrizConfusion\": \"[[2404, 20], [79, 53]]\",\n",
      "        \"exactitud\": \"96.13%\",\n",
      "        \"precision\": \"72.60%\",\n",
      "        \"sensibilidad\": \"40.15%\",\n",
      "        \"valorF\": \"51.71%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"GB\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 7666,\n",
      "        \"registrosPrueba\": 2556,\n",
      "        \"tiempoEjecucion\": \"61743ms\",\n",
      "        \"matrizConfusion\": \"[[2424, 0], [120, 12]]\",\n",
      "        \"exactitud\": \"95.31%\",\n",
      "        \"precision\": \"100.00%\",\n",
      "        \"sensibilidad\": \"9.09%\",\n",
      "        \"valorF\": \"16.67%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"GNB\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 7666,\n",
      "        \"registrosPrueba\": 2556,\n",
      "        \"tiempoEjecucion\": \"1939ms\",\n",
      "        \"matrizConfusion\": \"[[1929, 495], [56, 76]]\",\n",
      "        \"exactitud\": \"78.44%\",\n",
      "        \"precision\": \"13.31%\",\n",
      "        \"sensibilidad\": \"57.58%\",\n",
      "        \"valorF\": \"21.62%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"KNN\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 7666,\n",
      "        \"registrosPrueba\": 2556,\n",
      "        \"tiempoEjecucion\": \"3020ms\",\n",
      "        \"matrizConfusion\": \"[[2408, 16], [112, 20]]\",\n",
      "        \"exactitud\": \"94.99%\",\n",
      "        \"precision\": \"55.56%\",\n",
      "        \"sensibilidad\": \"15.15%\",\n",
      "        \"valorF\": \"23.81%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"LR\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 7666,\n",
      "        \"registrosPrueba\": 2556,\n",
      "        \"tiempoEjecucion\": \"6696ms\",\n",
      "        \"matrizConfusion\": \"[[2424, 0], [116, 16]]\",\n",
      "        \"exactitud\": \"95.46%\",\n",
      "        \"precision\": \"100.00%\",\n",
      "        \"sensibilidad\": \"12.12%\",\n",
      "        \"valorF\": \"21.62%\"\n",
      "    },\n",
      "    {\n",
      "        \"algoritmo\": \"RF\",\n",
      "        \"tipo\": \"Total de datos\",\n",
      "        \"registrosEntrenamiento\": 7666,\n",
      "        \"registrosPrueba\": 2556,\n",
      "        \"tiempoEjecucion\": \"15664ms\",\n",
      "        \"matrizConfusion\": \"[[2424, 0], [84, 48]]\",\n",
      "        \"exactitud\": \"96.71%\",\n",
      "        \"precision\": \"100.00%\",\n",
      "        \"sensibilidad\": \"36.36%\",\n",
      "        \"valorF\": \"53.33%\"\n",
      "    }\n",
      "]\n",
      "Fin: 2023-05-21 22:17:40.942720\n",
      "Tiempo: 0:02:21.099629\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
